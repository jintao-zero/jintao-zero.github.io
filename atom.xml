<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[jintao's blog]]></title>
  <link href="http://jintao-zero.github.io/atom.xml" rel="self"/>
  <link href="http://jintao-zero.github.io/"/>
  <updated>2017-08-09T15:52:00+08:00</updated>
  <id>http://jintao-zero.github.io/</id>
  <author>
    <name><![CDATA[jintao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Golang加两遍读锁导致程序死锁问题分析]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/06/20/golangjia-liang-bian-du-suo-dao-zhi-cheng-xu-si-suo-wen-ti-ji-lu/"/>
    <updated>2017-06-20T21:42:04+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/06/20/golangjia-liang-bian-du-suo-dao-zhi-cheng-xu-si-suo-wen-ti-ji-lu</id>
    <content type="html"><![CDATA[<p>golang程序使用读写锁对共享数据进行互斥保护时，注意在同一程序调用栈不要对锁进行多次加锁，这样会导致程序死锁，如下的代码片段就会导致程序死锁：</p>

<pre><code>import (
"sync"
"fmt"
"time"
_ "net/http/pprof"
"net/http"
)

var mutex sync.RWMutex

func f()  {
    fmt.Println("f begin to get Rlock ")
    mutex.RLock()
    defer mutex.RUnlock()
    fmt.Println("f get Rlock suc")
}

func main() {
    mutex.RLock()
    fmt.Println("main get RLock suc")
    defer mutex.RUnlock()

    go http.ListenAndServe(":6060", nil)
    go func() {
        fmt.Println("other goroutine begin to get write lock")
        mutex.Lock()
        defer mutex.Unlock()
        fmt.Println("other goroutine get write lock suc“)
    }()
    time.Sleep(time.Second)
    f()
}
</code></pre>

<p>程序执行结果如下：</p>

<pre><code>MacBook-Pro-2:sync jintao$ go run main.go 
main get RLock suc
other goroutine begin to get write lock
f begin to get Rlock
</code></pre>

<!-- more -->


<p>通过pprof工具查看相关goroutine调用栈：<br/>
main goroutine阻塞在获取读锁的位置：</p>

<pre><code>1 @ 0x102dfca 0x102e0ae 0x103e5a1 0x103e1a4 0x1060869 0x13119c6 0x1311bd7 0x102db7a 0x1059c01
#   0x103e1a3   sync.runtime_Semacquire+0x33    /usr/local/go/src/runtime/sema.go:47
#   0x1060868   sync.(*RWMutex).RLock+0x48  /usr/local/go/src/sync/rwmutex.go:43
#   0x13119c5   main.f+0xa5         /Users/jintao/Project/test/Golang/src/goutil/sync/main.go:15
#   0x1311bd6   main.main+0x136         /Users/jintao/Project/test/Golang/src/goutil/sync/main.go:33
#   0x102db79   runtime.main+0x209      /usr/local/go/src/runtime/proc.go:185
</code></pre>

<p>子goroutine阻塞在获取写锁的位置：</p>

<pre><code>1 @ 0x102dfca 0x102e0ae 0x103e5a1 0x103e1a4 0x106098e 0x1311cb6 0x1059c01
#   0x103e1a3   sync.runtime_Semacquire+0x33    /usr/local/go/src/runtime/sema.go:47
#   0x106098d   sync.(*RWMutex).Lock+0x6d   /usr/local/go/src/sync/rwmutex.go:91
#   0x1311cb5   main.main.func1+0xa5        /Users/jintao/Project/test/Golang/src/goutil/sync/main.go:28
</code></pre>

<p>通过上面的调用栈，我们发现main goroutine在第21行已经获取了读锁，当在调用的函数<code>f</code>第15行再次尝试获取读锁时，程序阻塞。创建的goroutine在第28行尝试获取写所时，协程阻塞。</p>

<h2>分析</h2>

<p>这个是读写锁的一个标准行为。在
<a href="https://en.wikipedia.org/wiki/Readers%E2%80%93writer_lock">Wikipedia &ldquo;Readers–writer lock&rdquo;</a>词条中对读写锁进行了介绍，在<code>Priority policies</code>一节中对<code>reader</code>和<code>writer</code>加锁时的优先级策略进行了说明，不同的优先级策略会给并发和死锁带来不同的影响：</p>

<ul>
<li>读优先策略 <br/>
  读优先允许最大并发，但是如果读并发太多，可能导致写饥饿。<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwji0rOAh9bUAhUW12MKHYx9CvUQFggyMAI&amp;url=http%3A%2F%2Fwww.beck-shop.de%2Ffachbuch%2Fleseprobe%2F9783642320262_Excerpt_001.pdf&amp;usg=AFQjCNEskoEL2n3HKpHGYVWc_XpU4z90nw">Concurrent Programming: Algorithms, Principles, and Foundations</a></li>
<li>写优先策略<br/>
  写优先策略可以避免上面读优先导致的写锁饥饿问题，如果有一个写锁着在等待，系统将会组织任何新reader加读锁成功，一旦当前已经获取的读锁释放完后，即会成功获取写锁。写优先策略相比较与读优先策略，会降低系统的并发性能。相对于读优先策略，写优先策略在实现上的效率要低，因为在获取或者释放读锁或者写锁时，都要操作多个互斥锁。</li>
<li>不指定优先级策略
  这种策略在一定场景下的效率更高</li>
</ul>


<p>从上面Wikipedia关于读写锁的说明看，golang中关于读写锁使用的是写优先策略，下面查看源码，对源码进行分析</p>

<h2>源码解析</h2>

<p>读写锁实现在sync/rwmutex.go文件中</p>

<pre><code>type RWMutex struct {
    w           Mutex  // 获取写锁时，必须获取的互斥量
    writerSem   uint32 // 写锁信号量
    readerSem   uint32 // 读锁信号量
    readerCount int32  // 目前获取的读锁个数
    readerWait  int32  // 需要等待reader释放锁个数
}
</code></pre>

<p><code>加载读锁：</code></p>

<pre><code>// RLock locks rw for reading.
func (rw *RWMutex) RLock() {
    if race.Enabled {
        _ = rw.w.state
        race.Disable()
    }
    if atomic.AddInt32(&amp;rw.readerCount, 1) &lt; 0 {
        // A writer is pending, wait for it.
        runtime_Semacquire(&amp;rw.readerSem)
    }
    if race.Enabled {
        race.Enable()
        race.Acquire(unsafe.Pointer(&amp;rw.readerSem))
    }
}
</code></pre>

<p>每次获取读锁时，都对readerCount计数器进行加1，如果加1后值为负，那么说明有人正在获取写锁。等待readerSem信号量变为正</p>

<p><code>释放读锁：</code></p>

<pre><code>func (rw *RWMutex) RUnlock() {
    if race.Enabled {
        _ = rw.w.state
        race.ReleaseMerge(unsafe.Pointer(&amp;rw.writerSem))
        race.Disable()
    }
    if r := atomic.AddInt32(&amp;rw.readerCount, -1); r &lt; 0 {
        if r+1 == 0 || r+1 == -rwmutexMaxReaders {
            race.Enable()
            panic("sync: RUnlock of unlocked RWMutex")
        }
        // A writer is pending.
        if atomic.AddInt32(&amp;rw.readerWait, -1) == 0 {
            // The last reader unblocks the writer.
            runtime_Semrelease(&amp;rw.writerSem)
        }
    }
    if race.Enabled {
        race.Enable()
    }
}
</code></pre>

<p>释放写锁时，对readerCount减1，说明获取释放一个读锁，如果最新值为负，那么说明有人正在尝试获取写锁，readerWait记录了写锁需要等待的读锁个数，此时将readerWait个数减1，如果个素减为0，说明写锁正在等待的所有reader都已经释放读锁，此时可以释放写锁信号量，让程序获取写锁。</p>

<p><code>获取写锁：</code></p>

<pre><code>func (rw *RWMutex) Lock() {
    if race.Enabled {
        _ = rw.w.state
        race.Disable()
    }
    // First, resolve competition with other writers.
    rw.w.Lock()
    // Announce to readers there is a pending writer.
    r := atomic.AddInt32(&amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders
    // Wait for active readers.
    if r != 0 &amp;&amp; atomic.AddInt32(&amp;rw.readerWait, r) != 0 {
        runtime_Semacquire(&amp;rw.writerSem)
    }
    if race.Enabled {
        race.Enable()
        race.Acquire(unsafe.Pointer(&amp;rw.readerSem))
        race.Acquire(unsafe.Pointer(&amp;rw.writerSem))
    }
}
</code></pre>

<p>获取写锁时，首先获取互斥锁，这样其他写锁必须等待。然后设置读锁个数为负值，这样后面的reader就无法获取到读锁。如果读锁没有释放，则等待写锁信号量变为正。</p>

<p><code>释放写锁：</code></p>

<pre><code>func (rw *RWMutex) Unlock() {
    if race.Enabled {
        _ = rw.w.state
        race.Release(unsafe.Pointer(&amp;rw.readerSem))
        race.Release(unsafe.Pointer(&amp;rw.writerSem))
        race.Disable()
    }

    // Announce to readers there is no active writer.
    r := atomic.AddInt32(&amp;rw.readerCount, rwmutexMaxReaders)
    if r &gt;= rwmutexMaxReaders {
        race.Enable()
        panic("sync: Unlock of unlocked RWMutex")
    }
    // Unblock blocked readers, if any.
    for i := 0; i &lt; int(r); i++ {
        runtime_Semrelease(&amp;rw.readerSem)
    }
    // Allow other writers to proceed.
    rw.w.Unlock()
    if race.Enabled {
        race.Enable()
    }
}
</code></pre>

<p>释放写锁时，将等待获取读锁的个数变为实际值，根据等待获取读锁的个数，释放读锁信号量。</p>

<h2>结论</h2>

<p>根据上面对读写锁源码的分析，我们可以看到golang中读写锁是使用写锁优先策略的，博文开头的例子中，main主协程在已经获取读锁的情况，又尝试第二次获取读锁，因为已经创建了一个子协程在获取写锁，那么第二次获取读锁操作将被阻塞，这样就导致主协程无法释放第一次获取的读锁，从而子协程获取写锁失败，这样整个程序两个写成处于死锁状态。</p>

<h2>参考</h2>

<ul>
<li><a href="https://groups.google.com/forum/#!topic/golang-nuts/4sx5pPp8gFw">Lock re-accquision in sync forbiden</a></li>
<li><a href="https://golang.org/pkg/sync/#RWMutex.Lock">Package sync</a></li>
<li><a href="https://en.wikipedia.org/wiki/Readers%E2%80%93writer_lock">Readers–writer lock</a></li>
<li><a href="https://stackoverflow.com/questions/30547916/goroutine-blocks-when-calling-rwmutex-rlock-twice-after-an-rwmutex-unlock">goroutine blocks when calling RWMutex RLock twice after an RWMutex Unlock</a></li>
<li><a href="https://github.com/golang/go/issues/15418">sync: document that double RLock isn&rsquo;t safe #15418</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go代码走读规范]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/06/14/godai-ma-zou-du-gui-fan/"/>
    <updated>2017-06-14T19:27:11+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/06/14/godai-ma-zou-du-gui-fan</id>
    <content type="html"><![CDATA[<p>Go代码走读时注意点，非代码规范：</p>

<ul>
<li><a href="#gofmt">Gofmt</a></li>
<li><a href="#Comment%20Sentences">Comment Sentences</a></li>
<li><a href="#Contexts">Contexts</a></li>
<li><a href="#Copying">Copying</a></li>
<li><a href="#Declaring%20Empty%20Slices">Declaring Empty Slices</a></li>
<li><a href="#Crypto%20Rand">Crypto Rand</a></li>
<li><a href="#Doc%20Comments">Doc Comments</a></li>
<li><a href="#Don't%20Panic">Don&rsquo;t Panic</a></li>
<li><a href="#Error%20Strings">Error Strings</a></li>
<li><a href="#Examples">Examples</a></li>
<li><a href="#Goroutine%20Lifetimes">Goroutine Lifetimes</a></li>
<li><a href="#Handle%20Errors">Handle Errors</a></li>
<li><a href="#Import">Import</a></li>
<li><a href="#Import%20Dot">Import Dot</a></li>
<li><a href="#In-Band%20Errors">In-Band Errors</a></li>
<li><a href="#Indent%20Error%20Flow">Indent Error Flow</a></li>
<li><a href="#Initialisms">Initialisms</a></li>
<li><a href="#Interfaces">Interfaces</a></li>
<li><a href="#Mixed%20Caps">Mixed Caps</a></li>
<li><a href="#Named%20Result%20Parameters">Named Result Parameters</a></li>
<li><a href="#Package%20Comments">Package Comments</a></li>
<li><a href="#Package%20Names">Package Names</a></li>
<li><a href="#Pass%20Values">Pass Values</a></li>
<li><a href="#Receiver%20Names">Receiver Names</a></li>
<li><a href="#Receiver%20Type">Receiver Type</a></li>
<li><a href="#Synchronous%20Functions">Synchronous Functions</a></li>
</ul>


<h2><span id="Gofmt">Gofmt</span></h2>

<p>使用<a href="https://golang.org/cmd/gofmt/">gofmt</a>工具修复大多数代码风格问题。机会所有Go代码都是用<code>gofmt</code>进行格式化。剩下的非机器可以格式化的代码风格将在本篇文章中进行说明。<br/>
一个替代工具是<code>goimports</code>，它是<code>gofmt</code>工具的一个超集，它会自动增加或者删除引入包行。</p>

<h2><span id="Comment Sentences">Comment Sentences</span></h2>

<p>查看<a href="https://golang.org/doc/effective_go.html#commentary">https://golang.org/doc/effective_go.html#commentary</a>，声明的注释应该占完整行，这样在将注释抽取到godoc文档时可以更好的格式化。注释应该以被注释声明开始，存在结束：</p>

<pre><code>// Request represents a request to run a command.
type Request struct { ...

// Encode writes the JSON encoding of req to w.
func Encode(w io.Writer, req *Request) { ...
</code></pre>

<h2><span id="Contexts">Contexts</span></h2>

<p><code>context.Context</code>类型实例在API和进程边界中传递安全证书、跟踪信息、超时期限和取消信号。Go程序在从RPC或者HTTP请求开始到输出请求的整个函数调用链过程中显示传递Context实例。  <br/>
大部分函数使用Context作为第一个参数：</p>

<pre><code>func F(ctx context.Context, /* other arguments */) {}
</code></pre>

<p>如果一个函数不是请求特化的话，可以使用context.Background，即使你觉得不必要也宁可传递一个Context实例。默认情况是传递一个Context上下文，除非有更好的理由来使用<code>context.Background</code>。<br/>
不要在结构体类型中添加<code>Context</code>成员，在结构体类型的所有需要使用Context的方法中添加一个ctx参数，用来传递Context。一个特殊情况是如果这些方法需要满足标准库或者第三方库中的接口。<br/>
不要在函数声明中使用特定Context类型或者使用非Context接口。<br/>
除非真的需要，否则通过参数，全局变量或者其他方法传递应用程序数据。<br/>
Context是不可变的，所以可在多个调用中传递同一个ctx共享同样的最后期限、取消信号、资格认证和跟踪等等。</p>

<h2><span id="Copying"> Copying</span></h2>

<p>避免非预期的别名使用，当从其他包拷贝结构体时需要小心。比如，bytes.Buffer类型包含一个<code>[]byte</code>数组，当保存的字符串比较小时，内部<code>[]byte</code>数组就比较小。如果拷贝一个<code>Buffer</code>，新旧Buffer类型变量中的数组就发生了混淆，这样接下来对于两个Buffer对象的使用将产生不可预知的情况。<br/>
总的来说，如果一个类型<code>T</code>，它的方法都与<code>*T</code>想对象，那就不要复制这个类型的变量。</p>

<h2><span id="Declaring Empty Slices"> Declaring Empty Slices</span></h2>

<p>声明一个空切片时，使用下面方式：</p>

<pre><code>var t []string
</code></pre>

<p>而不是</p>

<pre><code>t := []string{}
</code></pre>

<p>前者声明一个nil切片，后者定义一个长度为0的非nil切片。两种方式定义的切片<code>len</code>和<code>cap</code>的值都为0，建议使用前者。</p>

<p>一些场景下建议使用后者定义空切片，比如将对象序列化为JSON格式时，<code>nil</code>序列化为<code>null</code>，<code>[]string{}</code>序列化为<code>[]</code>。</p>

<p>设计接口时，避免nil切片，非nil切片和长度为0的切片产生差异，否则会产生微妙的错误。</p>

<p>更多关于Go中nil的讨论见：<a href="https://www.youtube.com/watch?v=ynoY2xz-F8s">Understanding Nil</a></p>

<h2><span id="Crypto Rand">Crypto Rand</span></h2>

<p>即使只使用一次，也不要使用<code>math/rand</code>生成key。没有种子，生成是可预测的。使用<code>time.Nanoseconds()</code>设置种子，只有一点熵。可替换方法是，使用<code>crypto/rand</code>，如果需要文本，打印为十六进制或者base64编码。</p>

<pre><code>import (
"crypto/rand"
// "encoding/base64"
// "encoding/hex"
"fmt"
)

func Key() string {
    buf := make([]byte, 16)
    _, err := rand.Read(buf)
if err != nil {
    panic(err)  // out of randomness, should never happen
}
return fmt.Sprintf("%x", buf)
// or hex.EncodeToString(buf)
// or base64.StdEncoding.EncodeToString(buf)    
}
</code></pre>

<h2><span id="Doc Comments">Doc Comments</span></h2>

<p>所有顶级，对外提供的名称应该有文档注释，一些重要的非对外提供的类型和函数定名也需要有注释。更多关于注释的信息参考：<a href="https://golang.org/doc/effective_go.html#commentary">https://golang.org/doc/effective_go.html#commentary</a></p>

<h2><span id="Don't Panic">Don&rsquo;t Panic</span></h2>

<p>关于错误处理参考：<a href="https://golang.org/doc/effective_go.html#errors">https://golang.org/doc/effective_go.html#errors</a>。不要使用<code>panic </code>处理普通错误。使用error和多返回值。</p>

<h2><span id="Error Strings">Error Strings</span></h2>

<p>错误字符串不应该大写，除非是以名词或者缩写开头，因为错误信息通常跟在其他信息后面。使用<code>fmt.Errorf("something bad")</code>，而不是<code>fmt.Errorf("Something bad")</code>，所以<code>log.Printf("Reading %s: %v", filename, err)</code>格式化的信息中不会在中间出现一个可以的大写字符。</p>

<h2><span id="Examples">Examples</span></h2>

<p>当添加一个新包时，包含使用示例：一个可运行示例，或者一个简单测试演示一个完整调用顺序。<br/>
更多信息参考：<a href="https://blog.golang.org/examples">testable Example() functions</a>。</p>

<h2><span id="Goroutine Lifetimes">Goroutine Lifetimes</span></h2>

<p>当创建goroutine时，需要对它是否退出和什么时间退出非常清楚。</p>

<p>goroutine阻塞在发送或者接收通道时可能会导致泄漏：垃圾收集不会结束这样的goroutine。</p>

<p>即使这些goroutine没有泄漏，这样的goroutine有可能导致微妙的不易定位的问题。向已经关闭的通道发送数据会导致panic。</p>

<p>保持并发执行的代码足够简单，这样goroutine的声明周期更明显。 如果不能这样的话，对goroutine的退出时机进行注释。</p>

<h2><span id="Handle Errors">Handle Errors</span></h2>

<p>查看错误处理<a href="https://golang.org/doc/effective_go.html#errors">https://golang.org/doc/effective_go.html#errors</a>，不要使用<code>_</code>丢弃错误。如果一个函数返回错误，对返回值进行检查。处理错误，返回。如果是异常情况，则panic。</p>

<h2><span id="Imports">Import</span></h2>

<p>除了避免命名冲突，不要重命名引入的包。好的包命名不需要重命名。万一出现冲突，优先考虑重命名本地包或者项目相关的引入。</p>

<p>引入的包成组组织，以空行分隔。标准库总是在第一组。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package main
</span><span class='line'>
</span><span class='line'>import (
</span><span class='line'>  "fmt"
</span><span class='line'>  "hash/adler32"
</span><span class='line'>  "os"
</span><span class='line'>
</span><span class='line'>  "appengine/foo"
</span><span class='line'>  "appengine/user"
</span><span class='line'>
</span><span class='line'>  "code.google.com/p/x/y"
</span><span class='line'>  "github.com/foo/bar"
</span><span class='line'>)</span></code></pre></td></tr></table></div></figure>


<p><a href="https://godoc.org/golang.org/x/tools/cmd/goimports">goimports</a>工具会完成上面的格式化。</p>

<h2><span id="Import Dot">Import Dot</span></h2>

<p>进行测试时，因为循环依赖，不能将测试用例放入被测包中时，可以用<code>import .</code>解决：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package foo_test
</span><span class='line'>
</span><span class='line'>import (
</span><span class='line'>  "bar/testutil" // also imports "foo"
</span><span class='line'>  . "foo"
</span><span class='line'>)</span></code></pre></td></tr></table></div></figure>


<p>这个例子中，测试文件不能放入<code>foo</code>包中，因为它使用<code>bar/testutil</code>，<code>bar/testutil</code>包引入了<code>foo</code>包。 我们使用<code>import .</code>使测试文件假装在包<code>foo</code>中，实际上不在。除了这一个特殊情况，不要使用<code>import .</code>。它使程序无法更好阅读，因为不方便区分一个大写开头的方法是当前包还是引入包中的顶级标识符。</p>

<h2><span id="In-Band Errors">In-Band Errors</span></h2>

<p>C或者其他类似语音中，函数返回-1或者null来表示错误是很常见的：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// Lookup returns the value for key or "" if there is no mapping for key.
</span><span class='line'>func Lookup(key string) string
</span><span class='line'>
</span><span class='line'>// Failing to check a for an in-band error value can lead to bugs:
</span><span class='line'>Parse(Lookup(key))  // returns "parse failure for value" instead of "no value for key"</span></code></pre></td></tr></table></div></figure>


<p>Go中的多返回值机制提供了一个更好的方案。函数直接放回一个错误值来表示函数执行结果是否正确。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// Lookup returns the value for key or ok=false if there is no mapping for key.
</span><span class='line'>func Lookup(key string) (value string, ok bool)
</span></code></pre></td></tr></table></div></figure>


<p>这种格式可以阻止不正确的使用函数返回值：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// Lookup returns the value for key or ok=false if there is no mapping for key.
</span><span class='line'>func Lookup(key string) (value string, ok bool)</span></code></pre></td></tr></table></div></figure>


<p>一个更健壮和可阅读的风格如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>value, ok := Lookup(key)  
</span><span class='line'>if !ok  {  
</span><span class='line'>    return fmt.Errorf("no value for %q", key)
</span><span class='line'>}
</span><span class='line'>return Parse(value)</span></code></pre></td></tr></table></div></figure>


<p>这个规则对于导出函数和非导出函数都是有用的。</p>

<h2><span id="Indent Error Flow">Indent Error Flow</span></h2>

<p>保持正常流程最小缩进，缩进异常处理流程。这有助于提高可读性，可以快速查阅程序正常流程，不建议如下风格：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if err != nil {
</span><span class='line'>  // error handling
</span><span class='line'>} else {
</span><span class='line'>  // normal code
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>建议如下风格：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if err != nil {
</span><span class='line'>  // error handling
</span><span class='line'>  return // or continue, etc.
</span><span class='line'>}
</span><span class='line'>// normal code</span></code></pre></td></tr></table></div></figure>


<p>像下面这样<code>if</code>表达式中带初始化操作的语句：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if x, err := f(); err != nil {
</span><span class='line'>  // error handling
</span><span class='line'>  return
</span><span class='line'>} else {
</span><span class='line'>  // use x
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>建议将声明挪到外面去，如下所示：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>x, err := f()
</span><span class='line'>if err != nil {
</span><span class='line'>  // error handling
</span><span class='line'>  return
</span><span class='line'>}
</span><span class='line'>// use x</span></code></pre></td></tr></table></div></figure>


<h2><span id="Initialisms"> Initialisms</span></h2>

<p>命名中的首字母缩写应该保持同一大小写风格。比如，<code>URL</code>应该写为<code>URL</code>或者<code>url</code>（<code>URLPony</code>或者<code>urlPony</code>）,不应该为<code>Url</code>。又一个例子：应该为<code>ServeHTTP</code>而不应该为<code>ServeHttp</code>。<br/>
这个规则也适用于<code>identifier</code>的缩写<code>ID</code>，应该命名为<code>appID</code>而不是<code>appid</code>。<br/>
protocol buffer编译生成的代码可以不遵守这个规则。人类编写的程序应该比机器坚持更高标准。</p>

<h2><span id="Interfaces"> Interfaces</span></h2>

<p>Go 接口通常定义在使用接口的包中，而不是在实现接口的包中。实现的包应该返回具体类型（通常指针类型或者结构体）：这种方法，可以方便的在实现类型上增加新方法。</p>

<p>不要因为模拟，在具体实现这边定义接口类型。</p>

<p>不要在使用之前定义接口类型：没有使用的实际用例，对于判断一个接口是否需要是困难的，不要去想接口应该包含哪些方法。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package consumer  // consumer.go
</span><span class='line'>
</span><span class='line'>type Thinger interface { Thing() bool }
</span><span class='line'>
</span><span class='line'>func Foo(t Thinger) string { … }</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package consumer // consumer_test.go
</span><span class='line'>
</span><span class='line'>type fakeThinger struct{ … }
</span><span class='line'>func (t fakeThinger) Thing() bool { … }
</span><span class='line'>…
</span><span class='line'>if Foo(fakeThinger{…}) == "x" { … }</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// DO NOT DO IT!!!
</span><span class='line'>package producer
</span><span class='line'>
</span><span class='line'>type Thinger interface { Thing() bool }
</span><span class='line'>
</span><span class='line'>type defaultThinger struct{ … }
</span><span class='line'>func (t defaultThinger) Thing() bool { … }
</span><span class='line'>
</span><span class='line'>func NewThinger() Thinger { return defaultThinger{ … } }</span></code></pre></td></tr></table></div></figure>


<p>定义一个具体类型，让消费者模拟生产者实现。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>package producer
</span><span class='line'>
</span><span class='line'>type Thinger struct{ … }
</span><span class='line'>func (t Thinger) Thing() bool { … }
</span><span class='line'>
</span><span class='line'>func NewThinger() Thinger { return Thinger{ … } }
</span></code></pre></td></tr></table></div></figure>


<h2><span id="Mixed Caps"> Mixed Caps</span></h2>

<p>查看<a href="https://golang.org/doc/effective_go.html#mixed-caps">mixed-caps</a>，这打破了其他语言中惯例。比如一个非导出常量命名<code>maxLength</code>而不是<code>MaxLength</code>和<code>MAX_LENGTH</code>。</p>

<h2><span id="Named Result Parameters"> Named Result Parameters</span></h2>

<p>下面这样的定义：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>func (n *Node) Parent1() (node *Node)
</span><span class='line'>func (n *Node) Parent2() (node *Node, err error)</span></code></pre></td></tr></table></div></figure>


<p>最好定义成如下方式：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>func (n *Node) Parent1() *Node
</span><span class='line'>func (n *Node) Parent2() (*Node, error)</span></code></pre></td></tr></table></div></figure>


<p>其他情况，如果一个函数返回两个或者三个相同类型的值，或者一个返回值的意义不是很明确，那么应该给返回值命名。</p>

<pre><code>func (f *Foo) Location() (float64, float64, error)
</code></pre>

<p>没有下面命名更清晰：</p>

<pre><code>// Location returns f's latitude and longitude.
// Negative values mean south and west, respectively.
func (f *Foo) Location() (lat, long float64, err error)
</code></pre>

<h2><span id="Package Comments"> Package Comments</span></h2>

<p>包注释，与其他被godoc工具展示的注释类似，必须紧邻着package语句，不需要空白行。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// Package math provides basic constants and mathematical functions.  
</span><span class='line'>package math</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/*
</span><span class='line'>Package template implements data-driven templates for generating textual
</span><span class='line'>output such as HTML.
</span><span class='line'>....
</span><span class='line'>*/
</span><span class='line'>package template</span></code></pre></td></tr></table></div></figure>


<p>对于<code>package main</code>可以使用一些其他风格的注释，比如，在<code>seedgen</code>目录中的<code>package main</code>包，可以采用如下注释：</p>

<pre><code>// Binary seedgen ...
package main
</code></pre>

<p>或者</p>

<pre><code>// Command seedgen ...
package main
</code></pre>

<p>或者</p>

<pre><code>// Program seedgen ...
package main
</code></pre>

<p>或者</p>

<pre><code>// The seedgen command ...
package main
</code></pre>

<p>或者
    // The seedgen program &hellip;
    package main</p>

<p>或者</p>

<pre><code>// Seedgen ..
package main
</code></pre>

<p>上面例子的其他形式也是可以接受的。<br/>
对于包注释，不应该以小写字母开头，因为这些注释会被公开查看，应该按照英语规则书写。
查看<a href="https://golang.org/doc/effective_go.html#commentary">https://golang.org/doc/effective_go.html#commentary</a>关于注释的详细说明。</p>

<h2><span id="Package Names"> Package Names</span></h2>

<p>外界需要使用报名来引用包中的命名，所以可以在命名中将包名去掉。比如，如果<code>package chubby</code>中定义<code>File</code>，不需要定义成<code>ChubbyFile</code>，因为访问时就是这样<code>chubby.ChubbyFile</code>。直接定义成<code>File</code>，这样访问时就会是<code>chubby.File</code>。避免无意义包名，如<code>util, common,misc,api,types,interfaces</code>。查看<a href="http://golang.org/doc/effective_go.html#package-names">http://golang.org/doc/effective_go.html#package-names</a>和<a href="http://blog.golang.org/package-names">http://blog.golang.org/package-names</a>详细信息。</p>

<h2><span id="Pass Values"> Pass Values</span></h2>

<p>不要只是为了节省几个字节而传递指针作为函数地址。如果一个函数都是以<code>*x</code>的形式使用参数<code>x</code>，那么就参数<code>x</code>就不应该是指针形式。比如以传递一个字符串的指针<code>*string</code>或者一个指向接口的类型<code>*io.Reader</code>作为函数参数，在这两种场景中，字符串和接口类型值都是固定大小，可以直接传递。这个建议对于大的结构体类型并不适用。</p>

<h2><span id="Receiver Names"> Receiver Names</span></h2>

<p>方法接受者名称应该反映它的实体类型。通常是类型的一个或者两个字母缩写（比如用c和cl代表Client）。不要使用<code>me</code>，<code>this</code>或者<code>self</code>这样的面向对象语言中使用的标识符。</p>

<h2><span id="Receiver Type"> Receiver Type</span></h2>

<p>对于Go新手来说，定义方法时使用值还是指针作为接收者是困难的。如果有所疑虑，使用指针。下面是一些指导意见：</p>

<ul>
<li>如果接受者是<code>map``func</code>或者<code>chan</code>时，不要使用指针。如果接受者是一个<code>slice</code>并且方法中并没有重新分配slice，不要使用指针。</li>
<li>如果方法需要修改接受者，必须使用指针。</li>
<li>如果接受者是一个结构体并且包含sync.Mutex或者类似同步元语字段，接受者必须是指针类型避免拷贝。</li>
<li>如果接受者是一个大的结构体或者数组，指针类型接受者更有效率。</li>
</ul>


<h2><span id="Synchronous Functions"> Synchronous Functions</span></h2>

<h2>参考</h2>

<ul>
<li><a href="https://github.com/golang/go/wiki/CodeReviewComments#receiver-names">CodeReviewComments</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang 工程代码结构]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/06/11/golang-gong-cheng-dai-ma-jie-gou/"/>
    <updated>2017-06-11T12:19:45+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/06/11/golang-gong-cheng-dai-ma-jie-gou</id>
    <content type="html"><![CDATA[<p>golang工程常用代码目录结构</p>

<pre><code>github.com/user/project
    pkg
        p1
            *.go
        p2
            *.go 
    cmd
        cmdline
            main.go
    web
            main.go
    vendor
        github/*/*
    examples
    docs
</code></pre>

<h2>参考</h2>

<ul>
<li><p><a href="https://stackoverflow.com/questions/32634837/project-structure-for-a-tool-with-multiple-uis/32635264#32635264">Project structure for a tool with multiple UIs</a></p></li>
<li><p><a href="https://forum.golangbridge.org/t/how-should-i-structure-packages-for-a-multiple-binary-web-application/665">How should I structure packages for a multiple-binary web application?</a></p></li>
<li><a href="https://github.com/seccom/kpass">kpass</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go Test命令详解]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/05/29/go-testming-ling-xiang-jie/"/>
    <updated>2017-05-29T10:58:11+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/05/29/go-testming-ling-xiang-jie</id>
    <content type="html"><![CDATA[<h2>Test packages</h2>

<p>使用：</p>

<pre><code>go test [build/test flags] [packages] [build/test flags &amp; test binary flags]
</code></pre>

<p><code>Go test</code>命令自动测试<code>packages</code>参数指定的包。它以如下格式打印测试结果摘要信息：</p>

<pre><code>ok   archive/tar   0.011s
FAIL archive/zip   0.022s
ok   compress/gzip 0.033s
...
</code></pre>

<p><code>Go test</code>重新编译每个包中文件名为<code>*_test.go</code>模式的文件，将这些文件与测试库进行链接、运行。<br/>
go tool工具会忽略名为<code>testdata</code>的文件夹，使用这个文件夹来保存test中需要的数据。<br/>
默认情况，<code>go tes</code>不需要任何参数。它会编译并当前目录下所有test文件。  <br/>
测试包被安装在临时目录，所以它不会涉及到非测试包安装目录。<br/>
除了build标志，<code>go test</code>自身支持的标志如下：</p>

<pre><code>-args
    将-args后面的参数不做任何修改和解释的传递给test可执行文件。  
    需要在这个参数之前指定包名。  
-c 
    编译test二进制文件为pkg.test但是不运行。pkg为引入包路径的最后一层。
    可以使用-o参数修改可执行文件名。  
-exec xprog
    使用xprog运行test二进制文件。行为表现与go run一样。详情参照go help run  
-i 
    安装测试依赖的包。但是不运行测试。  
-o file
    指定可执行测试文件名并运行测试。  
</code></pre>

<p>test二进制可执行文件接受参数来控制test执行。这些参数也可以在<code>go test</code>使用：</p>

<pre><code>-bench regexp
    运行负荷正则表达式的子性能测试。
-benchmem
    性能测试中的内存统计信息。  
-benchtime t
    运行足够多的性能测试用例次数，使测试时间达到t，t的类型为time.Duration(比如，-benchtime 1h30s)。默认是1秒。    
-blockprofile block.out  
    所有测试结束后，将goroutine blocking 性能数据写入指定文件。  
-blockprofilerate n  
    使用runtime.SetBlockProfileRate控制goroutine blocking性能数据格式。  
-count n  
    运行每个测试用例和性能测试用例n次。如果设置了-cpu参数，每个GOMAXPROCS运行n次。  
-cover 
    启动覆盖率分析  
-covermode set,count,atomic
    设置覆盖分析模式。如果设置了-race，则覆盖分析模式为atomic，否则为默认set模式。
    set：
    count：
    atomic：
-coverpkg pkg1,pkg2,pkg3
    每个测试中都对给定列表中的包进行覆盖分析。默认是对正在进行测试的包进行分析。
-coverprofile cover.out
    所有测试都通过后，输出一个覆盖测试文件。  
-cpu 1,2,4  
    指定一个GOMAXPROCS列表，默认是GOMAXPROCS当前值。  
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[翻译]SOCKS5 协议]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/04/02/socks5-xie-yi/"/>
    <updated>2017-04-02T16:38:00+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/04/02/socks5-xie-yi</id>
    <content type="html"><![CDATA[<h2>介绍</h2>

<p>网络防火墙用来隔离组织内部网络和外部网络，比如<code>INTERNET</code>。这些防火墙系统扮演着内外部网络之间的应用层网关，用来控制<code>TELNET</code>、<code>FTP</code>和<code>SMTP</code>等协议的进入。随着更多复杂应用层协议被设计用来加速全局信息发现，需要为这些协议提供一个框架以便透明和安全的通过防火墙。 也需要提供为这种通过提供可靠授权。 <br/>
<code>SOCKS5</code>协议被设计用来为基于TCP或者UDP协议的client-server模式应用程序方便且安全的使用网络防火墙服务。这个协议概念上认为是在应用层和传输层之间，因此它不提供网络层网关服务，比如转发<code>ICMP</code>消息。</p>

<p>已经存在了一个<code>SOCKS4</code>协议，这个版本的协议在4版本的基础上支持UDP协议，包含通用授权范型和支持域名和V6版本IP地址。</p>

<!-- more -->


<h2>TCP客户端处理步骤</h2>

<p>当一个基于TCP协议的客户端希望与位于防火墙后面的目标之间建立一个连接时，它必须打开一个到<code>SOCKS</code>服务端的连接。<code>SOCKS</code>服务按照惯例位于1080TCP端口。 如果连接建立成功后，客户端发送鉴权请求。服务端评估请求，要么建立相应连接或者拒绝这个请求。  <br/>
客户端连接socks服务端，发送一个版本标识符或者方法选择消息：</p>

<pre><code>+----+----------+----------+
|VER | NMETHODS | METHODS  |
+----+----------+----------+
| 1  |    1     | 1 to 255 |
+----+----------+----------+
</code></pre>

<p><code>VER</code>字段设置为<code>X'05'</code>是这个协议的版本。<code>NMETHODS</code>字段包含出现在<code>METHODS</code>字段中的值的字节数。<br/>
socks服务端从<code>METHODS</code>中选择一个方法，发送一个<code>METHOD</code>选择消息：</p>

<pre><code>+----+--------+
|VER | METHOD |
+----+--------+
| 1  |   1    |
+----+--------+
</code></pre>

<p>如果选择的<code>METHOD</code>为<code>X'FF'</code>，那么客户端列出的所有方法都不被接受，这时候客户端必须关闭连接。<br/>
目前定义的<code>METHOD</code>值有：</p>

<pre><code>o  X'00' NO AUTHENTICATION REQUIRED
o  X'01' GSSAPI
o  X'02' USERNAME/PASSWORD
o  X'03' to X'7F' IANA ASSIGNED
o  X'80' to X'FE' RESERVED FOR PRIVATE METHODS
o  X'FF' NO ACCEPTABLE METHODS  
</code></pre>

<p>方法选择之后，客户端和服务端之间进入与方法相关的子协商。</p>

<h2>请求</h2>

<p>子协商完成后，客户端发送请求详情。如果协商结果是需要对发送的消息进行封装加密，那么请求消息必须进行封装加密。<br/>
SOCKS协议请求格式为：</p>

<pre><code>+----+-----+-------+------+----------+----------+
|VER | CMD |  RSV  | ATYP | DST.ADDR | DST.PORT |
+----+-----+-------+------+----------+----------+
| 1  |  1  | X'00' |  1   | Variable |    2     |
+----+-----+-------+------+----------+----------+
</code></pre>

<p>字段说明如下：</p>

<pre><code>o  VER    protocol version: X'05'
o  CMD
o  CONNECT X'01'
o  BIND X'02'
o  UDP ASSOCIATE X'03'
o  RSV    RESERVED
o  ATYP   address type of following address
o  IP V4 address: X'01'
o  DOMAINNAME: X'03'
o  IP V6 address: X'04'
o  DST.ADDR       desired destination address
o  DST.PORT desired destination port in network octet order
</code></pre>

<p>SOCKS服务端将会根据源和目的地址评估请求，并且根据请求类型返回一个或者多个回复消息。</p>

<h2>地址</h2>

<p>在地址字段（<code>DST.ADDR BND.ADDR</code>），<code>ATYP</code>字段指示了地址的类型：</p>

<ul>
<li>X&#8217;01&#8217;
指示地址为IPv4地址，长度为4个字节。</li>
<li>X&#8217;03&#8217;
指示地址为域名。地址的第一个字节为域名的长度，域名不是以<code>NUL</code>结束的。</li>
<li>X&#8217;04&#8217;
地址为IPv6地址，长度为16个字节。</li>
</ul>


<h2>回复</h2>

<p>对应上面的请求，服务端回复以下应答：</p>

<pre><code>+----+-----+-------+------+----------+----------+
|VER | REP |  RSV  | ATYP | BND.ADDR | BND.PORT |
+----+-----+-------+------+----------+----------+
| 1  |  1  | X'00' |  1   | Variable |    2     |
+----+-----+-------+------+----------+----------+ 
</code></pre>

<p> 字段说明如下：</p>

<pre><code> o  VER    protocol version: X'05'
 o  REP    Reply field:
    o  X'00' succeeded
    o  X'01' general SOCKS server failure
    o  X'02' connection not allowed by ruleset
    o  X'03' Network unreachable
    o  X'04' Host unreachable
    o  X'05' Connection refused
    o  X'06' TTL expired
    o  X'07' Command not supported
    o  X'08' Address type not supported
    o  X'09' to X'FF' unassigned

 o  RSV    RESERVED
 o  ATYP   address type of following address
     o  IP V4 address: X'01'
     o  DOMAINNAME: X'03'
     o  IP V6 address: X'04'
 o  BND.ADDR       server bound address
 o  BND.PORT       server bound port in network octet order
</code></pre>

<p>标记为<code>RESERVED</code>的字段必须设置为X&#8217;00&#8217;</p>

<h3>CONNECT</h3>

<p>对于<code>CONNECT</code>请求消息的应答中，<code>BND.PORT</code>字段为服务端绑定的用来连接到目标主机的端口号，<code>BND.ADDR</code>字段为绑定的地址。绑定的地址通常与客户端连接服务端的地址不同。</p>

<h3>BIND</h3>

<p>BIND请求被用来要求客户端接受来自服务端的请求。FTP是一个常见的例子，它使用客户端到服务端的连接发送命令和状态，使用服务端到客户端的连接传输数据。  <br/>
客户端使用<code>CONNECT</code>建立主连接，使用<code>BIND</code>请求只是用来建立第二个连接。<br/>
对于<code>BIND</code>请求，<code>SOCKS</code>服务端将使用<code>DST.ADDR</code>和<code>DST.PORT</code>。<br/>
对于<code>BIND</code>操作，SOCKS服务端将会发送两个回复到客户端。服务端创建和绑定一个新的socket套接字后发送第一个回复。回复中<code>BND.PORT</code>字段值为SOCKS服务端本地绑定用来监听和接受连接的端口号。<code>BND.ADDR</code>字段为SOCKS服务端绑定的IP。客户端通过主控制链路发送这些信息给应用程序服务端。当新的连接建立成功或者失败后，SOCKS服务端会发送第二个应答。 在第二个应答中，<code>BND.PORT</code>和<code>BND.ADDR</code>字段包含连接主机的ip和端口信息。</p>

<h3>UDP</h3>

<p><code>UDP ASSOCIATE</code>请求用来与UDP中继进程建立一个联系来处理UDP数据报。客户端希望发送UDP数据报到<code>DST.ADDR</code>和<code>DST.PORT</code>字段标示的IP和端口号。在建立UDP ASSOCIATE时，如果客户端不拥有这些信息，客户端必须使用全零的端口号和ip地址。  <br/>
当发送UDP ASSOCIATE请求的TCP连接中断时，这个UDP 连接也要中断。<br/>
在对UDP ASSOCIATE请求的应答中，<code>BND.PORT</code>和<code>BND.ADDR</code>字段表示客户端必须将待转发的UDP消息发送到这个地址。</p>

<h3>应答处理</h3>

<p>如果应答消息中结果字段为失败，SOCKS服务端必须在发送应答后立即关闭TCP连接。关闭连接必须在检测到失败后10秒内终止连接。</p>

<p>如果应答消息中结果字段为成功，请求为<code>BIND</code>或者<code>CONNECT</code>的话，客户端就可以开始传输数据。 如果协商了封装加密方法的话，在客户端和SOCKS服务端通信过程中需要进行封装加密。</p>

<h2>UDP客户端</h2>

<p>udp客户端必须想UDP ASSOCIATE应答中<code>BND.PORT</code>标示的字段发送UDP数据报。如果协商了封装方法，那么通讯时需要进行封装。<br/>
每个UDP数据需要携带一个UDP请求头：</p>

<pre><code>+----+------+------+----------+----------+----------+
|RSV | FRAG | ATYP | DST.ADDR | DST.PORT |   DATA   |
+----+------+------+----------+----------+----------+
| 2  |  1   |  1   | Variable |    2     | Variable |
+----+------+------+----------+----------+----------+
</code></pre>

<p> 字段说明如下：</p>

<pre><code> o  RSV  Reserved X'0000'
 o  FRAG    Current fragment number
 o  ATYP    address type of following addresses:
        o  IP V4 address: X'01'
      o  DOMAINNAME: X'03'
      o  IP V6 address: X'04'
 o  DST.ADDR       desired destination address
 o  DST.PORT       desired destination port
 o  DATA     user data
</code></pre>

<p>UDP中继服务端必须从SOCKS服务端获取申请建立UDP ASSOCIATE的客户端ip地址。中继服务端对于其他源ip发送过来的数据包将会丢弃。</p>

<h2>参考</h2>

<p><a href="https://www.ietf.org/rfc/rfc1928.txt">rfc1928</a><br/>
<a href="https://tools.ietf.org/html/rfc1929">rfc1929</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH常用设置(免密、别名登录、隧道转发)]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/30/sshsui-dao-zhuan-fa-gong-neng/"/>
    <updated>2017-03-30T19:48:56+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/30/sshsui-dao-zhuan-fa-gong-neng</id>
    <content type="html"><![CDATA[<p>作为程序员每天都需要使用ssh登录到远程主机进行部署调试，本篇将总结ssh工具几个常用方法：</p>

<ul>
<li><a href="#password-less">免密登录</a></li>
<li><a href="#alias">别名登录</a></li>
<li><a href="#tunnel">隧道转发</a></li>
</ul>


<h2><a name="password-less"> </a>免密登录</h2>

<ol>
<li>在本地机器上生成pubkey</li>
<li>将pubkey拷贝到远程主机~/.ssh/authorized_keys文件中</li>
</ol>


<h2><a name="alias"/> </a>别名登录</h2>

<p>在免密登录的基础上， 可以方便实现别名登录
在本地~/.ssh/config文件中配置远程主机相关信息：</p>

<pre><code>Host vps
    HostName 45.78.61.64
    Port 22
    User root
</code></pre>

<p> 本地可以使用</p>

<pre><code>ssh vps
</code></pre>

<p> 这样的形式直接登录目标主机</p>

<h2><a name="tunnel"> </a> 隧道转发</h2>

<p>远端主机可能设置了防火墙，只开放少数端口，比如远端机器只开放了22 ssh端口，如果本地想连接远端3306端口的话，会被防火墙拒绝，这个时候我们可以利用ssh的隧道功能，将本地流量通过ssh tunnel转发远端目标端口，在~/.ssh/config配置文件中添加如下配置：</p>

<pre><code>Host tunnel
    HostName 45.78.61.64
    Port 27764
    LocalForward 3306 127.0.0.1:3306
    User root
</code></pre>

<p> 上面的意思是将本地3306端口流量隧道转发到45.78.61.64 3306端口
    添加配置后，需要运行下面命令：</p>

<pre><code>ssh -f -N tunnel 
</code></pre>

<p>使用lsof -i:3306我们可以看到ssh程序正在监听这个端口，当有数据从这个端口进来时，ssh程序会将数据转发到远端sshd服务端程序，服务端程序会将流量转发到远端本地3306端口，ssh隧道数据是加密的，我上一篇开发的<a href="http://jintao-zero.github.io/blog/2017/03/29/golang-shi-xian-httpdai-li/">http proxy</a>我们可以利用ssh可以利用这个功能躲避GFW</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang 实现HTTP代理]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/29/golang-shi-xian-httpdai-li/"/>
    <updated>2017-03-29T16:51:16+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/29/golang-shi-xian-httpdai-li</id>
    <content type="html"><![CDATA[<p>使用Golang实现一个HTTP代理程序，程序部署在海外VPS节点，可以实现翻墙功能<br/>
HTTP Proxy的基本原理是将客户端HTTP请求发送到目标主机，将目标主机返回的HTTP应答转发到客户端,对于HTTPS协议略有不同，HTTPS协议需要Proxy先建立一条到目标主机的链路，之后再进行协议本身的通讯，下面简单介绍一个HTTP Proxy的实现过程：</p>

<h3>分析第一条请求</h3>

<ol>
<li><p>启动一个简版HTTP Proxy程序，代码如下：</p>

<pre><code> func handleConn(conn net.Conn) {
     defer conn.Close()
     log.Println("client conn form ", conn.RemoteAddr())
     var buffer [1024]byte
     _, err := conn.Read(buffer[:])
     if err != nil {
         return
     }
     log.Println(string(buffer[:]))
 }

 func main() {
     // listen on tcp port
     l, err := net.Listen("tcp", ":8081")
     if err != nil {
         log.Println(err)
         return
     }
     for {
         conn, err := l.Accept()
         if err != nil {
             log.Println(err)
             return
         }
         go handleConn(conn)
     }
 }  
 go run httpproxy.go
</code></pre>

<p> 这个程序主要是用来接收客户端发送的第一条HTTP请求</p></li>
</ol>


<!-- more -->


<ol>
<li><p>Safari设置HTTP/HTTPS代理<br/>
 设置代理为<code>localhost:8081</code><br/>
 <img src="http://jintao-zero.github.io/images/http-proxy-1.png" alt="proxy" /></p></li>
<li><p>Safari输入框访问<code>http://localhost:8080</code>，我们的proxy程序输出HTTP请求：</p>

<pre><code> GET http://www.localhost.com:8080/ HTTP/1.1
 Host: www.localhost.com:8080
 Proxy-Connection: keep-alive
 Upgrade-Insecure-Requests: 1
 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/602.4.8 (KHTML, like Gecko)     Version/10.0.3 Safari/602.4.8
 Accept-Language: zh-cn
 Accept-Encoding: gzip, deflate
 Connection: keep-alive
</code></pre>

<p>其中跟代理有关的是前两行：</p>

<pre><code>  GET http://www.localhost.com:8080/ HTTP/1.1
  Host: www.localhost.com:8080
</code></pre>

<p>当访问<code>http://localhost</code>时，输出的前两行为：</p>

<pre><code>  GET http://www.localhost.com/ HTTP/1.1
  Host: www.localhost.com
</code></pre></li>
<li><p>Safari输入框访问<code>https://localhost:8080</code>时，proxy程序输出HTTP请求为：</p>

<pre><code> CONNECT www.localhost.com:8080 HTTP/1.1
 Host: www.localhost.com:8080
 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/602.4.8 (KHTML, like Gecko) Version/10.0.3 Safari/602.4.8
 Connection: keep-alive
 Proxy-Connection: keep-alive
</code></pre>

<p>访问网址为<code>https://localhost</code>时，输出为：</p>

<pre><code> CONNECT www.localhost.com:443 HTTP/1.1
 Host: www.localhost.com
 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/602.4.8 (KHTML, like Gecko) Version/10.0.3 Safari/602.4.8
 Connection: keep-alive
 Proxy-Connection: keep-alive
</code></pre></li>
</ol>


<p>设置代理后，客户端发送HTTP请求之前需要先与Proxy通讯建立到目标主机的通讯隧道，命令消息格式为：</p>

<pre><code>method absoluteURI HTTP/1.1
</code></pre>

<p>使用<code>HTTP</code>协议时，使用<code>GET</code>命令发送请求，使用<code>HTTPS</code>协议时，使用<code>CONNECT</code>命令发送请求,后面跟着<a href="http://greenbytes.de/tech/webdav/rfc2616.html#general.syntax">absoluteURI</a>,再就是HTTP版本信息
第二行为<code>Host</code>头标示了需要访问的目标地址，根据<a href="[Request-URI](http://greenbytes.de/tech/webdav/rfc2616.html#request-uri"><code>HTTP/1.1</code></a>)版本规定，客户端和服务的必须支持<code>Host</code>头，但是默认协议情况下，host头只包含域名，不包含默认端口号(<code>HTTP(80)``HTTPS(443)</code>)</p>

<p>我们的proxy程序需要根据<code>absoluteURI</code>获取目标域名和端口，从而建立到目标主机的连接，示例代码如下：</p>

<pre><code>var buffer [1024]byte
n, err := conn.Read(buffer[:])
if err != nil {
    return
}
log.Println(string(buffer[:]))
_, line, err := bufio.ScanLines(buffer[:], true)
if err != nil {
    log.Println(err)
    return
}
var method string
var absUri string
_, err = fmt.Sscanf(string(line), "%s%s", &amp;method, &amp;absUri)
if err != nil {
    log.Println(err)
    return
}
absUrl, err := url.Parse(absUri)
if err != nil {
    log.Println(err)
    return
}
log.Printf("%+v", *absUrl)
var hostPort string
if absUrl.Scheme == "http" {
    if strings.Index(absUrl.Host, ":") == -1 {
        hostPort = absUrl.Host + ":80"
    } else {
        hostPort = absUrl.Host
    }
} else {
    hostPort = absUrl.Scheme + ":" + absUrl.Opaque
}
log.Println("hostPort", hostPort)
</code></pre>

<h3>建立连接</h3>

<ol>
<li>根据获取的目标地址+端口建立到目标主机的tcp连接</li>
<li><p>根据第一条请求的协议类型(HTTP/HTTPS),做不同应答处理：<br/>
 2.1 HTTP消息，直接转发给目标主机，不对客户端有应答<br/>
 2.2 HTTPS CONNECT消息，对客户端应答<code>200</code>消息：</p>

<pre><code> HTTP/1.1 200 Connection established\r\n\r\n
</code></pre></li>
<li><p>不间断进行消息转发，某一方连接异常后，关闭双方连接</p>

<pre><code> go io.Copy(conn, serverConn)
 io.Copy(serverConn, conn)
</code></pre></li>
</ol>


<h3>部署</h3>

<ol>
<li><a href="https://github.com/jintao-zero/golang-http-proxy">完整代码</a></li>
<li>编译生成二进制可执行文件，部署到海外VPS服务器，浏览器设置对应ip和端口后，即可翻墙</li>
</ol>


<h3>遗留问题</h3>

<p>1、转发功能基本实现，但是依然无法访问google、facebook等被GFW墙的网站
    我猜想是明文HTTP请求中<code>google、facebook</code>类的网站名被匹配到，出口连接被关闭，使用了ssh tunnel功能，将数据加密传输解决了这个问题</p>

<h3>参考</h3>

<ol>
<li><a href="http://greenbytes.de/tech/webdav/rfc2616.html#changes.from.1.0">HTTP1.0 VS HTTP1.1</a></li>
<li><a href="http://stackoverflow.com/questions/7155529/how-does-http-proxy-work">how does http proxy work?</a></li>
<li><a href="https://en.wikipedia.org/wiki/Proxy_server#Web_proxy_servers">Proxy server</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Protocol-buffers Proto3 翻译]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/12/protocol-buffers-proto3-fan-yi/"/>
    <updated>2017-03-12T18:09:36+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/12/protocol-buffers-proto3-fan-yi</id>
    <content type="html"><![CDATA[<ul>
<li><a href="#message">定义Message类型</a></li>
<li><a href="#type">标量值类型</a></li>
<li><a href="#default">默认值</a></li>
<li><a href="#enum">枚举</a></li>
<li><a href="#other_message">使用其他消息类型</a></li>
<li><a href="#nested">嵌套类型</a></li>
<li><a href="#update">更新消息类型</a></li>
<li><a href="#unknown">未知字段</a></li>
<li><a href="#any">Any</a></li>
<li><a href="#oneof">Oneof</a></li>
<li><a href="#maps">Maps</a></li>
<li><a href="#packages">包</a></li>
<li><a href="#services">服务</a></li>
<li><a href="#json">json</a></li>
<li><a href="#options">选项</a></li>
<li><a href="#protoc">生成代码</a></li>
</ul>


<p>这个指导文档如何使用protocol buffer语言结构化你的protocol buffer数据，包括<code>.proto</code>文件语法和如何根据<code>.proto</code>文件生成代码访问数据。本文主要描述<code>proto3</code>版本。  <br/>
本文是参考文档，如果需要例子的话可以访问，你选择语言相关的<a href="https://developers.google.com/protocol-buffers/docs/tutorials">入门指导</a></p>

<h2><a name="message"></a>Message定义</h2>

<p>一个简单例子。下面定义一个搜索请求消息格式，这个消息包含一个查询字符串，包含一个搜索结果页码，和每页包含搜索结果数。下面是该消息<code>.proto</code>文件：</p>

<pre><code>syntax = "proto3";

message SearchRequest {
    string query = 1;
    int32 page_number = 2;
    int32 result_per_page = 3;
}
</code></pre>

<ul>
<li>第一行说明正在使用<code>proto3</code>语法：如果不指定proto版本，protocol buffer编译器默认认为正在使用<code>proto2</code>。这行语句必须是第一条非空、非注释语句。</li>
<li><code>SearchRequest</code>消息包含三个字段。每个字段有都有一个名字和类型。</li>
</ul>


<!-- more -->


<h3>字段类型</h3>

<p>在上面的例子中，所有字段都是标量类型：两个整型（<code>page_number</code>和<code>result_per_page</code>）和字符串（<code>query</code>）。你也可以指定字段类型为组合类型，包含枚举或者其他类型。</p>

<h3>添加Tag标签</h3>

<p>如定义所见，每一个字段都有一个唯一的数字标签。这些标签用来在<a href="https://developers.google.com/protocol-buffers/docs/encoding">消息二进制格式</a>中标示相应字段，一旦消息类型得到使用，就不应该在修改字段标签。值在1到15之间的tag编码时只占用一个字节，一个字节包含了tag值和字段类型，更多信息可以参考<a href="https://developers.google.com/protocol-buffers/docs/encoding.html#structure">Protocol Buffer Encoding</a>。16到2047之间的标签占用两个字节。所以应该用1到15之间的标签标示经常使用的字段，并且给未来可能添加进来的频繁使用字段预留一些标签。</p>

<p>自小标签值为1，最大值为2的29次方-1，即536,870,911。tag值区间19000到19999（FieldDescriptor::kFirstReservedNumber 到 FieldDescriptor::kLastReservedNumber）是<code>Protocol Buffers</code>的保留值，如果在<code>.proto</code>文件中使用了这个范围内的值，编译器将会报警。</p>

<h3>指定字段规则</h3>

<p>消息类型可以为如下类型：</p>

<ul>
<li>单数形式： 一个正确格式的消息可以包含0个或者一个这样的字段（不能大于一个）</li>
<li>重复类型： 这种类型的字段可以在一个消息中重复多次（包括0次）。</li>
</ul>


<p><code>proto3</code>中，标量类型的<code>repeated</code>字段类型默认使用<code>packed</code>编码。</p>

<p>可以在<a href="Protocol%20Buffer%20Encoding">Protocol Buffer Encoding</a>查看关于编码的详细内容。</p>

<h3>添加更多Message类型</h3>

<p>一个<code>.proto</code>文件中可以定义多个消息类型。因此可以将相关消息类型定义在一个<code>.proto</code>文件中，比如可以在上面的proto文件添加一个<code>SearchResponse</code>消息类型：</p>

<pre><code>message SearchRequest {
    string query = 1;
    int32 page_number = 2;
    int32 result_per_page = 3;
}

message SearchResponse {
    ...
}
</code></pre>

<h3>添加注释</h3>

<p><code>.proto</code>文件中，使用C/C++风格<code>//</code>注释</p>

<pre><code>message SearchRequest {
    string query = 1;
    int32 page_number = 2;  // Which page number do we want?
    int32 result_per_page = 3;  // Number of results to return per page.
}
</code></pre>

<h3>保留字段</h3>

<p>当完整删除一个字段，或者注释掉字段，这种方式修改一个消息类型时，未来用户可能会复用之前的标签值。如果加载就版本<code>.proto</code>文件时，这种情况可能会引起数据冲突，程序问题或者其他异常情况。可以通过将已经删除字段的tag值或者字段名设置为<code>reserved</code>。如果将来有人用到这些保留值，编译器将会报错。</p>

<pre><code>message Foo {
    reserved 2, 15, 9 to 11;
    reserved "foo", "bar";
}
</code></pre>

<p>注意不可以在同一个<code>reserved</code>语句中同时标示tag和字段</p>

<h3>从.proto文件生成什么</h3>

<p>当用编译器处理已经编写好的<code>.proto</code>文件时，编译器会根据选择的编程语言类型生成代码，使用这些代码可以操作<code>.proto</code>文件中定义的消息类型，包括获取、设置字段值，序列化消息到输出流，从输入流中反序列化消息。</p>

<ul>
<li>C++，编译器为每个<code>.proto</code>文件生成一个<code>.h</code>和<code>.cc</code>文件，对于文件中定义的每个消息类型生成一个类</li>
<li>Java,编译器为每个消息类型生成一个<code>.java</code>文件，同时生成一个<code>Builder</code>类用于创建消息类实例</li>
<li>Python，编译器为每个消息类型生成一个包含静态描述符的模块，在python运行时，可以与原类型一起生成一个Python数据存取类</li>
<li>Go，编译器为<code>.proto</code>文件中的每个消息类型生成一个<code>.pb.go</code>文件</li>
<li>Ruby，编译器生成一个<code>.rb</code>文件包含一个ruby模块包括所有文件中国年定义的消息类型</li>
<li>JavaNano，编译器生成的内容与Java类似，但是没有<code>Builder</code>类型。</li>
<li>Objective-C，编译器为每一个<code>.proto</code>文件生成一个<code>pbobjc.h</code>和<code>pbobjc.m</code>文件，为每个消息类型生成一个类。</li>
<li>C#，编译器生成一个<code>.cs</code>文件，每个消息类型生成一个类。</li>
</ul>


<p>可以从<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">API reference</a>中了解更多API相关信息</p>

<h2><a name="type"></a>标量值类型</h2>

<p>一个标量消息字段可以用如下消息类型，这些类型可以使用在<code>.proto</code>文件中，表中列出了相应语言的数据类型：</p>

<p><img src="http://jintao-zero.github.io/images/proto-1.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-2.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-3.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-4.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-5.png" alt="" /></p>

<p>可以在<a href="https://developers.google.com/protocol-buffers/docs/encoding">Protocol Buffer Encoding</a>中查看上面类型如何编码。</p>

<h2><a name="default"></a>默认值</h2>

<p>解析消息时，如果编码消息没有包含某个元素值，那么消息对象中对应字段的值设置为字段类型的默认值。不同类型具有不同默认值：</p>

<ul>
<li>字符串类型，默认为空字符串</li>
<li>字节类型，默认为空字节</li>
<li>布尔型，默认为false</li>
<li>数字类型，默认为0</li>
<li>枚举类型，默认为枚举类型第一个值，这个值必须为0</li>
<li>message类型，字段不进行设置。具体值依赖不同语言的初始化操作。</li>
</ul>


<p>重复型字段默认值为空。</p>

<p>注意，对于标量类型字段，一个消息解析时不会标示某个字段是否是显示设置为默认值，比如一个布尔型字段值为<code>false</code>时，不会告诉消息使用者这个布尔字段值为<code>false</code>还是被设置的默认值<code>false</code>。定义消息类型时，要注意这点。如果一个布尔字段值为<code>false</code>时，程序表现为某种行为，如果你不希望默认情况下程序表现为这种行为的话，就需要注意。对于标量类型字段，如果设置为默认值，那么将不会对这个字段进行编码传输。 <br/>
<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">generated code guide</a>查看关于不同语言默认值如何工作的详细情况。</p>

<h2><a name="enum"></a>枚举</h2>

<p>定义消息类型时，可能需要设置字段值为一些预定义值，我们可以在消息定义文件中定义<code>enum</code>枚举类型，在<code>SearchRequest</code>中定义一个枚举类型<code>Corpus</code>：</p>

<pre><code>message SearchRequest {
    string query = 1;
    int32 page_number = 2;
    int32 result_per_page = 3;
    enum Corpus {
        UNIVERSAL = 0;
        WEB = 1;
        IMAGES = 2;
        LOCAL = 3;
        NEWS = 4;
        PRODUCTS = 5;
        VIDEO = 6;
    }
    Corpus corpus = 4;
}
</code></pre>

<p><code>Corpus</code>枚举类型的第一个常量值为0：protobuf中每一个枚举类型<code>必须</code>将第一个值定义为0，原因如下：</p>

<ul>
<li>必须有一个0值，这样可以使用0值为枚举类型默认值</li>
<li>0值必须为第一个值，这样是为了与<code>proto2</code>语法相兼容，<code>proto2</code>中以第一个枚举值为默认值</li>
</ul>


<p>可以为枚举值定义一个别名，需要在定义别名的枚举类型中设置<code>allow_alias</code>选项为<code>true</code>，否则编译器将会报错。</p>

<pre><code>enum EnumAllowingAlias {
    option allow_alias = true;
    UNKNOWN = 0;
    STARTED = 1;
    RUNNING = 1;
}   
enum EnumNotAllowingAlias {
    UNKNOWN = 0;
    STARTED = 1;
    // RUNNING = 1;  // Uncommenting this line will cause a         compile error inside Google and a warning message outside.
}
</code></pre>

<p>枚举类型常量值必须在32位整型之间。因为<code>enum</code>类型使用<a href="https://developers.google.com/protocol-buffers/docs/encoding">varint encoding</a>进行编码，值为负数的话，编码效率低，所以不推荐为负数。可以在消息定义体之中，或者之外定义<code>enum</code>枚举类型，可以在<code>.proto</code>文件任何为值使用这些枚举类型。 你可以通过<code>MessageType.EnumType</code>的方式使用在其他消息中定义的枚举类型。</p>

<p>当编译带有<code>enum</code>的<code>.proto</code>文件时，目标语言是<code>C++</code>或者<code>Java</code>时，产生的代码中包含<code>enum</code>定义，目标代码是<code>Python</code>时，产生一个<code>EnumDescriptor</code>类。</p>

<h2><a name="other_message"></a>使用其他消息类型</h2>

<p>可以使用其他消息类型定义字段。比如在<code>SearchResponse</code>消息中包含<code>Result</code>消息，<code>Result</code>消息可以定义在同一个<code>.proto</code>文件中。</p>

<pre><code>message SearchResponse {
    repeated Result results = 1;
}

message Result {
    string url = 1;
    string title = 2;
    repeated string snippets = 3;
}
</code></pre>

<h3>引入定义</h3>

<p>上面的例子中，<code>Result</code>定义在<code>SearchResponse</code>同样的<code>.proto</code>文件中，如果需要使用的消息类型定义在其他文件中消息类型。</p>

<p>通过import<code>.proto</code>文件使用<code>.proto</code>文件中的定义。在自己<code>.proto</code>文件顶部添加一行引入语句：</p>

<pre><code>import "myproject/other_protos.proto";
</code></pre>

<p>默认情况下，只能使用被直接<code>import</code>的文件中的消息定义。如果需要将<code>.proto</code>文件挪到一个新的位置去，可以放一个替代<code>.proto</code>文件到老的位置，在这个替代文件中使用<code>import public</code>将定义转移到新位置。例子：</p>

<pre><code>// new.proto
// All definitions are moved here


// old.proto
// This is the proto that all clients are importing.
import public "new.proto";
import "other.proto";

// client.proto
import "old.proto";
// You use definitions from old.proto and new.proto, but not other.proto
</code></pre>

<p>编译器在<code>-I/--proto_path</code>参数指定的目录中搜索被引入的<code>.proto</code>文件。如果没有设置这个参数，编译器在当前目录下查找，通常情况下，应该设置<code>--proto_path</code>为工程的根目录。</p>

<h3>使用proto2消息类型</h3>

<p>可以在<code>proto3</code>消息中引入<code>proto2</code>消息类型。但是proto2枚举类型不能在proto3语法中直接使用。</p>

<h2><a name="nested"></a>嵌套类型</h2>

<p>可以在消息类型中定义其他类型，下面的例子中，<code>Result</code>消息定义在<code>SearchResponse</code>消息中：</p>

<pre><code>message SearchResponse {
    message Result {
    string url = 1;
    string title = 2;
    repeated string snippets = 3;
    }
    repeated Result results = 1;
}  
</code></pre>

<p>如果想在<code>SearchResponse</code>消息以外使用<code>Result</code>消息，以<code>Parent.Type</code>格式使用：</p>

<pre><code>message SomeOtherMessage {
    SearchResponse.Result result = 1;
}
</code></pre>

<p>可以任意潜逃消息定义：</p>

<pre><code>message Outer {                  // Level 0
    message MiddleAA {  // Level 1
        message Inner {   // Level 2
            int64 ival = 1;
            bool  booly = 2;
        }
    }
    message MiddleBB {  // Level 1
        message Inner {   // Level 2
            int32 ival = 1;
            bool  booly = 2;
        }
    }
}
</code></pre>

<h2><a name="update"></a>更新消息类型</h2>

<p>如果已有消息不能满足新的需求，比如，需要增加一个新的字段，但是仍然使用根据老的消息格式产生的代码，对于protocol buffer来说这很容易完成，请记住如下的规则：</p>

<ul>
<li>不要修改当前字段的标签值</li>
<li>如果新增字段，任何根据老格式序列化的消息，都能够被根据新格式产生的代码进行解析。这种情况下，新增字段的值都会被设置为<a href="https://developers.google.com/protocol-buffers/docs/proto3#default">默认值</a>。新格式消息同样可以为老格式代码解析，新增字段将会被忽略。</li>
<li>可以删除字段，只要新消息格式中该字段标签值没有被使用。对于删除的字段，最好是对字段名称进行修改，添加<code>OBSOLETE_</code>字段或者设置tag为<a href="https://developers.google.com/protocol-buffers/docs/proto3#reserved">reserved</a>，这样未来不会错误使用该tag值。</li>
<li><code>int32</code>,<code>uint32</code>,<code>int64</code>,<code>uint64</code>,<code>bool</code>都是兼容的，意味着可以将字段从一种类型修改为另一种。如果解析时，从序列化数据中解析出的数据与响应字段类型不匹配，那么行为表现为从类型转换。</li>
<li><code>sint32</code>和<code>sint64</code>互相兼容，但是与其他整型类型不兼容。</li>
<li><code>string</code>和<code>bytes</code>互相兼容，只要bytes是UTF-8格式。</li>
<li>嵌套消息与<code>bytes</code>互相兼容，只要bytes包含该消息的编码</li>
<li><code>fixed32</code>与<code>sfixed32</code>，<code>fixed64</code>，<code>sfixed64</code>相兼容。</li>
<li><code>enum</code>与<code>int32</code>，<code>uint32</code>，<code>int64</code>，<code>uint64</code>相兼容</li>
</ul>


<h2><a name="unknown"></a>未知字段</h2>

<p>未知字段是正确格式数据，解析程序不能识别的字段。当旧格式解析程序解析新格式消息时，解析程序无法识别新格式消息中新增字段，认为为未知字段。</p>

<p><code>Proto3</code>实现可以解析这些未知字段，但是实现可能不支持保留这些字段。不应依赖这些未知字段。对于大部分实现，未知字段都是不可访问的，在序列化时，未知字段将会被忽略。这与<code>proto2</code>不同，未知字段也会被保留和序列化。</p>

<h2><a name="any"></a>Any</h2>

<p><code>Any</code>消息类型允许你使用某消息类型，而不需要引入该类型消息<code>.proto</code>文件。<code>Any</code>类型包含任意<code>bytes</code>类型序列化数据，<code>Any</code>类型包含一个URL，作为消息类型的唯一标识。引入<code>google/protobuf/any.proto</code>来使用<code>Any</code>类型。</p>

<pre><code>import "google/protobuf/any.proto";

message ErrorStatus {
    string message = 1;
    repeated google.protobuf.Any details = 2;
}
</code></pre>

<p>一个消息类型的默认URL为<code>type.googleapis.com/packagename.messagename</code>。</p>

<p>不同语言都会有运行时库去打包和解包Any类型值，Java中，Any类型字段会有<code>pack()</code>和<code>unpack()</code>方法访问，C++语言中有<code>PackFrom()</code>和<code>UnpackTo()</code>方法：</p>

<pre><code>// Storing an arbitrary message type in Any.
NetworkErrorDetails details = ...;
ErrorStatus status;
status.add_details()-&gt;PackFrom(details);

// Reading an arbitrary message from Any.
ErrorStatus status = ...;
for (const Any&amp; detail : status.details()) {
    if (detail.Is&lt;NetworkErrorDetails&gt;()) {
        NetworkErrorDetails network_error;
        detail.UnpackTo(&amp;network_error);
        ... processing network_error ...
    }
}
</code></pre>

<h2><a name="oneof"></a>Oneof</h2>

<p>如果消息中包含多个字段，同一时间最多设置一个字段，可以使用<code>oneof</code>特性来强制这种行为并且节省内存。</p>

<p>设置<code>oneof</code>中的任一字段将会清楚其他字段值。可以使用<code>case</code>或者<code>WhichOneof</code>方法查看当前哪个字段被设置。</p>

<h3>使用Oneof</h3>

<p>使用<code>oneof</code>关键词在<code>.proto</code>文件中定义：</p>

<pre><code>message SampleMessage {
    oneof test_oneof {
        string name = 4;
        SubMessage sub_message = 9;
    }
}
</code></pre>

<p>可以在oneof定义中添加除了<code>repeated</code>以外任意类型的字段。</p>

<p>产生的代码中，对于oneof中的字段拥有跟普通字段一样的获取、设置函数。还会获取一个特殊方法检查哪个值被设置。关于oneof更多API请参考<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">API reference</a>。</p>

<h3>Oneof 特性</h3>

<ul>
<li><p>设置oneof字段会清楚其他字段值。如果多次设置oneof字段值，只保留最后一次设置值。</p>

<pre><code>  SampleMessage message;
  message.set_name("name");
  CHECK(message.has_name());
  message.mutable_sub_message();   // Will clear name field.
  CHECK(!message.has_name());  
</code></pre></li>
<li>如果解析程序遇到oneof定义中的多个字段值，只有最后一个是有效的。</li>
<li>不能将一个<code>oneof</code>类型用于<code>repeated</code>中</li>
<li>反射对于oneof字段有效</li>
<li><p>使用C++时，防止非法访问内存。下面代码示例中，执行<code>set_name</code>时，<code>sub_message</code>已经被清除：</p>

<pre><code>  SampleMessage message;
  SubMessage* sub_message = message.mutable_sub_message();
  message.set_name("name");      // Will delete sub_message
  sub_message-&gt;set_...            // Crashes here
</code></pre>

<p>*使用C++ oneof <code>Swap</code>方法时，互换两个变量中设置的字段值：</p>

<pre><code>  SampleMessage msg1;
  msg1.set_name("name");  
  SampleMessage msg2;
  msg2.mutable_sub_message();
  msg1.swap(&amp;msg2);
  CHECK(msg1.has_sub_message());
  CHECK(msg2.has_name());
</code></pre></li>
</ul>


<h3>向后兼容问题</h3>

<p>添加或者删除oneof字段时要小心。如果检查oneof值时返回<code>None</code>或者<code>NOT_SET</code>时,意味着oneof没有被设置或者设置了oneof的一个其他版本。 因为没有办法区分一个未知字段是新加字段。</p>

<p>复用标签问题</p>

<ul>
<li>添加或者移除字段： 可能会丢失某些字段信息。</li>
<li>删除字段后又添加：</li>
<li>分拆或者合并：</li>
</ul>


<h2><a name="maps"></a>Maps</h2>

<p>protocol buffers提供一个映射类型定义字段：</p>

<pre><code>map&lt;key_type, value_type&gt; map_field = N;
</code></pre>

<p><code>key_type</code>可以为整型或者字符串类型（除了<code>floating point</code>和<code>bytes</code>以外的标量类型）。<code>value_type</code>可以为任何类型。</p>

<p>下面定义个map类型字段，每个<code>project</code>对应一个字符串：</p>

<pre><code>map&lt;string, Project&gt; projects = 3;
</code></pre>

<ul>
<li>Map字段不可以是<code>repeated</code></li>
<li>不依赖map顺序</li>
<li>生成<code>.proteo</code>文本格式时，maps以key排序。数字按照数字排序</li>
</ul>


<h3>向后兼容</h3>

<p>map语法等同于下面的消息定义，所以不支持map的protocol buffers实现仍然可以解析数据：</p>

<pre><code>message MapFieldEntry {
    key_type key = 1;
    value_type value = 2;
}

repeated MapFieldEntry map_field = N;
</code></pre>

<h2><a name="packages"></a>包</h2>

<p>可以在<code>.proto</code>文件中添加一个<code>package</code>可选项，防止消息类型命名冲突。</p>

<pre><code>package foo.bar;
message Open { ... }
</code></pre>

<p>可以在定义字段时使用包名：</p>

<pre><code>message Foo {
    ...
    foo.bar.Open open = 1;
    ...
}
</code></pre>

<p>根据不同语言产生不同的代码：</p>

<ul>
<li>C++中，产生的类包含在C++命名空间中，例如，<code>Open</code>将会出现在<code>foo::bar</code>命名空间</li>
<li>Java，<code>package</code>名被用来作为Java包名，除非在<code>.proto</code>文件中使用<code>option java_package</code>指定包名</li>
<li>Python，<code>package</code>指令被忽略，因为Python中包是按照在文件系统中的路径组织的</li>
<li>Go，<code>package</code>包名被用做Go代码包名，除非使用<code>option java_package</code>指定包名</li>
<li>Ruby，产生的代码包裹在Ruby命名空间，命名空间名称根据<code>package</code>参数包名生成</li>
<li>JavaNano，<code>package</code>参数名被用做产生代码包名</li>
<li>C#，<code>package</code>参数名被用来作为产生代码包名</li>
</ul>


<h3>包和命名查找</h3>

<p>protocol buffer中名字查找规则与C++类似：从内到外，逐层查找。<code>.foo.bar.Baz</code>意思是从最外层开始查找。</p>

<h2><a name="services"></a>定义服务</h2>

<p>如果在<code>RPC</code>中使用定义的消息类型，可以在<code>.proto</code>文件中定义一个RPC服务接口，protocol buffer编译器将会产生服务接口代码。下面定义一个服务函数，输入<code>SearchRequest</code>返回一个<code>SearchResponse</code>：</p>

<pre><code>service SearchService {
    rpc Search (SearchRequest) returns (SearchResponse);
}
</code></pre>

<p>最简单的使用protocol buffers的RPC系统是<a href="https://github.com/grpc/grpc-common">gRPC</a>：Google开发的一个语言和平台无关的开源RPC系统。使用一个protocol buffer编译器插件可以直接从<code>.proto</code>文件中直接生成相应的RPC代码。</p>

<h2><a name="json"></a>JSON映射</h2>

<p>Proto3支持JSON编码，方便系统间共享数据。下面的表格列入了Proto3消息类型与JSON对应关系。</p>

<p><img src="http://jintao-zero.github.io/images/proto-6.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-7.png" alt="" /></p>

<h2><a name="options"></a>Options选项</h2>

<p>单独的声明可以用一些options修饰。选项不会改变一个声明的总体意义，但是会影响在特殊上下文中的意义。完整options选项定义在<code>google/protobuf/descriptor.proto</code>。<br/>
一些options选项是文件级别的。一些选项是消息级别的。一些选项是字段级别的。<br/>
下面是一些经常是用的选项：</p>

<ul>
<li><p><code>java_package</code>(文件级别选项)：使用这个选项指定产生的java代码包名。如果没有使用这个参数显示指定包名，编译器将会使用<code>.proto</code>文件中package指定的包名作为java代码包名。但是proto包名生成的java包名并不符合Java包名倒序的惯例。如果不是生成Java代码，这个选项无效：</p>

<pre><code>  option java_package = "com.example.foo";
</code></pre></li>
<li><p><code>java_multiple_files</code>（文件级别选项）：指定产生的最外层Java类名。如果没有使用<code>java_outer_classname</code>参数，则使用<code>.proto</code>文件名作为最外层类名，文件名被转换成驼峰模式（<code>foo_bar.proto</code>生成<code>FooBar.java</code>）。如果不是生成java代码，下面选项无效：</p>

<pre><code>  option java_outer_classname = "Ponycopter";
</code></pre></li>
<li><p><code>optimize_for</code>（文件级别选项）：可以设置为<code>SPEED</code>，<code>CODE_SIZE</code>，<code>LITE_RUNTIME</code>。这个参数按照下面方式影响C++和Java代码生成：</p>

<ul>
<li><code>SPEED</code>(默认值)：protocol buffer编译器为消息类型生成序列化、反序列化和其他操作的相关代码。代码是高度优化的。</li>
<li><code>CODE_SIZE</code>：protocol buffer编译器生成最少类，依赖共享的，基于反射的代码去实现序列化、反序列化和其他操作。生成的代码与<code>SPEED</code>相比很小，但是更慢。生成的类的接口与<code>SPEED</code>模式一样。这个选项在拥有大量<code>.proto</code>文件不需要它们都很快。</li>
<li><p><code>LITE_RUNTIME</code>：编译器将生成类只依赖轻运行时库（<code>libprotobuf-lite</code>而不是<code>libprotobuf</code>）。轻运行时库比全库更小。这对于运行在限制平台（比如智能手机）的应用很有用。编译器将会生成跟<code>SPEED</code>选项一样的高效代码。生成的类只实现<code>MessageLite</code>接口，只提供了全<code>Message</code>接口方法的子集。</p>

<pre><code>  option optimize_for = CODE_SIZE;
</code></pre></li>
</ul>
</li>
<li><p><code>cc_enable_arenas</code>（文件级别选项）：为产生的C++代码使能<a href="https://developers.google.com/protocol-buffers/docs/reference/arenas">arena allocation</a></p></li>
<li><code>objc_class_prefix</code>（文件级别选项）：为产生的Objective-C代码添加前缀。没有默认值，应该按照Apple推荐的惯例设置此选项。</li>
<li><p><code>deprecated</code>（文件级别选项）：如果设置为<code>true</code>，指示这个字段已弃用。在大多数语言中，这个选项无效。Java代码中，这个选项变成<code>@Deprecated</code>注解。</p>

<pre><code>  int32 old_field = 6 [deprecated=true];
</code></pre>

<h2>自定义选项</h2>

Protocol Buffers also allows you to define and use your own options. This is an advanced feature which most people don&rsquo;t need. If you do think you need to create your own options, see the Proto2 Language Guide for details. Note that creating custom options uses extensions, which are permitted only for custom options in proto3.

<h2><a name="protoc"></a>生成代码</h2>

<p>使用<code>protoc</code>编译器根据<code>.proto</code>文件生成Java，Python，C++，Go，Ruby，JavaNano，Objective-C，或者C#代码。如果格式调用程序：</p>

<pre><code>  protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR --ruby_out=DST_DIR --javanano_out=DST_DIR --objc_out=DST_DIR --csharp_out=DST_DIR path/to/file.proto
</code></pre></li>
<li><p><code>IMPORT_PATH</code> 指定目录，在目录中查找<code>import</code>指令引入的文件。如果没有制定，使用当前目录。可以多次使用<code>--proto_path</code>参数指定多个路径；按照顺序查找。<code>-I=IMPORT_PATH</code>可以作为<code>--proto_path</code>的短形式</p></li>
<li>可以设置多个输出指令：

<ul>
<li><code>--cpp_out</code>在<code>DST_DIR</code>中生成C++代码。</li>
<li><code>--java_out</code>在<code>DST_DIR</code>中生成Java代码</li>
<li><code>--python_out</code>在<code>DST_DIR</code>中生成Python代码</li>
<li><code>--go_out</code>在<code>DST_DIR</code>中生成Go代码</li>
<li><code>--ruby_out</code>在<code>DST_DIR</code>中生成Ruby代码</li>
<li><code>--javanano_out</code>在<code>DST_DIR</code>中生成JavaNano代码</li>
<li><code>--objc_out</code>在<code>DST_DIR</code>中生成Objective-C代码</li>
<li><code>--csharp_out</code>在<code>DST_DIR</code>中生成C#代码</li>
<li><code>--php_out</code>在<code>DST_DIR</code>中生成PHP代码</li>
</ul>
</li>
<li>必须指定一个或者多个<code>.proto</code>文件作为参数。多个<code>.proto</code>文件可以同时指定。每个文件必须在<code>IMPORT_PATH</code>指定的路径中能够查找到</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Defer Panic 和Recover介绍和实践]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/07/golang-defer-panic-he-recoverjie-shao/"/>
    <updated>2017-03-07T11:08:41+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/07/golang-defer-panic-he-recoverjie-shao</id>
    <content type="html"><![CDATA[<p>Golang语言提供了正常的流程控制：if、for、switch和goto。还提供了go表达式创建goroutine协程。接下来将要介绍的是：<code>defer</code>、<code>panic</code>和<code>recovery</code></p>

<h2>defer</h2>

<p>defer表达式将一个函数放到一个list中。包裹defer函数的函数return时，这个defer函数将会被执行。<code>Defer</code>通常被用来简化资源清理动作。  <br/>
下面的代码片段，完成的功能是打开两个文件，将一个文件的内容拷贝到另外一个文件中：</p>

<pre><code>func CopyFile(dstName, srcName string) (written int64, err error) {
    src, err := os.Open(srcName)
    if err != nil {
        return
    }

    dst, err := os.Create(dstName)
    if err != nil {
        return
    }

    written, err = io.Copy(dst, src)
    dst.Close()
    src.Close()
    return
}
</code></pre>

<p>这个片段有bug。当调用os.Createa失败时，函数返回，但是没有将已经打开的源文件关闭。在第二个return语句之前执行src.Close可以修复bug。但是如果存在多个资源需要关闭或者多个return语句时，这样就比较繁琐。使用defer表达式，可以方便确保资源关闭：</p>

<pre><code>func CopyFile(dstName, srcName string) (written int64, err error) {
    src, err := os.Open(srcName)
    if err != nil {
        return
    }
    defer src.Close()

    dst, err := os.Create(dstName)
    if err != nil {
        return
    }
    defer dst.Close()

    return io.Copy(dst, src)
}
</code></pre>

<p>Defer表达式会提醒我们在打开文件之后关闭资源，并且确保无论多少return语句都会将资源关闭。<br/>
defer表达式的行为是简单和可预测的。下面有三条简单规则：</p>

<ol>
<li><p>注册defer函数时，计算deferred函数的参数
下面的例子中，defer表达式注册fmt.Println函数时确定了入参为0，下面函数执行return语句时，fmt.Println将会打印出0</p>

<pre><code>  func a() {
      i := 0
      defer fmt.Println(i)
      i++
      return
  }
</code></pre></li>
<li><p>注册函数按照先进后出的的顺序进行执行</p>

<pre><code> func b() {
     for i := 0; i &lt; 4; i++ {
         defer fmt.Print(i)
      }
 }
</code></pre>

<p> 打印结果是“3210”</p></li>
<li><p>Deferred函数可以读写包裹函数的命名返回值
下面的例子中，包裹函数返回后，deferred函数修改了命名返回值i。因此，包裹函数的返回值为2</p>

<pre><code>  func c() (i int) {
      defer func() { i++ }()
      return 1
  }
</code></pre>

<p>  这个特点可以用来修改函数返回的error返回值</p></li>
</ol>


<!-- more -->


<h2>Panic</h2>

<p><code>panic</code>是Golang内建函数，它会停止当前流程，开始<code>panicking</code>。当函数F调用panic时，F将会停止执行正常流程，执行F函数中注册的defer函数，然后F函数返回。对于F函数的调用函数，F函数表现为panic。F函数的调用函数按照F函数panic时的行为一样，执行deferred函数后返回，这样沿着沿着调用栈，直到最上层，之后程序崩溃。<code>Panic</code>可以由程序调用<code>panic</code>函数后触发，也会有运行时错误触发，比如slice越界访问。</p>

<h2>Recover</h2>

<p><code>recover</code>内建函数，可以用来从处于<code>panic</code>状态的goroutine中重新获取控制。<code>recover</code>只有在defer函数中才有用。在正常状态下，调用recover函数返回nil，不会有其他作用。如果当前goroutine处于<code>panicking</code>状态，那么调用<code>recover</code>函数，可以获取<code>panic</code>函数的参数，并终止<code>panicking</code>状态，进入正常状态。
下面的例子演示如何利用<code>defer</code>、<code>panic</code>和<code>recover</code>：</p>

<pre><code>package main

import "fmt"

func main() {
    f()
    fmt.Println("Returned normally from f.")
}

func f() {
    defer func() {
        if r := recover(); r != nil {
            fmt.Println("Recovered in f", r)
        }
    }()
    fmt.Println("Calling g.")
    g(0)
    fmt.Println("Returned normally from g.")
}

func g(i int) {
    if i &gt; 3 {
    fmt.Println("Panicking!")
        panic(fmt.Sprintf("%v", i))
    }
    defer fmt.Println("Defer in g", i)
    fmt.Println("Printing in g", i)
    g(i + 1)
}
</code></pre>

<p>程序输出如下：</p>

<pre><code>Calling g.
Printing in g 0
Printing in g 1
Printing in g 2
Printing in g 3
Panicking!
Defer in g 3
Defer in g 2
Defer in g 1
Defer in g 0
Recovered in f 4
Returned normally from f.
</code></pre>

<p>如果我们删除F函数中的defer函数，那么panic将不会得到恢复，一直到到goroutine调用栈的最顶层，终止程序执行。这样程序的输出如下：</p>

<pre><code>Calling g.
Printing in g 0
Printing in g 1
Printing in g 2
Printing in g 3
Panicking!
Defer in g 3
Defer in g 2
Defer in g 1
Defer in g 0
panic: 4

panic PC=0x2a9cd8
[stack trace omitted]
</code></pre>

<h2>实践</h2>

<p>使用<code>defer</code>和<code>recover</code>构造一个带recover的goroutine包裹函数</p>

<pre><code>func defaultPanicHandler(e interface{}) {
    fmt.Println(e)
    debug.PrintStack()
    // log here
}

var PanicHandler func(interface{}) = defaultPanicHandler

func withRecover(fn func()) {
    defer func() {
        handler := PanicHandler
        if handler != nil {
            if err := recover(); err != nil {
                handler(err)
            }
        }
    }()
    fn()
}

func main () {
    go withRecover(
        func () {
            fmt.Println("aaaa")
            panic("panicking")
        }
    )
    for {
        time.Sleep(3 * time.Second)
    }
}
</code></pre>

<p>参考：</p>

<ol>
<li><a href="https://blog.golang.org/defer-panic-and-recover">https://blog.golang.org/defer-panic-and-recover</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Reflect介绍]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/06/golang-reflectjie-shao/"/>
    <updated>2017-03-06T17:44:02+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/06/golang-reflectjie-shao</id>
    <content type="html"><![CDATA[<p>Golang <a href="https://golang.org/pkg/reflect/">reflect</a>包实现了运行时反射，允许程序管理任意类型对象。典型应用是使用<code>TypeOf</code>从静态类型<code>interface{}</code>中抽取动态类型信息。<br/>
使用<code>ValueOf</code>返回一个<code>Value</code>类型变量代表运行时数据。<br/>
<a href="https://golang.org/doc/articles/laws_of_reflection.html">The Laws of Reflection</a>介绍了Golang reflect机智中的几条规则：</p>

<h2>从interface反射到对象</h2>

<p>反射基本功能是用来检查interface变量中保存的<code>类型</code>和<code>数据</code>对。<a href="http://golang.org/pkg/reflect/">package reflect</a>中提供了两种类型：<a href="http://golang.org/pkg/reflect/#Type">Type</a>和<a href="http://golang.org/pkg/reflect/#Value">Value</a>。这两种类型提供了反问interface内部数据的机制。调用<code>reflect.TypeOf</code>和<code>reflect.ValueOf</code>函数分别返回<code>reflect.Type</code>和<code>reflect.Value</code>变量：</p>

<pre><code>ackage main

import (
"fmt"
"reflect"
)

func main() {
    var x float64 = 3.4
    fmt.Println("type:", reflect.TypeOf(x))
}
</code></pre>

<p>程序输出如下：</p>

<pre><code>type: float64
</code></pre>

<p><code>reflect.TypeOf</code>函数定义如下：</p>

<pre><code>// TypeOf returns the reflection Type of the value in the interface{}.
func TypeOf(i interface{}) Type
</code></pre>

<p>当我们调用<code>TypeOf(x)</code>时，x首先存在一个空interface中，之后作为参数，reflect.TypeOf解析参数获取实际类型。  <br/>
调用<code>Value(x)</code>时，从接口参数中获取实参值。</p>

<pre><code>var x float64 = 3.4
fmt.Println("value:", reflect.ValueOf(x))
</code></pre>

<p>打印结果如下：</p>

<pre><code>value: &lt;float64 Value&gt;
</code></pre>

<!-- more -->


<p></p>

<h2>从反射对象逆转回接口值</h2>

<p>给定一个<code>reflect.Value</code>对象，调用<code>Interface</code>方法可以恢复一个接口值。实际上，<code>Interface</code>方法将Value对象的值和类型信息打包到一个接口值中并返回：</p>

<pre><code>// Interface returns v's value as an interface{}.
func (v Value) Interface() interface{}
</code></pre>

<p>接上面的例子：</p>

<pre><code>y := v.Interface().(float64) // y will have type float64.
fmt.Println(y)
</code></pre>

<p>将反射对象v代表的float64值打印。</p>

<h2>如果修改一个反射对象，value必须可设置</h2>

<p><code>reflect.ValueOf</code>返回的Value值，并不是所有情况下都是可修改的。下面示例：</p>

<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
v.SetFloat(7.1) // Error: will panic.
</code></pre>

<p>执行代码时，报如下panic错误：</p>

<pre><code>panic: reflect.Value.SetFloat using unaddressable value
</code></pre>

<p>反射对象v不是可设置的。可设置是<code>reflect.Value</code>类型对象的一个属性，不是所有<code>Value</code>对象有此属性。<br/>
Value对象<code>CanSet</code>方法返回Value对象是否可以设置，在我们的例子中：</p>

<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
fmt.Println("settability of v:", v.CanSet())
</code></pre>

<p>将会输出：</p>

<pre><code>settability of v: false
</code></pre>

<p><code>Settability</code>是反射对象的一个属性，它反映的是是否能够修改创建这个反射对象的原对象。<code>Settability</code>由反射对象是否持有原对象决定。</p>

<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
</code></pre>

<p>当我们执行上面代码时，根据x生成一个interface对象作为是实参调用<code>reflect.Value</code>，interface对象保存的是x值拷贝。</p>

<pre><code>v.SetFloat(7.1)
</code></pre>

<p>上面代码修改的并不是x值。<br/>
对于函数调用，如果想修改实参，那必须传递实参地址到函数中。</p>

<pre><code>var x float64 = 3.4
p := reflect.ValueOf(&amp;x) // Note: take the address of x.
fmt.Println("type of p:", p.Type())
fmt.Println("settability of p:", p.CanSet())
</code></pre>

<p>上面代码，我们创建了一个x地址的反射对象，代码的输出如下：</p>

<pre><code>type of p: *float64
settability of p: false
</code></pre>

<p>反射对象p是不可设置的，我们不是要修改p，而是要修改p指向的x对象。  调用<code>Elem</code>方法可以获取p所指向的原对象：</p>

<pre><code>v := p.Elem()
fmt.Println("settability of v:", v.CanSet())
</code></pre>

<p>现在v对象就是可以修改的了：</p>

<pre><code>settability of v: true
</code></pre>

<p>现在v对象代表了原对象x，现在可以对v对象进行设置：</p>

<pre><code>v.SetFloat(7.1)
fmt.Println(v.Interface())
fmt.Println(x)
</code></pre>

<p>结果输出如下：<br/>
    7.1
    7.1</p>

<h3>Structs</h3>

<p>当我们拥有struct结构体对象地址时，可以对结构体对象进行修改<br/>
接下来是一个小的示例，使用结构体对象地址创建一个反射对象，然后使用reflect包中提供的结构体相关的方法，对结构体对象进行遍历和修改。</p>

<pre><code>type T struct {
    A int
    B string
}
t := T{23, "skidoo"}
s := reflect.ValueOf(&amp;t).Elem()
typeOfT := s.Type()
for i := 0; i &lt; s.NumField(); i++ {
    f := s.Field(i)
    fmt.Printf("%d: %s %s = %v\n", i,
    typeOfT.Field(i).Name, f.Type(), f.Interface())
}
</code></pre>

<p>上面代码的输出如下：</p>

<pre><code>0: A int = 23
1: B string = skidoo
</code></pre>

<p>因为s是可设置的反射对象，我们可以修改原对象的字段值：</p>

<pre><code>s.Field(0).SetInt(77)
s.Field(1).SetString("Sunset Strip")
fmt.Println("t is now", t)
</code></pre>

<p>结果如下：</p>

<pre><code>t is now {77 Sunset Strip}
</code></pre>

<h2>案例</h2>

<p>参考：</p>

<p>1、<a href="https://golang.org/pkg/reflect/">https://golang.org/pkg/reflect/</a>   <br/>
2、<a href="https://blog.golang.org/laws-of-reflection">https://blog.golang.org/laws-of-reflection</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang使用protobuf搭建rpc]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/02/03/golangshi-yong-protobufda-jian-rpc/"/>
    <updated>2017-02-03T19:55:10+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/02/03/golangshi-yong-protobufda-jian-rpc</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go并发模型之Context]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/18/gobing-fa-mo-xing-zhi-context/"/>
    <updated>2017-01-18T15:26:37+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/18/gobing-fa-mo-xing-zhi-context</id>
    <content type="html"><![CDATA[<p>Go语言中go和channel是开发高并发程序的基础。我们使用channel进行goroutine程序通讯，传送数据和控制信号，<a href="https://blog.golang.org/pipelines">Pipelines and Cancelation</a>向我们讲解了如何利用Done通道来向goroutine发送结束信号：</p>

<pre><code>func main() {
    var done = make(chan struct {})
    go func(done chan struct{}) {
        select {
        case &lt;- done:
            fmt.Println("receive exit signal")
        }
    }(done)

    done &lt;- struct {}{}
    time.Sleep(3 * time.Second)
}
</code></pre>

<p>在Go服务端，每一个请求都对应会有一个goroutine进行处理。处理函数通常又会开启另外的goroutine去访问后段服务，比如数据库和RPC服务。对应一个请求创建的这一系列的goroutine通常会需要访问请求相关的信息，比如终端用户名，授权token和请求的deadline等等。当一个请求被取消或者处理超时，与这个请求相关的一些列goroutine应该尽快退出，以便系统回收资源。<br/>
Go中<code>context</code>包提供了这样的功能，利用context包可以进行请求范围内的数据传递，发送请求信号和deadline查看。本文简单示例如何使用<code>context</code>包进行goroutine并发编程。</p>

<!-- more -->


<h2>Context</h2>

<p><code>Context</code>接口定义如下：</p>

<pre><code>// A Context carries a deadline, cancelation signal, and request-scoped values
// across API boundaries. Its methods are safe for simultaneous use by multiple
// goroutines.
type Context interface {
    // Done returns a channel that is closed when this Context is canceled
    // or times out.
    Done() &lt;-chan struct{}

    // Err indicates why this context was canceled, after the Done channel
    // is closed.
    Err() error

    // Deadline returns the time when this Context will be canceled, if any.
    Deadline() (deadline time.Time, ok bool)

    // Value returns the value associated with key or nil if none.
    Value(key interface{}) interface{}
}
</code></pre>

<p><code>Context</code>接口包含四个方法。<br/>
当Context被取消或者超时时，<code>Done</code>返回的通道将会被关闭。<br/>
<code>Err</code>函数返回关闭原因。  <br/>
<code>Deadline</code>返回Context将要被取消的时间，如果设置了超时时间的话,程序可以利用Deadline的返回值判断是否需要有必要开始操作，或者利用返回值设置I/O超时时间。<br/>
<code>Value</code>方法返回与key相对应的value数据。<br/>
<code>Context</code>接口是并发安全的。可以将同一个Context对象传递给任意goroutine。</p>

<h3>派生contexts</h3>

<p>context包提供函数从已存在Conext接口对象派生新接口对象。这些对象形成了一个树，当一个Context被取消时，所有从此Context对象派生的对象都被取消。<br/>
<code>Background</code>是任何Context树的根；Background永远不会被取消</p>

<pre><code>// Background returns an empty Context. It is never canceled, has no deadline,
// and has no values. Background is typically used in main, init, and tests,
// and as the top-level Context for incoming requests.
func Background() Context
</code></pre>

<p><code>WithCancle</code>和<code>WithTimeout</code>返回一个可以比parent Context更早取消的Context接口对象。</p>

<h3>WithCancle示例</h3>

<pre><code>func f1(ctx context.Context) {
    fmt.Println("f1 running...")
    withCancel, cancel := context.WithCancel(ctx)
    defer cancel()
    go f2(withCancel)
    // wait f2 to run
    time.Sleep(time.Second)
    fmt.Println("f1 cancel f2", )
    cancel()
    ticker := time.NewTicker(time.Second)
    for ; ;  {
        select {
        case &lt;- ctx.Done():
            fmt.Println("f1, parent call canceled", ctx.Err())
        case t := &lt;- ticker.C:
            fmt.Println("f1 running at ", t)
        }

    }
}

func f2(ctx context.Context)  {
    fmt.Println("f2 running...")
    ticker := time.NewTicker(time.Second)
    for ; ;  {
        select {
        case &lt;- ctx.Done():
            fmt.Println("f2, parent call canceled", ctx.Err())
            return
        case t := &lt;- ticker.C:
            fmt.Println("f2 running at", t)
        }
    }
}

func main()  {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    go f1(ctx)
    for {
        time.Sleep(5 * time.Second)
    }
    //cancel()
    //time.Sleep(5 * time.Second)
}
</code></pre>

<p><code>WithCancel</code>从parent派生出一个新Context接口对象和一个CancelFunc函数。调用CancelFunc函数时关闭<code>Done</code>返回的通道，通知子goroutine退出。</p>

<h3>WithDeadline</h3>

<p><code>WithDeadline</code> 返回一个Context接口对象，当设置的deadline时间到达时，<code>Context</code>对象<code>Done</code>可读。</p>

<pre><code>func main()  {
    n := time.Now()
    ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(5 * time.Second))
    defer cancel()
    ticker := time.NewTicker(1 * time.Second)
    for {
        select {
        case &lt;-ticker.C:
            fmt.Println("ticker timeout")
        case &lt;-ctx.Done():
            fmt.Println("context timeout", time.Since(n))
            return
        }
    }
}                                                                                                }
</code></pre>

<h3>WithTimeout示例</h3>

<p><code>WithTimeout</code>与<code>WithDeadline</code>类似，当设置的超时时间到达时，<code>Done</code>可读  <br/>
    func main()  {
        ctx, cancel := context.WithTimeout(context.Background(), 5 * time.Second)
        defer cancel()
        ticker := time.NewTicker(1 * time.Second)
        for {
            select {
            case &lt;-ticker.C:
                fmt.Println(&ldquo;ticker timeout&rdquo;)
            case &lt;-ctx.Done():
                fmt.Println(&ldquo;context timeout&rdquo;)
                return
            }
        }
    }</p>

<h3>WithValue示例</h3>

<p>使用<code>WithValue</code>来传递请求相关数据</p>

<pre><code>func WithValue(parent Context, key, val interface{}) Context
func main()  {
    ctx := context.WithValue(context.Background(), "test", "value")
    go func(ctx context.Context) {
        fmt.Println(ctx.Value("test"))
    }(ctx)
    time.Sleep(5 * time.Second)
}
</code></pre>

<h2>参考</h2>

<p>更多关于Go并发模型的讲解：<br/>
<a href="https://blog.golang.org/pipelines">Go Concurrency Patterns: Pipelines and cancellation</a>         <br/>
<a href="http://talks.golang.org/2012/concurrency.slide#1">Go Concurrency Patterns</a>         <br/>
<a href="http://blog.golang.org/advanced-go-concurrency-patterns">Advanced Go Concurrency Patterns</a>      <br/>
<a href="https://blog.golang.org/context">Go Concurrency Patterns: Context</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Go命令详解]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/13/golang-goming-ling-xiang-jie/"/>
    <updated>2017-01-13T19:17:12+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/13/golang-goming-ling-xiang-jie</id>
    <content type="html"><![CDATA[<h1>go命令</h1>

<p><a href="#compile">Compile packages and dependencies</a>    <br/>
<a href="#clean">Remove object files</a><br/>
<a href="#testing">Description of testing flags</a></p>

<p><code>Go</code>工具用来管理Go语音源代码。
使用：</p>

<pre><code>go command [arguments]
</code></pre>

<p>命令为：</p>

<pre><code>build       compile packages and dependencies
clean       remove object files
doc         show documentation for package or symbol
env         print Go environment information
fix         run go tool fix on packages
fmt         run gofmt on package sources
generate    generate Go files by processing source
get         download and install packages and dependencies
install     compile and install packages and dependencies
list        list packages
run         compile and run Go program
test        test packages
tool        run specified go tool
version     print Go version
vet         run go tool vet on packages
</code></pre>

<p>使用<code>go help [command]</code>查看命令相信信息。<br/>
更多topic：</p>

<pre><code>c           calling between Go and C
buildmode   description of build modes
filetype    file types
gopath      GOPATH environment variable
environment environment variables
importpath  import path syntax
packages    description of package lists
testflag    description of testing flags
testfunc    description of testing functions
</code></pre>

<p>使用<code>go help [topic]</code>查看topic帮助信息</p>

<!-- more -->


<h2><a name="compile"></a>编译包及其依赖</h2>

<p>使用：</p>

<pre><code>go build [-o output] [-i] [build flags] [packages]
</code></pre>

<p><code>Build</code>编译包，及其依赖，但是不进行安装。</p>

<p>如果输入的是一些.go文件，build认为是编译由这些文件组成的单独包。
当单独编译main包时，build将可执行程序写入输出文件，输出文件以列出的第一个.go源文件名称命名，或者以main包源文件所在的文件夹名称命名，Windows环境下，可执行成后后缀为.exe。</p>

<p>当编译多个包或者一个非main包，build命令只是编译这些包，丢弃结果文件，只是查看包是否能够编译成功。</p>

<p>编译包时，build忽略以<code>_test.go</code>为后缀的文件。</p>

<p><code>-o</code>参数，可以用来指定编译结果存放路径。<br/>
<code>-i</code>参数，设置将目标程序依赖的包进行安装。</p>

<p>build 标志是<code>build,clean,get,install,list,run,test</code>共享的：</p>

<pre><code>-a
    force rebuilding of packages that are already up-to-date.
-n
    print the commands but do not run them.
-p n
    the number of programs, such as build commands or
    test binaries, that can be run in parallel.
    The default is the number of CPUs available.
-race
    enable data race detection.
    Supported only on linux/amd64, freebsd/amd64, darwin/amd64 and windows/amd64.
-msan
    enable interoperation with memory sanitizer.
    Supported only on linux/amd64,
    and only with Clang/LLVM as the host C compiler.
-v
    print the names of packages as they are compiled.
-work
    print the name of the temporary work directory and
    do not delete it when exiting.
-x
    print the commands.

-asmflags 'flag list'
    arguments to pass on each go tool asm invocation.
-buildmode mode
    build mode to use. See 'go help buildmode' for more.
-compiler name
    name of compiler to use, as in runtime.Compiler (gccgo or gc).
-gccgoflags 'arg list'
    arguments to pass on each gccgo compiler/linker invocation.
-gcflags 'arg list'
    arguments to pass on each go tool compile invocation.
-installsuffix suffix
    a suffix to use in the name of the package installation directory,
    in order to keep output separate from default builds.
    If using the -race flag, the install suffix is automatically set to race
    or, if set explicitly, has _race appended to it.  Likewise for the -msan
    flag.  Using a -buildmode option that requires non-default compile flags
    has a similar effect.
-ldflags 'flag list'
    arguments to pass on each go tool link invocation.
-linkshared
    link against shared libraries previously created with
    -buildmode=shared.
-pkgdir dir
    install and load all packages from dir instead of the usual locations.
    For example, when building with a non-standard configuration,
    use -pkgdir to keep generated packages in a separate location.
-tags 'tag list'
    a list of build tags to consider satisfied during the build.
    For more information about build tags, see the description of
    build constraints in the documentation for the go/build package.
-toolexec 'cmd args'
    a program to use to invoke toolchain programs like vet and asm.
    For example, instead of running asm, the go command will run
    'cmd args /path/to/asm &lt;arguments for asm&gt;'.
</code></pre>

<p>上面列的参数标志接收以空格为分隔符的字符串列表。如果参数中包含空格，那么需要将参数用单引号或者双引号包裹。</p>

<p>使用<code>go help packages</code>查看更多关于包的信息，使用<code>go help gopath</code>查看更多关于编译和安装路径的信息，使用<code>go help c</code>查看更多关于Go和C/C++调用的帮助信息。</p>

<p><code>Build</code>依附于<code>go help gopath</code>中描述的惯例。并不是所有项目遵从惯例。使用不同构建惯例或者构建系统可能会选择使用更低层的构建工具如<code>go tool compile</code>和<code>go tool link</code>。</p>

<h2><a name="clean"></a>删除目标文件</h2>

<p>使用：</p>

<pre><code>go clean [-i] [-r] [-n] [-x] [build flags] [packages]
</code></pre>

<p>将包源代码路径中的目标文件删除。<code>go</code>命令通常在临时目录构建目标对象，所以<code>go clean</code>通常用来删除其他工具或者手动执行<code>go build</code>生成的结果文件。</p>

<p>特别的，clena命令将包源码路径下生成的如下文件删除：</p>

<pre><code>_obj/            old object directory, left from Makefiles
_test/           old test directory, left from Makefiles
_testmain.go     old gotest file, left from Makefiles
test.out         old test log, left from Makefiles
build.out        old test log, left from Makefiles
*.[568ao]        object files, left from Makefiles

DIR(.exe)        from go build
DIR.test(.exe)   from go test -c
MAINFILE(.exe)   from go build MAINFILE.go
*.so             from SWIG
</code></pre>

<p><code>-i</code>参数指定go clean 命令将go install命令安装的包文件或者二进制文件删除。 <br/>
<code>-n</code>参数指定go clean把要执行的删除命令打印，但是不实际执行。<br/>
<code>-r</code>参数指定go clean对于指定包的所有依赖进行go clean命令。<br/>
<code>-x</code>参数指定go clean在执行删除操作时将命令打印。</p>

<h2><a name="testing"></a>Description of testing flags</h2>

<pre><code>-bench regexp
    Run (sub)benchmarks matching a regular expression.
    The given regular expression is split into smaller ones by top-level '/', where each must match the corresponding part of a benchmark's identifier.
    By default, no benchmarks run. To run all benchmarks,
    use '-bench .' or '-bench=.'.

-benchmem
    Print memory allocation statistics for benchmarks.

-benchtime t
    Run enough iterations of each benchmark to take t, specified as a time.Duration (for example, -benchtime 1h30s).
    The default is 1 second (1s).

-blockprofile block.out
    Write a goroutine blocking profile to the specified file when all tests are complete.
    Writes test binary as -c would.

-blockprofilerate n
    Control the detail provided in goroutine blocking profiles by calling runtime.SetBlockProfileRate with n.
    See 'go doc runtime.SetBlockProfileRate'.
    The profiler aims to sample, on average, one blocking event every n nanoseconds the program spends blocked.  By default, if -test.blockprofile is set without this flag, all blocking events are recorded, equivalent to -test.blockprofilerate=1.

-count n
    Run each test and benchmark n times (default 1).
    If -cpu is set, run n times for each GOMAXPROCS value.
    Examples are always run once.

-cover
    Enable coverage analysis.

-covermode set,count,atomic
    Set the mode for coverage analysis for the package[s] being tested. The default is "set" unless -race is enabled, in which case it is "atomic".
    The values:
        set: bool: does this statement run?
        count: int: how many times does this statement run?
        atomic: int: count, but correct in multithreaded tests; significantly more expensive.
    Sets -cover.

-coverpkg pkg1,pkg2,pkg3
    Apply coverage analysis in each test to the given list of packages.
    The default is for each test to analyze only the package being tested.
    Packages are specified as import paths.
    Sets -cover.

-coverprofile cover.out
    Write a coverage profile to the file after all tests have passed.
    Sets -cover.

-cpu 1,2,4
    Specify a list of GOMAXPROCS values for which the tests or benchmarks should be executed.  The default is the current value of GOMAXPROCS.

-cpuprofile cpu.out
    Write a CPU profile to the specified file before exiting.
    Writes test binary as -c would.

-memprofile mem.out
    Write a memory profile to the file after all tests have passed.
    Writes test binary as -c would.

-memprofilerate n
    Enable more precise (and expensive) memory profiles by setting runtime.MemProfileRate.  See 'go doc runtime.MemProfileRate'.
    To profile all memory allocations, use -test.memprofilerate=1 and pass --alloc_space flag to the pprof tool.

-outputdir directory
    Place output files from profiling in the specified directory, by default the directory in which "go test" is running.

-parallel n
    Allow parallel execution of test functions that call t.Parallel. The value of this flag is the maximum number of tests to run simultaneously; by default, it is set to the value of GOMAXPROCS.
    Note that -parallel only applies within a single test binary.
    The 'go test' command may run tests for different packages in parallel as well, according to the setting of the -p flag
    (see 'go help build').

-run regexp
    Run only those tests and examples matching the regular expression.
    For tests the regular expression is split into smaller ones by top-level '/', where each must match the corresponding part of a test's identifier.

-short
    Tell long-running tests to shorten their run time.
    It is off by default but set during all.bash so that installing the Go tree can run a sanity check but not spend time running exhaustive tests.

-timeout t
    If a test runs longer than t, panic. The default is 10 minutes (10m).

-trace trace.out
    Write an execution trace to the specified file before exiting.

-v
    Verbose output: log all tests as they are run. Also print all text from Log and Logf calls even if the test succeeds.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang 通过http服务获取程序性能统计数据]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/08/golang-tong-guo-httpfu-wu-huo-qu-cheng-xu-xing-neng-tong-ji-shu-ju/"/>
    <updated>2017-01-08T22:55:07+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/08/golang-tong-guo-httpfu-wu-huo-qu-cheng-xu-xing-neng-tong-ji-shu-ju</id>
    <content type="html"><![CDATA[<p>Golang标准库<code>net/http/pprof</code>通过HTTP服务对外提供性能统计数据，以便<code>pprof</code>这样的可视化工具使用。</p>

<p>引入此<code>pprof</code>库向http服务注册路径处理函数。此库注册的http服务路径都是以<code>/debug/pprof</code>开头。</p>

<h2>使用方法</h2>

<h3>方式引入库</h3>

<pre><code>import _ "net/http/pprof"
</code></pre>

<h3>开启HTTP服务</h3>

<p>如果程序中已经运行了一个或者多个HTTP服务，那么就无需再开启HTTP服务，否则需要像如下代码片段，开启一个HTTP服务：</p>

<pre><code>go func() {
    log.Println(http.ListenAndServe("localhost:6060",   nil))
}()
</code></pre>

<p>其中地址也可以不绑定到localhost,可以选择监听所有端口,比如:</p>

<pre><code>go func() {
    log.Println(http.ListenAndServe(":6060",    nil))
}()
</code></pre>

<h3>获取性能数据</h3>

<p>1、查看堆栈性能数据</p>

<pre><code>go tool pprof http://localhost:6060/debug/pprof/heap
</code></pre>

<p>2、查看30s CPU性能数据</p>

<pre><code>go tool pprof http://localhost:6060/debug/pprof/profile
</code></pre>

<p>3、查看goroutine阻塞性能数据</p>

<pre><code>go tool pprof http://localhost:6060/debug/pprof/block
</code></pre>

<p>4、查看5s执行栈</p>

<pre><code>wget http://localhost:6060/debug/pprof/trace?seconds=5
</code></pre>

<p>5、查看所有可用性能数据</p>

<pre><code>浏览器打开  http://localhost:6060/debug/pprof/
</code></pre>

<p>参考：<br/>
<a href="https://golang.org/pkg/net/http/pprof/">Golang官博</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[golang创建、解压.tar.gz文件简单库]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/05/golangchuang-jian-,-jie-ya-dot-tar-dot-gzwen-jian/"/>
    <updated>2017-01-05T19:17:06+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/05/golangchuang-jian-,-jie-ya-dot-tar-dot-gzwen-jian</id>
    <content type="html"><![CDATA[<p>golang提供了<code>tar</code>包和<code>compress/gzip</code>包进行文件打包和压缩，但是没有函数同时进行打包和压缩，下面利用打包和压缩功能，实现一个简单的制作和解压.tar.gz文件的功能。</p>

<h2>tar打包功能</h2>

<p>利用tar中<code>Writer</code>和<code>Reader</code>可以实现将文件和文件夹进行打包的功能。</p>

<h3>打包</h3>

<p>创建目标文件</p>

<pre><code>f, err := os.Create(dstPath)
</code></pre>

<p>创建<code>Writer</code></p>

<pre><code>tw := tar.NewWriter(f)
</code></pre>

<p>循环遍历文件夹，写入Writer</p>

<pre><code>fileInfo, err := os.Stat(path)
if err != nil {
    return err
}
if fileInfo.Mode().IsRegular() {
    header, err := tar.FileInfoHeader(fileInfo, "")
    if err != nil {
        return err
    }
    header.Name = path
    if err = tw.WriteHeader(header); err != nil {
        return err
    }
    file, err := os.Open(path)
    if err != nil {
        return err
    }
    if _, err = io.Copy(tw, file); err != nil {
        return err
    }
}

if fileInfo.Mode().IsDir() {
    // tar each file and dir in the dir
    var file *os.File
    if file, err = os.Open(path); err != nil {
        return err
    }
    fileInfos, err := file.Readdir(0)
    if err != nil {
        return err
    }
    for _, info := range fileInfos {
        if err = tarPath(filepath.Join(path, info.Name()), tw); err != nil {
            return err
        }
    }
}
</code></pre>

<!-- more -->


<h3>解包</h3>

<p>打开源文件</p>

<pre><code>tarFile, err := os.Open(srcPath)
</code></pre>

<p>创建Reader</p>

<pre><code>tr := tar.NewReader(tarFile)
</code></pre>

<p>循环遍历解压文件</p>

<pre><code>for {
    hdr, err := tr.Next()
    if err == io.EOF {
        break
    }
    fullPath := filepath.Join(dstPath, hdr.Name)
    os.MkdirAll(filepath.Dir(fullPath), os.ModePerm)
    log.Println("fullPath", fullPath)
    file, err := os.Create(fullPath)
    if err != nil {
        return err
    }
    if _, err := io.Copy(file, tr); err != nil {
        return err
    }
    file.Close()
}
</code></pre>

<h2>Gzip压缩功能</h2>

<h3>压缩</h3>

<p>创建目标文件</p>

<pre><code>dstFile, err := os.Create(dstPath)
</code></pre>

<p>创建Writer</p>

<pre><code>gw := gzip.NewWriter(dstFile)
</code></pre>

<p>将源内容写入Writer</p>

<pre><code>if _, err = io.Copy(gw, srcFile); err != nil {
    return err
}
</code></pre>

<h3>解压</h3>

<p>打开源文件</p>

<pre><code>srcFile, err := os.Open(srcPath)
</code></pre>

<p>创建Reader</p>

<pre><code>gr, err := gzip.NewReader(srcFile)
</code></pre>

<p>进行解压</p>

<pre><code>if _, err = io.Copy(dstFile, gr); err != nil {
    return err
}
</code></pre>

<h2>.tar.gz文件</h2>

<p>将上面tar包进行打包和解包湿的的<code>io.Writer</code>和 <code>io.Reader</code>实参传入<code>gzip.Writer</code>和<code>gzip.Reader</code> ，即可将打包的目的文件进行压缩和解包时的源文件进行解压</p>

<h3>打包压缩</h3>

<pre><code>func Targz(srcPath, dstPath string) error {
dstFile, err := os.Create(dstPath)
if err != nil {
    return err
}
defer dstFile.Close()
gw := gzip.NewWriter(dstFile)
defer gw.Close()
tw := tar.NewWriter(gw)
defer tw.Close()
if err = tarPath(srcPath, tw); err != nil {
    dstFile.Close()
    os.Remove(dstPath)
    return err
}
return nil
</code></pre>

<p>}</p>

<h3>解压解包</h3>

<pre><code>srcFile, err := os.Open(srcPath)
if err != nil {
    return err
}
gr, err := gzip.NewReader(srcFile)
if err != nil {
    return err
}
tr := tar.NewReader(gr)
for {
    hdr, err := tr.Next()
    if err == io.EOF {
        break
    }
    fullPath := filepath.Join(dstPath, hdr.Name)
    os.MkdirAll(filepath.Dir(fullPath), os.ModePerm)
    file, err := os.Create(fullPath)
    if err != nil {
        return err
    }
    if _, err := io.Copy(file, tr); err != nil {
        return err
    }
    file.Close()
}
</code></pre>

<h3>备注</h3>

<p>完整源代码请参考<a href="https://github.com/jintao-zero/targz">targz</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Cpu性能优化]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/01/golang-cpuxing-neng-you-hua/"/>
    <updated>2017-01-01T17:18:20+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/01/golang-cpuxing-neng-you-hua</id>
    <content type="html"><![CDATA[<p>本文根据<a href="https://blog.golang.org/profiling-go-programs">Profiling Go Programs</a>文章，进行演示如何利用Golang性能工具进行cpu性能统计和优化。</p>

<h2>准备工作</h2>

<p>1、Golang编译运行环境。</p>

<pre><code>go version go1.7 darwin/amd64
</code></pre>

<p>2、下载<a href="https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/benchgraffiti/source-archive.zip">测试源码</a></p>

<pre><code>-rw-r--r-- 1 jintao staff 16594  1  1 16:58 havlak1.go
-rw-r--r-- 1 jintao staff 16597  1  1 16:58 havlak2.go
-rw-r--r-- 1 jintao staff 16832  1  1 16:58 havlak3.go
-rw-r--r-- 1 jintao staff 16905  1  1 16:58 havlak4.go
-rw-r--r-- 1 jintao staff 17501  1  1 16:58 havlak5.go
-rw-r--r-- 1 jintao staff  9467  1  1 16:58 havlak6.go
</code></pre>

<p>havlak1-6是源文件，以及优化后的源文件</p>

<h2>采集CPU性能数据</h2>

<p>优化程序之前，需要采集性能数据。多种方法可以使用，本文中采用的方法是引入<code>runtime/pprof</code>包，在代码文件main函数中添加如下代码片段:</p>

<pre><code>var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to file")

func main() {
    flag.Parse()
    if *cpuprofile != "" {
        f, err := os.Create(*cpuprofile)
        if err != nil {
          log.Fatal(err)
        }
        pprof.StartCPUProfile(f)
        defer pprof.StopCPUProfile()
    }
    ... 
</code></pre>

<p>利用flag包设置并解析cpuprofile参数，传入文件名，创建文件，调用<code>ppfof.StartCPUProfile</code>方法开始进行采样，并将采样结果保存在文件中，在程序返回之前调用<code>pprof.StopCPUProfile</code>方法确保所有采样数据刷新到结果文件中。</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ time ./havlak1 -cpuprofile=havlak1.prof
# of loops: 76000 (including 1 artificial root node)

real    0m21.768s
user    0m31.026s
sys 0m0.284s
</code></pre>

<p>产生性能文件havlak1.prof</p>

<!-- more -->


<h2>分析性能文件</h2>

<p><code>go tool pprof</code>是<a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools">Google&rsquo;s pprof C++ profiler</a>一个变种，利用go tool pprof命令读取分析性能文件:</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go tool pprof havlak1 havlak1.prof
Entering interactive mode (type "help" for commands)
(pprof)
</code></pre>

<p>输入<code>help</code>可以查看哪些可用命令，最常用是<code>top n</code>命令，查看前n个样本：</p>

<pre><code>(pprof) top
18750ms of 27430ms total (68.36%)
Dropped 95 nodes (cum &lt;= 137.15ms)
Showing top 10 nodes out of 80 (cum &gt;= 790ms)
      flat  flat%   sum%        cum   cum%
    3360ms 12.25% 12.25%     6790ms 24.75%  runtime.scanobject
    2890ms 10.54% 22.79%    14430ms 52.61%  main.FindLoops
    2470ms  9.00% 31.79%     2760ms 10.06%  runtime.mapaccess1_fast64
    1950ms  7.11% 38.90%     5140ms 18.74%  runtime.mapassign1
    1690ms  6.16% 45.06%     4080ms 14.87%  runtime.mallocgc
    1630ms  5.94% 51.00%     1630ms  5.94%  runtime.heapBitsForObject
    1580ms  5.76% 56.76%     3440ms 12.54%  main.DFS
    1250ms  4.56% 61.32%     1250ms  4.56%  runtime.memmove
    1140ms  4.16% 65.48%     1890ms  6.89%  runtime.greyobject
     790ms  2.88% 68.36%      790ms  2.88%  runtime/internal/atomic.Or8
(pprof)
</code></pre>

<p>启动性能分析时，Go程序每秒钟停止100次并对当前正在执行的goroutine调用栈进行采样。从上面数据可以看到，程序总执行时间为27430ms，采样top10函数一共占用18750ms（68.36%）。每行是一个函数的统计数据，前两列数据分别为采样时goroutine正在当前函数中的时间和占比，后两列为采样时此函数出现（正在执行或正在等待调用函数返回）的时间和占比。sum%列为前n行消耗时间之和对于总时间的占比。<code>main.FindLoops</code>函数正在执行的时间是2890ms占10.54%，在调用栈中出现的时间为14430ms占比为52.61%。<code>runtime.mapaccess1_fast64</code>执行的时间为2470ms占9.00%，在调用栈中出现的时间为2760ms占比为10.06%。使用-cum参数，按照第四第五列排序</p>

<pre><code>(pprof) top5 -cum
2.89s of 27.43s total (10.54%)
Dropped 95 nodes (cum &lt;= 0.14s)
Showing top 5 nodes out of 80 (cum &gt;= 14.43s)
  flat  flat%   sum%        cum   cum%
     0     0%     0%     22.79s 83.08%  runtime.goexit
     0     0%     0%     14.52s 52.93%  main.main
     0     0%     0%     14.52s 52.93%  runtime.main
     0     0%     0%     14.43s 52.61%  main.FindHavlakLoops
 2.89s 10.54% 10.54%     14.43s 52.61%  main.FindLoops
(pprof)
</code></pre>

<p>调用栈采样数据中关于函数间的调用关系可以有其他的有趣方式进行展现。比如<code>web</code>命令输出一个图片并用浏览器打开。<code>gv</code>命令写PostScript并在Ghostview中打开。</p>

<pre><code>(pprof) web
(pprof)
</code></pre>

<p>以下为图片部分截图： <br/>
<img src="http://jintao-zero.github.io/images/havlak1.png" alt="web" />
    图中每个方块对应一个单独函数，方块的大小与函数消耗的时间相对应。从X到Y的边显示X调用Y；边上的数字代表在被调用函数中消耗的时间。从图中我们可以发现在runtime.mapaccess1_fast64和runtime.mapassign1函数上消耗了较多时间。<br/>
    可以只显示包含某个函数的调用关系图：</p>

<pre><code>(pprof) web mapaccess
(pprof)
</code></pre>

<p><img src="http://jintao-zero.github.io/images/havlak1-mapaccess.png" alt="mapaccess" /><br/>
从上图我们可以发现主要是main.DFS和main.FindLoops函数调用了runtime.mapaccess<br/>
接下来重点分析<code>main.DFS</code>和<code>main.FindLoops</code>两个函数的时间消耗情况：</p>

<pre><code>(pprof) list DFS
Total: 27.43s
ROUTINE ======================== main.DFS in /Users/jintao/Project/opensource/benchgraffiti/havlak_new/havlak1.go
     1.58s      6.84s (flat, cum) 24.94% of Total
         .          .    235:   return false
         .          .    236:}
         .          .    237:
         .          .    238:// DFS - Depth-First-Search and node numbering.
         .          .    239://
      20ms       20ms    240:func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
     140ms      140ms    241:   nodes[current].Init(currentNode, current)
         .      310ms    242:   number[currentNode] = current
         .          .    243:
         .          .    244:   lastid := current
        1s         1s    245:   for _, target := range currentNode.OutEdges {
     160ms      1.31s    246:       if number[target] == unvisited {
      40ms      3.44s    247:           lastid = DFS(target, nodes, number, last, lastid+1)
         .          .    248:       }
         .          .    249:   }
     200ms      600ms    250:   last[number[currentNode]] = lastid
      20ms       20ms    251:   return lastid
         .          .    252:}
         .          .    253:
         .          .    254:// FindLoops
         .          .    255://
         .          .    256:// Find loops and build loop forest using Havlak's algorithm, which
(pprof)
</code></pre>

<p><code>list DFS</code> 会列出所有匹配DFS函数名的函数。从上面的代码我们发现耗时的语句分别在<code>242 246 247 250</code>行其中 247行是与DFS行数调用有关，其他三行都是与number变量有关，number是一个map数据结构，可以考虑改为采用slice，使用block number作为索引。</p>

<p>对文件进行修改，diff修改如下：</p>

<pre><code>240c240
&lt; func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
---
&gt; func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number []int, last []int, current int) int {
242c242
&lt;   number[currentNode] = current
---
&gt;   number[currentNode.Name] = current
246c246
&lt;       if number[target] == unvisited {
---
&gt;       if number[target.Name] == unvisited {
250c250
&lt;   last[number[currentNode]] = lastid
---
&gt;   last[number[currentNode.Name]] = lastid
271c271
&lt;   number := make(map[*BasicBlock]int)
---
&gt;   number := make([]int, size)
287c287
&lt;       number[bb] = unvisited
---
&gt;       number[bb.Name] = unvisited
315c315
&lt;               v := number[nodeV]
---
&gt;               v := number[nodeV.Name]
</code></pre>

<p>测试修改后的cpu性能：</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go build havlak2.go
MacBook-Pro-2:havlak_new jintao$ time ./havlak2 -   cpuprofile=havlak2.prof
# of loops: 76000 (including 1 artificial root node)

real    0m11.685s
user    0m19.647s
sys 0m0.268s
</code></pre>

<p>再次使用go tool profile工具查看topn数据：</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go tool pprof havlak2 havlak2.prof
Entering interactive mode (type "help" for commands)
(pprof) top
11460ms of 16610ms total (68.99%)
Dropped 92 nodes (cum &lt;= 83.05ms)
Showing top 10 nodes out of 87 (cum &gt;= 540ms)
   flat  flat%   sum%        cum   cum%
2950ms 17.76% 17.76%     5630ms 33.90%  runtime.scanobject
1500ms  9.03% 26.79%     4100ms 24.68%  runtime.mallocgc
1260ms  7.59% 34.38%     1260ms  7.59%  runtime.heapBitsForObject
1250ms  7.53% 41.90%     8700ms 52.38%  main.FindLoops
 920ms  5.54% 47.44%     1450ms  8.73%  runtime.greyobject
 920ms  5.54% 52.98%     2120ms 12.76%  runtime.mapassign1
 770ms  4.64% 57.62%      780ms  4.70%  runtime.heapBitsSetType
 760ms  4.58% 62.19%      760ms  4.58%  runtime.memmove
 590ms  3.55% 65.74%     1500ms  9.03%  runtime.makemap
 540ms  3.25% 68.99%      540ms  3.25%  runtime/internal/atomic.Or8
(pprof)
</code></pre>

<p>从上面可以看到<code>main.DFS</code>已经不在topn列表上，其他函数的时间也在显著下降。现在累计有24.68%的时间用在分配内存和垃圾回收（<code>runtime.mallocgc</code>）。下面需要使用进行内存性能优化。</p>

<h2>参考</h2>

<p>1、<a href="https://blog.golang.org/profiling-go-programs">Golang官方博客</a><br/>
2、<a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools">C++ pprof</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang日期转化处理]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/10/30/golangri-qi-zhuan-hua-chu-li/"/>
    <updated>2016-10-30T22:13:12+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/10/30/golangri-qi-zhuan-hua-chu-li</id>
    <content type="html"><![CDATA[<p>golang中time包提供了时间操作函数。</p>

<h2>获取时间</h2>

<pre><code>type Time struct {
    // contains filtered or unexported fields
}

func Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time
func Now() Time
</code></pre>

<p>一个Time结构体代表一个纳米精度的时间实例。now函数可以获取当前时间：</p>

<pre><code>now := time.Now()
fmt.Println(now)
</code></pre>

<p>结果如下：</p>

<pre><code>2016-11-27 22:46:17.666418725 +0800 CST 
</code></pre>

<!-- more -->


<h2>格式化时间</h2>

<pre><code>func (t Time) Format(layout string) string
</code></pre>

<p>Format方法可以按照layout定义的格式格式化时间字符串。<br/>
Golang中以2006 01 02 03 04 05 分别定义年、月、日 时、分、秒字段，03的24表示法为15。<br/>
比如将当前时间格式化为YYYY-mm-dd hh:MM:ss，则layout为<code>2006-01-02 15:04:05</code></p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
</code></pre>

<p> 输出为：</p>

<pre><code>2016-11-27 22:56:40
</code></pre>

<p>控制精度的方法为在秒后面加0, 000、000000、000000000分别代表毫秒、微秒、纳秒：</p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
fmt.Println(now.Format("2006-01-02 15:04:05.000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000000"))
</code></pre>

<p>输出：</p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
fmt.Println(now.Format("2006-01-02 15:04:05.000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000000"))
</code></pre>

<h2>解析时间</h2>

<pre><code>func Parse(layout, value string) (Time, error)
func ParseInLocation(layout, value string, loc *Location) (Time, error)
</code></pre>

<p>Parse函数将格式化字符串解析为一个时间实例。<code>layout</code>定义了时间字符串的表现格式，比如：</p>

<pre><code>Mon Jan 2 15:04:05 -0700 MST 2006
</code></pre>

<p>当待解析时间字符串中没有时区时，<code>Parse</code>默认按照<code>UTC</code>时区解析时间。<code>ParseInLocation</code>按照loc参数指定的的location解析时间。</p>

<h2>定时器</h2>

<p>定时器通过<code>NewTimer</code>或者<code>AfterFunc</code>创建，用AfterFunc创建的定时器超时后，在定时器goroutine中调用func函数，其他定时器则通过C通道发送一个时间对象。</p>

<pre><code>type Timer struct {
    C &lt;-chan Time
    // contains filtered or unexported fields
}

func AfterFunc(d Duration, f func()) *Timer  
func NewTimer(d Duration) *Timer
</code></pre>

<p>定时器在使用过程中需要注意<code>Reset</code>和<code>Stop</code>方法的使用：</p>

<pre><code>func (t *Timer) Stop() bool
</code></pre>

<p>Stop方法用来停止定时器触发。停止定时器则返回true，如果定时器已经超时或者已经被停止则返回false。Stop方法不关闭定时器中的channel。<br/>
为了防止调用Stop方法后，定时器仍然触发，需要检查方法返回值并且读取定时器时间channel，代码片段：</p>

<pre><code>if !t.Stop() {
    &lt;-t.C
}

func (t *Timer) Reset(d Duration) bool
</code></pre>

<p><strong>需要特别注意的是，不要并发执行上面的代码。</strong></p>

<p>Reset修改定时器的超时时间为d。修改成功则返回true，如果定时器已经超时或者被停止则返回false。</p>

<pre><code>func (t *Timer) Reset(d Duration) bool
</code></pre>

<p>为了重复一个已经激活的定时器，需要先调用定时器<code>Stop</code>方法，如果定时器已经超时，则例如一下代码片段，先读取channel中的时间：</p>

<pre><code>if !t.Stop() {
    &lt;-t.C
}
t.Reset(d)
</code></pre>

<p><strong>需要特别注意的是，不要并发执行上面的代码。</strong>  <br/>
在读取通道和定时器超时之间存在竞态条件，所以几乎不可能正确使用Reset方法的返回值。Reset方法应该总是与Stop方法一起使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grep命令]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/10/05/grepming-ling/"/>
    <updated>2016-10-05T20:48:14+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/10/05/grepming-ling</id>
    <content type="html"><![CDATA[<h1>grep命令</h1>

<p>grep, egrep, fgrep, zgrep, zegrep, zfgrep 文件模式搜索</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]] [-e pattern] [-f file] [--binary-files=value] [--color[=when]]
</span><span class='line'>          [--colour[=when]] [--context[=num]] [--label] [--line-buffered] [--null] [pattern] [file ...]</span></code></pre></td></tr></table></div></figure>


<p>grep搜索输入文件，输出匹配一个或者多个模式的文件行。通常情况，不包括结尾换行符的文件行匹配指定模式中的表达式即为匹配成功。空表达式匹配所有行。匹配行将会打印到标准输出。<br/>
grep命令用于简单模式和基本正则表达式（BRES）；egrep命令可以处理扩展正则表达式。查看re_format(7）关于正则表达式的详细信息。fgre较grep和egrep更快，但是只能处理固定模式（比如，它不能解析正则表达式）。匹配模式可以由一行或者多行组成，以便于匹配输入内容的一部分。<br/>
zgrep，zegrep，zfgrep分别与grep，egrep，fgrep功能类似，只是可以接收由compress或者gzip压缩工具压缩过的文件作为输入。</p>

<!-- more -->


<h2>参数</h2>

<pre><code>-A num, --after-context=num
</code></pre>

<p>打印匹配行后面的num行文本，与-B和-C选项功能类似</p>

<pre><code>-a, --text
</code></pre>

<p>将所有输入当作文本文件处理。如果文件包含二进制字符，grep简单打印<code>Binary file ... matches</code>。使用这个参数强制grep输出匹配行。</p>

<pre><code>-B num, --before-context=num
</code></pre>

<p>打印每个匹配行前面num行文本。</p>

<pre><code>-b, --byte-offset  
</code></pre>

<p>打印匹配模式在文件中的字节偏移数</p>

<pre><code>-C[num, --context=num]
</code></pre>

<p>指定打印匹配行前后文本行数。默认为2，相当于设置-A 2 -B 2</p>

<pre><code>-c, --count
</code></pre>

<p>只向标准输出打印匹配文本行的行数</p>

<pre><code>--colour=[when, --color=[when]]
</code></pre>

<p>打印时，用GREP_COLOR环境变量里面保存的颜色设置标记匹配到的模式</p>

<pre><code>-D action, --devices=action
</code></pre>

<p>为devices，FIFOS和sockets指定动作。默认动作是读，把他们当作普通文件处理。如果action指定为skip，这些设备将会被跳过。</p>

<pre><code>-d action, --directories=action
</code></pre>

<p>为目录指定特殊的动作。默认是读动作，把目录当作普通文件处理。<code>skip</code>动作是默默跳过目录，<code>recurse</code>动作是循环读取目录。</p>

<pre><code>-E, --extended-regexp
</code></pre>

<p>按照扩展正则表达式来解析pattern模式（强制grep表现为egrep）</p>

<pre><code>-e pattern, --regexp=pattern
</code></pre>

<p>指定匹配用的模式。可以多次使用-e选项来指定多个模式串</p>

<pre><code>--exclude
</code></pre>

<p>使用此选项将匹配参数模式的文件去除，不尽兴模式串的匹配。</p>

<pre><code>--exclude-dir
</code></pre>

<p>将某些目录去除，不进行模式匹配</p>

<pre><code>-F, --fixed-strings
</code></pre>

<p>将模式解析为固定字符串集合（强制grep为fgrep）</p>

<pre><code>-f file, --file=file
</code></pre>

<p>从file文件中读取匹配用的模式串</p>

<pre><code>-G, --basic-regexp
</code></pre>

<p>按照基本正则表达式解析模式串（强制grep工作模式为传统grep）</p>

<pre><code>-H
</code></pre>

<p>在匹配文本行前头打印所属文件名</p>

<pre><code>-h, --no-filename
</code></pre>

<p>在匹配文本行前头不打印文件名</p>

<pre><code>--help
</code></pre>

<p>打印简要帮助信息</p>

<pre><code>-I
</code></pre>

<p>忽略二进制文件</p>

<pre><code>-i, --ignore-case
</code></pre>

<p>进行大小无关匹配，grep默认是大小相关</p>

<pre><code>--include
</code></pre>

<p>指定符合文件名模式的文件进行模式匹配</p>

<pre><code>--include-dir
</code></pre>

<p>如果指定-R参数，只有符合模式的目录才进行模式匹配</p>

<pre><code>-J, --bz2decompress
</code></pre>

<p>进行文本匹配之前，解压bzip压缩过的文件</p>

<pre><code>-L, --files-without-match
</code></pre>

<p>只打印不包含指定模式文本行文件的文件名</p>

<pre><code>-l, --files-with-matches
</code></pre>

<p>只打印包含指定模式文本行文件的文件名，不打印文本行</p>

<pre><code>--mmap
</code></pre>

<p>使用mmap代替read来读取输入，在某些环境下能够达到更高性能，也可能引起为定义行为</p>

<pre><code>-m num, --max-count=num
</code></pre>

<p>达到<code>num</code>处匹配后，停止继续读取输入</p>

<pre><code>-n, --line-number
</code></pre>

<p>输出结果时，每行前面打印匹配行在文件中的行数。</p>

<pre><code>--null
</code></pre>

<p>打印文件名时，后面跟零字节</p>

<pre><code>-O
</code></pre>

<p>8888</p>

<pre><code>-o, --only-matching
</code></pre>

<p>只打印每行中匹配的部分</p>

<pre><code>-p
</code></pre>

<p>如果指定<code>-R</code>选项，不跟随符号链接，这个是默认选项</p>

<pre><code>-q, --quiet, --silent
</code></pre>

<p>安静模式：压制正常输出。grep程序只是搜索文件，直到达到一个匹配，使grep命令更少的花销。</p>

<pre><code>-R, -r, --recursive
</code></pre>

<p>循环搜索子文件夹</p>

<pre><code>-S
</code></pre>

<p>如果指定<code>-R</code>参数，所有符号连接也会参与匹配，默认不匹配符号连接</p>

<pre><code>-s, --no-messages
</code></pre>

<p>安静模式。不存在或者不可达的文件将被忽略</p>

<pre><code>-U, --binary
</code></pre>

<p>搜索二进制文件，但是不尝试打印他们</p>

<pre><code>-V, --version
</code></pre>

<p>打印版本信息</p>

<pre><code>-v, --invert-match
</code></pre>

<p>搜索不匹配给定模式的行文本</p>

<pre><code>-w, --word-regexp
</code></pre>

<p>表达式被当做是一个单词来进行匹配（形如被<code>[[:&lt;:]]</code>和<code>[[:&gt;:]]</code>包裹）</p>

<pre><code>-x, --line-regexp
</code></pre>

<p>只有一整行匹配给定模式才算成功匹配行</p>

<pre><code>-Z, -z, --decompress
</code></pre>

<p>强制grep像zgrep</p>

<pre><code>--binary-files=value
</code></pre>

<p>控制搜索和打印二进制文件。选项<code>binary</code>，默认选项，搜索但是不打印；<code>without-match</code>:不搜索二进制文件；<code>text</code>：将二进制文件视为文本文件</p>

<pre><code>--context[=num]
</code></pre>

<p>打印匹配行前后文本，默认是2行</p>

<pre><code>--line-buffered
</code></pre>

<p>强制输出行缓存。</p>

<h2>例子</h2>

<p>搜索一个文件中的单词</p>

<pre><code>grep 'patricia' myfile
</code></pre>

<p>所有行首包含<code>.Pp</code>的行</p>

<pre><code>grep '^\.Pp' myfile
</code></pre>

<p>搜索不包含<code>foo</code>和<code>bar</code>的所有行</p>

<pre><code>grep -v -e 'foo' -e 'bar' myfile
</code></pre>

<p>扩展正则表达式</p>

<pre><code>egrep '19|20|25' calendar
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MapReduce WordCount实例]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/03/06/mapreduce-wordcountshi-li/"/>
    <updated>2016-03-06T15:08:34+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/03/06/mapreduce-wordcountshi-li</id>
    <content type="html"><![CDATA[<p>搭建开发环境，开发mapreduce job程序，部署mapreduce程序。</p>

<h1>开发环境搭建</h1>

<p>开发mapreduce程序的环境有可能与运行环境不同，我是Windows环境上开发mapreduce job程序，编译没有错误后，打包放到hadoop集群中调试和运行。这样就要求开发环境依赖的jar包，在hadoop集群环境中存在并且版本一致。<br/>
我的开发环境是Windows＋eclipse＋maven，hadoop集群环境上部署的版本号为：</p>

<pre><code>jintao@node0:~/Project$ hadoop  version
Hadoop 2.7.1
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a
Compiled by jenkins on 2015-06-29T06:04Z
Compiled with protoc 2.5.0
From source with checksum fc0a1a23fc1868e4d5ee7fa2b28a58a
This command was run using /usr/local/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar
</code></pre>

<p>maven配置文件pom.xml的配置如下：</p>

<pre><code>&lt;dependencies&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
    &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
    &lt;version&gt;2.7.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>

<p>maven工程会自动将依赖的jar下载到build path中。<br/>
你也可以建立一个普通java工程，手动将依赖的jar添加到build path中，这样需要找依赖的jar，比较麻烦，但是可以让新手更快的了解mapreduce相关类分布情况。</p>

<!-- more -->


<h1>开发mapreduce job程序</h1>

<p>一般情况下，一个job包含一个map类和一个reduce类，但是也可以只有一个类，或者都不包含。本文例子中的WordCount是mapreduce程序开发的helloworld程序，包含map和reduce类，通过WordCount我们可以了解mapreduce程序开发的基本框架。</p>

<h2>Mapper</h2>

<p>map程序的基类为：</p>

<pre><code>@InterfaceAudience.Public
@InterfaceStability.Stable
public class Mapper&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; extends Object
</code></pre>

<p>Maps将输入的key/value对处理并输出一个key/value形式的中间结果集。</p>

<p>Maps是一个个独立的任务线程分别处理不同的记录集合，输出中间结果集。输出结果集的类型不一定与初始的输入记录相同。一个输入key/value对，有可能输出零个或多个key/value结果对。</p>

<p>Hadoop Map-Reduce框架对于job的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html">InputFormat</a>输入数据产生的每个<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputSplit.html">InputSplit</a>派生一个map任务。Mapper的具体实现可以通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/JobContext.html#getConfiguration(">JobContext.getConfiguration()</a>)获取job的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">Configuration配置</a>。</p>

<p>框架首先调用Mapper实现类的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#setup(org.apache.hadoop.mapreduce.Mapper.Context">setup(org.apache.hadoop.mapreduce.Mapper.Context)</a>)，然后对于对于获取的每一个输入记录，调用map方法进行处理。最后调用<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#cleanup(org.apache.hadoop.mapreduce.Mapper.Context">cleanup(org.apache.hadoop.mapreduce.Mapper.Context)</a>)。</p>

<p>框架将与某个key相关的所有value值形成一组，传给Reducer来产生最后结果。通过指定key比较类，用户可以控制key/value的排序和分组。</p>

<p>Mapper的输出结果对于每个Reducer进行分片。通过实现一个特定的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Partitioner.html">Partitioner</a>，用户可以控制keys分片到Reducer。</p>

<p>视情况，通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Job.html#setCombinerClass(java.lang.Class">Job.setCombinerClass(Class)</a>)用户可以指定一个combiner，combiner可以在Mapper本地对输出结果进行聚合，这样可以减少从Mapper传输到Reducer的数据量。</p>

<p>通过对Configuration程序可以指定是否并且如何对Mapper结果进行压缩。</p>

<p>如果reducer个数为0，那么不会对Mapper的结果不对结果进行排序，并且直接输出到<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/OutputFormat.html">OutputFormat</a>。<br/>
WordCount对应Mapper实现类如下：</p>

<pre><code>public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
    private static Logger logger = Logger.getLogger(WordCountMapper.class);

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException{
        StringTokenizer iTokenizer = new StringTokenizer(value.toString());
        while (iTokenizer.hasMoreTokens()) {
            word.set(iTokenizer.nextToken());
            context.write(word, one);
        }
    }   
}
</code></pre>

<p>应用也可以重写<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#run(org.apache.hadoop.mapreduce.Mapper.Context"> run(org.apache.hadoop.mapreduce.Mapper.Context)</a>)来更多的控制map处理，比如multi-threaded Mapper。</p>

<h2>Reducer</h2>

<p>Reducer的基类定义如下：</p>

<pre><code>@Checkpointable
@InterfaceAudience.Public
@InterfaceStability.Stable
public class Reducer&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; extends Object
</code></pre>

<p>Reducer将Mapper输出的中间结果集处理输出最终结果集。<br/>
Reducer实现类可以通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/JobContext.html#getConfiguration("> JobContext.getConfiguration()</a>)获取job的配置信息<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">Configuration</a>。<br/>
Reducer主要有三个步骤：</p>

<ol>
<li><p>Shuffle<br/>
 Reducer使用Http从个Mapper拷贝传输中间结果集到本地。</p></li>
<li><p>Sort<br/>
 框架将从不同Mapper传输过来的结果集按照key进行合并排序。</p></li>
<li>Reduce
 在这一阶段，对于每个&lt;key, (collection of values)>调用<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html#reduce(KEYIN,%20java.lang.Iterable,%20org.apache.hadoop.mapreduce.Reducer.Context">reduce(Object, Iterable, org.apache.hadoop.mapreduce.Reducer.Context)</a>)方法进行处理。<br/>
 reduce任务调用<a href="TaskInputOutputContext.write(Object,%20Object">TaskInputOutputContext.write(Object, Object)</a>)将最终结果写到<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/RecordWriter.html">RecordWriter</a>。<br/>
 Reducer的输出不是有序的。</li>
</ol>


<p>WordCount的Reduce实现类为：</p>

<pre><code>public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
            Context context) throws IOException, InterruptedException {
        int total = 0;
        for (IntWritable count : values) {
            total += count.get();
        }
        result.set(total);
        context.write(key, result);
    }
}
</code></pre>

<h2>Driver</h2>

<p>已经完成mapper和reducer的编写。接下来写一个job driver用来提交程序到hadoop中运行。<br/>
可以有两种方式编写job driver：</p>

<ol>
<li>实现一个普通Java类，在类中设置job属性信息，提交job</li>
<li>实现<a href="http://hadoop.apache.org/docs/current/api/index.html">Tool</a>接口</li>
</ol>


<p>实际应用中，我们采用实现Tool接口的方式，这种方式能够更好的控制程序运行。<br/>
WordCount Job的属性设置如下：</p>

<pre><code>public class WordCountDriver extends Configured implements Tool {

    public int run(String[] arg0) throws Exception {
        // TODO Auto-generated method stub
        if (arg0.length != 2) {
            System.err.printf("Usage: %s [generic options] &lt;input&gt; &lt;output&gt;\n", 
                    getClass().getSimpleName());
            ToolRunner.printGenericCommandUsage(System.err);
            return -1;
        }

        //Create new job
        Job job = Job.getInstance();
        job.setJarByClass(getClass());

        job.setJobName("WordCount");

        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        job.setNumReduceTasks(1);

        FileInputFormat.addInputPath(job, new Path(arg0[0]));
        FileOutputFormat.setOutputPath(job, new Path(arg0[1]));

        return job.waitForCompletion(true) ? 0 : 1;
    }   

    public static void main(String[] args) {
        // TODO Auto-generated method stub
        try {
            int exitCode = ToolRunner.run(new WordCountDriver(), args);
            System.exit(exitCode);
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
    }

}   
</code></pre>

<p>WordCountDriver实现了Tool接口，这样我们运行程序时可以使用GenericOptionParser支持的参数项。<br/>
调用Job.getInstance()获取一个Job实例。设置Job名称。设置输入路径和输出路径。设置mapper和reducer类名。设置输出key和value类型（输入类型由数据源格式确定，数据源缺省为TextInputFormat文本格式，默认key类型为LongWritable，value类型为Text）。</p>

<h2>本地运行WordCount</h2>

<p>将程序打成jar包，放到hadoop集群一台机器上去。在jar包文件所在目录，新建一个input目录，input目录中放置一个文本文件words.txt，运行以下命令：</p>

<pre><code>$ hadoop jar hadoopjob.jar com.hugedata.jobs.WordCountDriver -fs file:/// -jt local input/ output/
</code></pre>

<p>-fs file:///指定使用本地文件系统，-jt local 指定mapreduce任务运行在本地。<br/>
当前目录会产生一个output目录，里面有两个文件（part-r-00000、_SUCCESS），其中part-r-00000即为</p>

<pre><code>jintao@node0:~/Project$ cat output/part-r-00000
is  2
jintao  1
jintao. 1
mx  1
my  2
mz  1
name    2
name.   1
too.    1
whit's  1
your    1
</code></pre>

<h2>集群运行WordCount</h2>

<p>前提是集群环境已经运行正常。将本地目录下的input拷贝到hdfs上：</p>

<pre><code>jintao@node0:~/Project$ hdfs dfs -put input
jintao@node0:~/Project$ hdfs dfs -ls
Found 2 items
drwxr-xr-x   - jintao supergroup          0 2016-03-07 16:51 input
drwxr-xr-x   - jintao supergroup          0 2016-03-05 14:04 tmp
</code></pre>

<p>屏幕上打印的过程信息如下：</p>

<pre><code>16/03/07 16:55:18 INFO client.RMProxy: Connecting to ResourceManager at node0/192.168.88.120:8032
16/03/07 16:55:20 INFO input.FileInputFormat: Total input paths to process : 1
16/03/07 16:55:20 INFO mapreduce.JobSubmitter: number of splits:1
16/03/07 16:55:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457076326520_0001
16/03/07 16:55:21 INFO impl.YarnClientImpl: Submitted application application_1457076326520_0001
16/03/07 16:55:21 INFO mapreduce.Job: The url to track the job: http://node0:8088/proxy/application_1457076326520_0001/
16/03/07 16:55:21 INFO mapreduce.Job: Running job: job_1457076326520_0001
16/03/07 16:55:32 INFO mapreduce.Job: Job job_1457076326520_0001 running in uber mode : false
16/03/07 16:55:32 INFO mapreduce.Job:  map 0% reduce 0%
16/03/07 16:55:43 INFO mapreduce.Job:  map 100% reduce 0%
16/03/07 16:55:51 INFO mapreduce.Job:  map 100% reduce 100%
16/03/07 16:55:52 INFO mapreduce.Job: Job job_1457076326520_0001 completed successfully
16/03/07 16:55:52 INFO mapreduce.Job: Counters: 49
File System Counters
    FILE: Number of bytes read=156
    FILE: Number of bytes written=230351
    FILE: Number of read operations=0
    FILE: Number of large read operations=0
    FILE: Number of write operations=0
    HDFS: Number of bytes read=177
    HDFS: Number of bytes written=77
    HDFS: Number of read operations=6
    HDFS: Number of large read operations=0
    HDFS: Number of write operations=2
Job Counters
    Launched map tasks=1
    Launched reduce tasks=1
    Data-local map tasks=1
    Total time spent by all maps in occupied slots (ms)=8022
    Total time spent by all reduces in occupied slots (ms)=4886
    Total time spent by all map tasks (ms)=8022
    Total time spent by all reduce tasks (ms)=4886
    Total vcore-seconds taken by all map tasks=8022
    Total vcore-seconds taken by all reduce tasks=4886
    Total megabyte-seconds taken by all map tasks=8214528
    Total megabyte-seconds taken by all reduce tasks=5003264
Map-Reduce Framework
    Map input records=3
    Map output records=14
    Map output bytes=122
    Map output materialized bytes=156
    Input split bytes=110
    Combine input records=0
    Combine output records=0
    Reduce input groups=11
    Reduce shuffle bytes=156
    Reduce input records=14
    Reduce output records=11
    Spilled Records=28
    Shuffled Maps =1
    Failed Shuffles=0
    Merged Map outputs=1
    GC time elapsed (ms)=243
    CPU time spent (ms)=2860
    Physical memory (bytes) snapshot=444420096
    Virtual memory (bytes) snapshot=3891036160
    Total committed heap usage (bytes)=348651520
Shuffle Errors
    BAD_ID=0
    CONNECTION=0
    IO_ERROR=0
    WRONG_LENGTH=0
    WRONG_MAP=0
    WRONG_REDUCE=0
File Input Format Counters
    Bytes Read=67
File Output Format Counters
    Bytes Written=77
jintao@node0:~/Project$ 
</code></pre>

<p>程序执行成功后，会产生一个output目录，执行一下命令，可以产看结果：</p>

<pre><code>jintao@node0:~/Project$ hdfs dfs -cat output/part-r-00000
is  2
jintao  1
jintao. 1
mx  1
my  2
mz  1
name    2
name.   1
too.    1
whit's  1
your    1
</code></pre>

<p>至此，讲述了最基本的mapreduce程序开发、运行过程，后续需要学习的有如果查看日志，如何调试优化程序等方面。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hdfs文件系统java Api介绍]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao/"/>
    <updated>2015-12-21T17:29:19+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao</id>
    <content type="html"><![CDATA[<h1>Hadoop Filesystems</h1>

<p>Hadoop对于文件系统有一个抽象设计，HDFS只是一个实现。客户端使用Java 抽象类org.apache.hadoop.fs.FileSystem来访问Hadoop中的文件系统，有多个具体实现类:</p>

<pre><code>FileSystem      URI scheme      Java implementaion  
Local           file            fs.LocalFileSystem  

HDFS            hdfs            hdfs.DistributedFileSystem

WebHDFS         webhdfs         hdfs.web.WebHdfsFileSystem

Secure
WebHDFs         swebhdfs        hdfs.web.SWebHdfsFileSystem

HAR             har             fs.HarFileSystem

View            viewfs          viewfs.ViewFileSystem

FTP             ftp             fs.ftp.FTPFileSystem

S3              s3a             fs.s3a.S3AFileSystem

Azure           wasb            fs.azure.NativeAzureFileSystem

Swift           swift           fs.swift.snative.SwiftNative
</code></pre>

<p>Hadoop提供多个接口访问文件系统，接口利用URI的scheme来创建对应的实例与文件系统进行通讯。hdfs命令可以用来操作Hadoop各种文件系统，比如列出本地文件系统根目录内容：</p>

<pre><code>[root@yun1 ~]# hdfs dfs -ls file:///
Found 25 items
-rw-r--r--   1 root root          0 2015-10-19 11:06 file:///.autofsck
-rw-r--r--   1 root root          0 2014-07-04 14:16 file:///.autorelabel
dr-xr-xr-x   - root root       4096 2014-07-04 14:36 file:///bin
dr-xr-xr-x   - root root       1024 2014-09-17 15:54 file:///boot
drwxr-xr-x   - root root       4096 2014-07-04 09:17 file:///data
-rw-r--r--   1 root root       1001 2014-07-29 16:28 file:///dataplatform.log
drwxr-xr-x   - root root       3580 2015-10-19 11:08 file:///dev
</code></pre>

<h1>Java Interface</h1>

<!-- more -->


<p>访问HDFS文件系统需要先获取一个文件系统实例，FileSystem是一个文件系统统一访问接口。通过以下接口可以获取访问hdfs文件系统的实例：</p>

<pre><code>public static FileSystem get(Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf, String user) throws IOException
</code></pre>

<p>Configuration对象封装客户端或者服务端的配置信息，这些信息由classpath目录下配置文件初始化，比如etc/hadoop/core-site.xml。第一个接口根据conf中的信息，返回文件系统。第二个接口使用URI的scheme和授权来觉得使用哪个文件系统，如果没有设置scheme，则使用conf中配置的文件系统。第三个接口是以user用户的身份获取文件系统。 使用FileSystem实例，调用open方法可以获取一个输入文件流：</p>

<pre><code>public FSDataInputStream open(Path f) throws IOException
public abstract FSDataInputStream open(Path f, int bufferSize) throws IOException 
</code></pre>

<p>下面的代码实例用于读取hdfs文件输出到标准输出：</p>

<pre><code>public class FileSystemCat {

    public static void main(String[] args) throws Exception {
        String uri = args[0];
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(uri), conf);
        InputStream in = null;
        try {
            in = fs.open(new Path(uri));
            IOUtils.copyBytes(in, System.out, 4096, false);
        } finally {
            IOUtils.closeStream(in);
        }
    }
}
</code></pre>

<p>编译文件后，使用hadoop命令运行class文件：</p>

<pre><code># hadoop FileSystemCat hdfs://localhost/user/tom/quangle.txt
On the top of the Crumpetty Tree
The Quangle Wangle sat, 
But his face you could not see,
On account of his Beaver Hat.
</code></pre>

<h2>Writing Data</h2>

<p>FileSystem提供多个接口来创建文件，最简单的是输入一个路径作为参数，返回一个输出流：</p>

<pre><code>public FSDataOutputStream create(Path f) throws IOException 存在多个重载接口，允许指定是否重写已存在文件，文件的副本个数，写文件的缓冲区大小，文件的块大小和文件权限等等。存在append接口对已存在文件进行追加：
public FSDataOutputStream append(Path f) throws IOException
</code></pre>

<p>下面的代码实例是拷贝一个本地文件到Hadoop文件系统中：</p>

<pre><code>public class FileCopyWithProgress {
    public static void main(String []args) throws Exception {
        String localSrc = args[0];
        String dst = args[1];

        InputStream in = new BufferedInputStream(new FileInputStream(localSrc));

        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(dst), conf);
        OutputStream out = fs.create(new Path(dst), new Progressable() {
            public void progress() {
                System.out.print(".");
            }
        });

        IOUtils.copyBytes(in, out, 4096, true);
    }
}
</code></pre>

<p>运行程序结果如下：
    #hadoop FileCopyWithProgress input/docs/1400-8.txt hdfs://localhost/user/tom/1400-8.txt</p>

<p>创建目录使用下面的接口：</p>

<pre><code>public boolean mkdirs(Path f) throws IOException
</code></pre>

<h2>Quering the FileSystem</h2>

<p>FilsSystem提供了接口来获取文件或者文件夹信息，信息包括文件长度，块大小，复制，修改时间，所有权，访问权限属性。</p>

<pre><code>abstract FileStatus getFileStatus(Path f)
</code></pre>

<p>FileSystem提供了接口来列出一个目录中包含的内容：</p>

<pre><code>abstract FileStatus[]   listStatus(Path f)
FileStatus[]    listStatus(Path[] files)
FileStatus[]    listStatus(Path[] files, PathFilter filter)
FileStatus[]    listStatus(Path f, PathFilter filter)
</code></pre>
]]></content>
  </entry>
  
</feed>

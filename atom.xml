<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[jintao's blog]]></title>
  <link href="http://jintao-zero.github.io/atom.xml" rel="self"/>
  <link href="http://jintao-zero.github.io/"/>
  <updated>2017-03-19T17:32:53+08:00</updated>
  <id>http://jintao-zero.github.io/</id>
  <author>
    <name><![CDATA[jintao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Protocol-buffers Proto3 翻译]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/12/protocol-buffers-proto3-fan-yi/"/>
    <updated>2017-03-12T18:09:36+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/12/protocol-buffers-proto3-fan-yi</id>
    <content type="html"><![CDATA[<ul>
<li><a href="#message">定义Message类型</a></li>
<li><a href="#type">标量值类型</a></li>
<li><a href="#default">默认值</a></li>
<li><a href="#enum">枚举</a></li>
<li><a href="#other_message">使用其他消息类型</a></li>
<li><a href="#nested">嵌套类型</a></li>
<li><a href="#update">更新消息类型</a></li>
<li><a href="#unknown">未知字段</a></li>
<li><a href="#any">Any</a></li>
<li><a href="#oneof">Oneof</a></li>
<li><a href="#maps">Maps</a></li>
<li><a href="#packages">包</a></li>
<li><a href="#services">服务</a></li>
<li><a href="#json">json</a></li>
<li><a href="#options">选项</a></li>
<li><a href="#protoc">生成代码</a></li>
</ul>


<p>这个指导文档如何使用protocol buffer语言结构化你的protocol buffer数据，包括<code>.proto</code>文件语法和如何根据<code>.proto</code>文件生成代码访问数据。本文主要描述<code>proto3</code>版本。  <br/>
本文是参考文档，如果需要例子的话可以访问，你选择语言相关的<a href="https://developers.google.com/protocol-buffers/docs/tutorials">入门指导</a></p>

<h2><a name="message"></a>Message定义</h2>

<p>一个简单例子。下面定义一个搜索请求消息格式，这个消息包含一个查询字符串，包含一个搜索结果页码，和每页包含搜索结果数。下面是该消息<code>.proto</code>文件：</p>

<pre><code>syntax = "proto3";

message SearchRequest {
    string query = 1;
    int32 page_number = 2;
    int32 result_per_page = 3;
}
</code></pre>

<ul>
<li>第一行说明正在使用<code>proto3</code>语法：如果不指定proto版本，protocol buffer编译器默认认为正在使用<code>proto2</code>。这行语句必须是第一条非空、非注释语句。</li>
<li><code>SearchRequest</code>消息包含三个字段。每个字段有都有一个名字和类型。</li>
</ul>


<!-- more -->


<h3>字段类型</h3>

<p>在上面的例子中，所有字段都是标量类型：两个整型（<code>page_number</code>和<code>result_per_page</code>）和字符串（<code>query</code>）。你也可以指定字段类型为组合类型，包含枚举或者其他类型。</p>

<h3>添加Tag标签</h3>

<p>如定义所见，每一个字段都有一个唯一的数字标签。这些标签用来在<a href="https://developers.google.com/protocol-buffers/docs/encoding">消息二进制格式</a>中标示相应字段，一旦消息类型得到使用，就不应该在修改字段标签。值在1到15之间的tag编码时只占用一个字节，一个字节包含了tag值和字段类型，更多信息可以参考<a href="https://developers.google.com/protocol-buffers/docs/encoding.html#structure">Protocol Buffer Encoding</a>。16到2047之间的标签占用两个字节。所以应该用1到15之间的标签标示经常使用的字段，并且给未来可能添加进来的频繁使用字段预留一些标签。</p>

<p>自小标签值为1，最大值为2的29次方-1，即536,870,911。tag值区间19000到19999（FieldDescriptor::kFirstReservedNumber 到 FieldDescriptor::kLastReservedNumber）是<code>Protocol Buffers</code>的保留值，如果在<code>.proto</code>文件中使用了这个范围内的值，编译器将会报警。</p>

<h3>指定字段规则</h3>

<p>消息类型可以为如下类型：</p>

<ul>
<li>单数形式： 一个正确格式的消息可以包含0个或者一个这样的字段（不能大于一个）</li>
<li>重复类型： 这种类型的字段可以在一个消息中重复多次（包括0次）。</li>
</ul>


<p><code>proto3</code>中，标量类型的<code>repeated</code>字段类型默认使用<code>packed</code>编码。</p>

<p>可以在<a href="Protocol%20Buffer%20Encoding">Protocol Buffer Encoding</a>查看关于编码的详细内容。</p>

<h3>添加更多Message类型</h3>

<p>一个<code>.proto</code>文件中可以定义多个消息类型。因此可以将相关消息类型定义在一个<code>.proto</code>文件中，比如可以在上面的proto文件添加一个<code>SearchResponse</code>消息类型：</p>

<pre><code>message SearchRequest {
    string query = 1;
    int32 page_number = 2;
    int32 result_per_page = 3;
}

message SearchResponse {
    ...
}
</code></pre>

<h3>添加注释</h3>

<p><code>.proto</code>文件中，使用C/C++风格<code>//</code>注释</p>

<pre><code>message SearchRequest {
    string query = 1;
    int32 page_number = 2;  // Which page number do we want?
    int32 result_per_page = 3;  // Number of results to return per page.
}
</code></pre>

<h3>保留字段</h3>

<p>当完整删除一个字段，或者注释掉字段，这种方式修改一个消息类型时，未来用户可能会复用之前的标签值。如果加载就版本<code>.proto</code>文件时，这种情况可能会引起数据冲突，程序问题或者其他异常情况。可以通过将已经删除字段的tag值或者字段名设置为<code>reserved</code>。如果将来有人用到这些保留值，编译器将会报错。</p>

<pre><code>message Foo {
    reserved 2, 15, 9 to 11;
    reserved "foo", "bar";
}
</code></pre>

<p>注意不可以在同一个<code>reserved</code>语句中同时标示tag和字段</p>

<h3>从.proto文件生成什么</h3>

<p>当用编译器处理已经编写好的<code>.proto</code>文件时，编译器会根据选择的编程语言类型生成代码，使用这些代码可以操作<code>.proto</code>文件中定义的消息类型，包括获取、设置字段值，序列化消息到输出流，从输入流中反序列化消息。</p>

<ul>
<li>C++，编译器为每个<code>.proto</code>文件生成一个<code>.h</code>和<code>.cc</code>文件，对于文件中定义的每个消息类型生成一个类</li>
<li>Java,编译器为每个消息类型生成一个<code>.java</code>文件，同时生成一个<code>Builder</code>类用于创建消息类实例</li>
<li>Python，编译器为每个消息类型生成一个包含静态描述符的模块，在python运行时，可以与原类型一起生成一个Python数据存取类</li>
<li>Go，编译器为<code>.proto</code>文件中的每个消息类型生成一个<code>.pb.go</code>文件</li>
<li>Ruby，编译器生成一个<code>.rb</code>文件包含一个ruby模块包括所有文件中国年定义的消息类型</li>
<li>JavaNano，编译器生成的内容与Java类似，但是没有<code>Builder</code>类型。</li>
<li>Objective-C，编译器为每一个<code>.proto</code>文件生成一个<code>pbobjc.h</code>和<code>pbobjc.m</code>文件，为每个消息类型生成一个类。</li>
<li>C#，编译器生成一个<code>.cs</code>文件，每个消息类型生成一个类。</li>
</ul>


<p>可以从<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">API reference</a>中了解更多API相关信息</p>

<h2><a name="type"></a>标量值类型</h2>

<p>一个标量消息字段可以用如下消息类型，这些类型可以使用在<code>.proto</code>文件中，表中列出了相应语言的数据类型：</p>

<p><img src="http://jintao-zero.github.io/images/proto-1.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-2.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-3.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-4.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-5.png" alt="" /></p>

<p>可以在<a href="https://developers.google.com/protocol-buffers/docs/encoding">Protocol Buffer Encoding</a>中查看上面类型如何编码。</p>

<h2><a name="default"></a>默认值</h2>

<p>解析消息时，如果编码消息没有包含某个元素值，那么消息对象中对应字段的值设置为字段类型的默认值。不同类型具有不同默认值：</p>

<ul>
<li>字符串类型，默认为空字符串</li>
<li>字节类型，默认为空字节</li>
<li>布尔型，默认为false</li>
<li>数字类型，默认为0</li>
<li>枚举类型，默认为枚举类型第一个值，这个值必须为0</li>
<li>message类型，字段不进行设置。具体值依赖不同语言的初始化操作。</li>
</ul>


<p>重复型字段默认值为空。</p>

<p>注意，对于标量类型字段，一个消息解析时不会标示某个字段是否是显示设置为默认值，比如一个布尔型字段值为<code>false</code>时，不会告诉消息使用者这个布尔字段值为<code>false</code>还是被设置的默认值<code>false</code>。定义消息类型时，要注意这点。如果一个布尔字段值为<code>false</code>时，程序表现为某种行为，如果你不希望默认情况下程序表现为这种行为的话，就需要注意。对于标量类型字段，如果设置为默认值，那么将不会对这个字段进行编码传输。 <br/>
<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">generated code guide</a>查看关于不同语言默认值如何工作的详细情况。</p>

<h2><a name="enum"></a>枚举</h2>

<p>定义消息类型时，可能需要设置字段值为一些预定义值，我们可以在消息定义文件中定义<code>enum</code>枚举类型，在<code>SearchRequest</code>中定义一个枚举类型<code>Corpus</code>：</p>

<pre><code>message SearchRequest {
    string query = 1;
    int32 page_number = 2;
    int32 result_per_page = 3;
    enum Corpus {
        UNIVERSAL = 0;
        WEB = 1;
        IMAGES = 2;
        LOCAL = 3;
        NEWS = 4;
        PRODUCTS = 5;
        VIDEO = 6;
    }
    Corpus corpus = 4;
}
</code></pre>

<p><code>Corpus</code>枚举类型的第一个常量值为0：protobuf中每一个枚举类型<code>必须</code>将第一个值定义为0，原因如下：</p>

<ul>
<li>必须有一个0值，这样可以使用0值为枚举类型默认值</li>
<li>0值必须为第一个值，这样是为了与<code>proto2</code>语法相兼容，<code>proto2</code>中以第一个枚举值为默认值</li>
</ul>


<p>可以为枚举值定义一个别名，需要在定义别名的枚举类型中设置<code>allow_alias</code>选项为<code>true</code>，否则编译器将会报错。</p>

<pre><code>enum EnumAllowingAlias {
    option allow_alias = true;
    UNKNOWN = 0;
    STARTED = 1;
    RUNNING = 1;
}   
enum EnumNotAllowingAlias {
    UNKNOWN = 0;
    STARTED = 1;
    // RUNNING = 1;  // Uncommenting this line will cause a         compile error inside Google and a warning message outside.
}
</code></pre>

<p>枚举类型常量值必须在32位整型之间。因为<code>enum</code>类型使用<a href="https://developers.google.com/protocol-buffers/docs/encoding">varint encoding</a>进行编码，值为负数的话，编码效率低，所以不推荐为负数。可以在消息定义体之中，或者之外定义<code>enum</code>枚举类型，可以在<code>.proto</code>文件任何为值使用这些枚举类型。 你可以通过<code>MessageType.EnumType</code>的方式使用在其他消息中定义的枚举类型。</p>

<p>当编译带有<code>enum</code>的<code>.proto</code>文件时，目标语言是<code>C++</code>或者<code>Java</code>时，产生的代码中包含<code>enum</code>定义，目标代码是<code>Python</code>时，产生一个<code>EnumDescriptor</code>类。</p>

<h2><a name="other_message"></a>使用其他消息类型</h2>

<p>可以使用其他消息类型定义字段。比如在<code>SearchResponse</code>消息中包含<code>Result</code>消息，<code>Result</code>消息可以定义在同一个<code>.proto</code>文件中。</p>

<pre><code>message SearchResponse {
    repeated Result results = 1;
}

message Result {
    string url = 1;
    string title = 2;
    repeated string snippets = 3;
}
</code></pre>

<h3>引入定义</h3>

<p>上面的例子中，<code>Result</code>定义在<code>SearchResponse</code>同样的<code>.proto</code>文件中，如果需要使用的消息类型定义在其他文件中消息类型。</p>

<p>通过import<code>.proto</code>文件使用<code>.proto</code>文件中的定义。在自己<code>.proto</code>文件顶部添加一行引入语句：</p>

<pre><code>import "myproject/other_protos.proto";
</code></pre>

<p>默认情况下，只能使用被直接<code>import</code>的文件中的消息定义。如果需要将<code>.proto</code>文件挪到一个新的位置去，可以放一个替代<code>.proto</code>文件到老的位置，在这个替代文件中使用<code>import public</code>将定义转移到新位置。例子：</p>

<pre><code>// new.proto
// All definitions are moved here


// old.proto
// This is the proto that all clients are importing.
import public "new.proto";
import "other.proto";

// client.proto
import "old.proto";
// You use definitions from old.proto and new.proto, but not other.proto
</code></pre>

<p>编译器在<code>-I/--proto_path</code>参数指定的目录中搜索被引入的<code>.proto</code>文件。如果没有设置这个参数，编译器在当前目录下查找，通常情况下，应该设置<code>--proto_path</code>为工程的根目录。</p>

<h3>使用proto2消息类型</h3>

<p>可以在<code>proto3</code>消息中引入<code>proto2</code>消息类型。但是proto2枚举类型不能在proto3语法中直接使用。</p>

<h2><a name="nested"></a>嵌套类型</h2>

<p>可以在消息类型中定义其他类型，下面的例子中，<code>Result</code>消息定义在<code>SearchResponse</code>消息中：</p>

<pre><code>message SearchResponse {
    message Result {
    string url = 1;
    string title = 2;
    repeated string snippets = 3;
    }
    repeated Result results = 1;
}  
</code></pre>

<p>如果想在<code>SearchResponse</code>消息以外使用<code>Result</code>消息，以<code>Parent.Type</code>格式使用：</p>

<pre><code>message SomeOtherMessage {
    SearchResponse.Result result = 1;
}
</code></pre>

<p>可以任意潜逃消息定义：</p>

<pre><code>message Outer {                  // Level 0
    message MiddleAA {  // Level 1
        message Inner {   // Level 2
            int64 ival = 1;
            bool  booly = 2;
        }
    }
    message MiddleBB {  // Level 1
        message Inner {   // Level 2
            int32 ival = 1;
            bool  booly = 2;
        }
    }
}
</code></pre>

<h2><a name="update"></a>更新消息类型</h2>

<p>如果已有消息不能满足新的需求，比如，需要增加一个新的字段，但是仍然使用根据老的消息格式产生的代码，对于protocol buffer来说这很容易完成，请记住如下的规则：</p>

<ul>
<li>不要修改当前字段的标签值</li>
<li>如果新增字段，任何根据老格式序列化的消息，都能够被根据新格式产生的代码进行解析。这种情况下，新增字段的值都会被设置为<a href="https://developers.google.com/protocol-buffers/docs/proto3#default">默认值</a>。新格式消息同样可以为老格式代码解析，新增字段将会被忽略。</li>
<li>可以删除字段，只要新消息格式中该字段标签值没有被使用。对于删除的字段，最好是对字段名称进行修改，添加<code>OBSOLETE_</code>字段或者设置tag为<a href="https://developers.google.com/protocol-buffers/docs/proto3#reserved">reserved</a>，这样未来不会错误使用该tag值。</li>
<li><code>int32</code>,<code>uint32</code>,<code>int64</code>,<code>uint64</code>,<code>bool</code>都是兼容的，意味着可以将字段从一种类型修改为另一种。如果解析时，从序列化数据中解析出的数据与响应字段类型不匹配，那么行为表现为从类型转换。</li>
<li><code>sint32</code>和<code>sint64</code>互相兼容，但是与其他整型类型不兼容。</li>
<li><code>string</code>和<code>bytes</code>互相兼容，只要bytes是UTF-8格式。</li>
<li>嵌套消息与<code>bytes</code>互相兼容，只要bytes包含该消息的编码</li>
<li><code>fixed32</code>与<code>sfixed32</code>，<code>fixed64</code>，<code>sfixed64</code>相兼容。</li>
<li><code>enum</code>与<code>int32</code>，<code>uint32</code>，<code>int64</code>，<code>uint64</code>相兼容</li>
</ul>


<h2><a name="unknown"></a>未知字段</h2>

<p>未知字段是正确格式数据，解析程序不能识别的字段。当旧格式解析程序解析新格式消息时，解析程序无法识别新格式消息中新增字段，认为为未知字段。</p>

<p><code>Proto3</code>实现可以解析这些未知字段，但是实现可能不支持保留这些字段。不应依赖这些未知字段。对于大部分实现，未知字段都是不可访问的，在序列化时，未知字段将会被忽略。这与<code>proto2</code>不同，未知字段也会被保留和序列化。</p>

<h2><a name="any"></a>Any</h2>

<p><code>Any</code>消息类型允许你使用某消息类型，而不需要引入该类型消息<code>.proto</code>文件。<code>Any</code>类型包含任意<code>bytes</code>类型序列化数据，<code>Any</code>类型包含一个URL，作为消息类型的唯一标识。引入<code>google/protobuf/any.proto</code>来使用<code>Any</code>类型。</p>

<pre><code>import "google/protobuf/any.proto";

message ErrorStatus {
    string message = 1;
    repeated google.protobuf.Any details = 2;
}
</code></pre>

<p>一个消息类型的默认URL为<code>type.googleapis.com/packagename.messagename</code>。</p>

<p>不同语言都会有运行时库去打包和解包Any类型值，Java中，Any类型字段会有<code>pack()</code>和<code>unpack()</code>方法访问，C++语言中有<code>PackFrom()</code>和<code>UnpackTo()</code>方法：</p>

<pre><code>// Storing an arbitrary message type in Any.
NetworkErrorDetails details = ...;
ErrorStatus status;
status.add_details()-&gt;PackFrom(details);

// Reading an arbitrary message from Any.
ErrorStatus status = ...;
for (const Any&amp; detail : status.details()) {
    if (detail.Is&lt;NetworkErrorDetails&gt;()) {
        NetworkErrorDetails network_error;
        detail.UnpackTo(&amp;network_error);
        ... processing network_error ...
    }
}
</code></pre>

<h2><a name="oneof"></a>Oneof</h2>

<p>如果消息中包含多个字段，同一时间最多设置一个字段，可以使用<code>oneof</code>特性来强制这种行为并且节省内存。</p>

<p>设置<code>oneof</code>中的任一字段将会清楚其他字段值。可以使用<code>case</code>或者<code>WhichOneof</code>方法查看当前哪个字段被设置。</p>

<h3>使用Oneof</h3>

<p>使用<code>oneof</code>关键词在<code>.proto</code>文件中定义：</p>

<pre><code>message SampleMessage {
    oneof test_oneof {
        string name = 4;
        SubMessage sub_message = 9;
    }
}
</code></pre>

<p>可以在oneof定义中添加除了<code>repeated</code>以外任意类型的字段。</p>

<p>产生的代码中，对于oneof中的字段拥有跟普通字段一样的获取、设置函数。还会获取一个特殊方法检查哪个值被设置。关于oneof更多API请参考<a href="https://developers.google.com/protocol-buffers/docs/reference/overview">API reference</a>。</p>

<h3>Oneof 特性</h3>

<ul>
<li><p>设置oneof字段会清楚其他字段值。如果多次设置oneof字段值，只保留最后一次设置值。</p>

<pre><code>  SampleMessage message;
  message.set_name("name");
  CHECK(message.has_name());
  message.mutable_sub_message();   // Will clear name field.
  CHECK(!message.has_name());  
</code></pre></li>
<li>如果解析程序遇到oneof定义中的多个字段值，只有最后一个是有效的。</li>
<li>不能将一个<code>oneof</code>类型用于<code>repeated</code>中</li>
<li>反射对于oneof字段有效</li>
<li><p>使用C++时，防止非法访问内存。下面代码示例中，执行<code>set_name</code>时，<code>sub_message</code>已经被清除：</p>

<pre><code>  SampleMessage message;
  SubMessage* sub_message = message.mutable_sub_message();
  message.set_name("name");      // Will delete sub_message
  sub_message-&gt;set_...            // Crashes here
</code></pre>

<p>*使用C++ oneof <code>Swap</code>方法时，互换两个变量中设置的字段值：</p>

<pre><code>  SampleMessage msg1;
  msg1.set_name("name");  
  SampleMessage msg2;
  msg2.mutable_sub_message();
  msg1.swap(&amp;msg2);
  CHECK(msg1.has_sub_message());
  CHECK(msg2.has_name());
</code></pre></li>
</ul>


<h3>向后兼容问题</h3>

<p>添加或者删除oneof字段时要小心。如果检查oneof值时返回<code>None</code>或者<code>NOT_SET</code>时,意味着oneof没有被设置或者设置了oneof的一个其他版本。 因为没有办法区分一个未知字段是新加字段。</p>

<p>复用标签问题</p>

<ul>
<li>添加或者移除字段： 可能会丢失某些字段信息。</li>
<li>删除字段后又添加：</li>
<li>分拆或者合并：</li>
</ul>


<h2><a name="maps"></a>Maps</h2>

<p>protocol buffers提供一个映射类型定义字段：</p>

<pre><code>map&lt;key_type, value_type&gt; map_field = N;
</code></pre>

<p><code>key_type</code>可以为整型或者字符串类型（除了<code>floating point</code>和<code>bytes</code>以外的标量类型）。<code>value_type</code>可以为任何类型。</p>

<p>下面定义个map类型字段，每个<code>project</code>对应一个字符串：</p>

<pre><code>map&lt;string, Project&gt; projects = 3;
</code></pre>

<ul>
<li>Map字段不可以是<code>repeated</code></li>
<li>不依赖map顺序</li>
<li>生成<code>.proteo</code>文本格式时，maps以key排序。数字按照数字排序</li>
</ul>


<h3>向后兼容</h3>

<p>map语法等同于下面的消息定义，所以不支持map的protocol buffers实现仍然可以解析数据：</p>

<pre><code>message MapFieldEntry {
    key_type key = 1;
    value_type value = 2;
}

repeated MapFieldEntry map_field = N;
</code></pre>

<h2><a name="packages"></a>包</h2>

<p>可以在<code>.proto</code>文件中添加一个<code>package</code>可选项，防止消息类型命名冲突。</p>

<pre><code>package foo.bar;
message Open { ... }
</code></pre>

<p>可以在定义字段时使用包名：</p>

<pre><code>message Foo {
    ...
    foo.bar.Open open = 1;
    ...
}
</code></pre>

<p>根据不同语言产生不同的代码：</p>

<ul>
<li>C++中，产生的类包含在C++命名空间中，例如，<code>Open</code>将会出现在<code>foo::bar</code>命名空间</li>
<li>Java，<code>package</code>名被用来作为Java包名，除非在<code>.proto</code>文件中使用<code>option java_package</code>指定包名</li>
<li>Python，<code>package</code>指令被忽略，因为Python中包是按照在文件系统中的路径组织的</li>
<li>Go，<code>package</code>包名被用做Go代码包名，除非使用<code>option java_package</code>指定包名</li>
<li>Ruby，产生的代码包裹在Ruby命名空间，命名空间名称根据<code>package</code>参数包名生成</li>
<li>JavaNano，<code>package</code>参数名被用做产生代码包名</li>
<li>C#，<code>package</code>参数名被用来作为产生代码包名</li>
</ul>


<h3>包和命名查找</h3>

<p>protocol buffer中名字查找规则与C++类似：从内到外，逐层查找。<code>.foo.bar.Baz</code>意思是从最外层开始查找。</p>

<h2><a name="services"></a>定义服务</h2>

<p>如果在<code>RPC</code>中使用定义的消息类型，可以在<code>.proto</code>文件中定义一个RPC服务接口，protocol buffer编译器将会产生服务接口代码。下面定义一个服务函数，输入<code>SearchRequest</code>返回一个<code>SearchResponse</code>：</p>

<pre><code>service SearchService {
    rpc Search (SearchRequest) returns (SearchResponse);
}
</code></pre>

<p>最简单的使用protocol buffers的RPC系统是<a href="https://github.com/grpc/grpc-common">gRPC</a>：Google开发的一个语言和平台无关的开源RPC系统。使用一个protocol buffer编译器插件可以直接从<code>.proto</code>文件中直接生成相应的RPC代码。</p>

<h2><a name="json"></a>JSON映射</h2>

<p>Proto3支持JSON编码，方便系统间共享数据。下面的表格列入了Proto3消息类型与JSON对应关系。</p>

<p><img src="http://jintao-zero.github.io/images/proto-6.png" alt="" />
<img src="http://jintao-zero.github.io/images/proto-7.png" alt="" /></p>

<h2><a name="options"></a>Options选项</h2>

<p>单独的声明可以用一些options修饰。选项不会改变一个声明的总体意义，但是会影响在特殊上下文中的意义。完整options选项定义在<code>google/protobuf/descriptor.proto</code>。<br/>
一些options选项是文件级别的。一些选项是消息级别的。一些选项是字段级别的。<br/>
下面是一些经常是用的选项：</p>

<ul>
<li><p><code>java_package</code>(文件级别选项)：使用这个选项指定产生的java代码包名。如果没有使用这个参数显示指定包名，编译器将会使用<code>.proto</code>文件中package指定的包名作为java代码包名。但是proto包名生成的java包名并不符合Java包名倒序的惯例。如果不是生成Java代码，这个选项无效：</p>

<pre><code>  option java_package = "com.example.foo";
</code></pre></li>
<li><p><code>java_multiple_files</code>（文件级别选项）：指定产生的最外层Java类名。如果没有使用<code>java_outer_classname</code>参数，则使用<code>.proto</code>文件名作为最外层类名，文件名被转换成驼峰模式（<code>foo_bar.proto</code>生成<code>FooBar.java</code>）。如果不是生成java代码，下面选项无效：</p>

<pre><code>  option java_outer_classname = "Ponycopter";
</code></pre></li>
<li><p><code>optimize_for</code>（文件级别选项）：可以设置为<code>SPEED</code>，<code>CODE_SIZE</code>，<code>LITE_RUNTIME</code>。这个参数按照下面方式影响C++和Java代码生成：</p>

<ul>
<li><code>SPEED</code>(默认值)：protocol buffer编译器为消息类型生成序列化、反序列化和其他操作的相关代码。代码是高度优化的。</li>
<li><code>CODE_SIZE</code>：protocol buffer编译器生成最少类，依赖共享的，基于反射的代码去实现序列化、反序列化和其他操作。生成的代码与<code>SPEED</code>相比很小，但是更慢。生成的类的接口与<code>SPEED</code>模式一样。这个选项在拥有大量<code>.proto</code>文件不需要它们都很快。</li>
<li><p><code>LITE_RUNTIME</code>：编译器将生成类只依赖轻运行时库（<code>libprotobuf-lite</code>而不是<code>libprotobuf</code>）。轻运行时库比全库更小。这对于运行在限制平台（比如智能手机）的应用很有用。编译器将会生成跟<code>SPEED</code>选项一样的高效代码。生成的类只实现<code>MessageLite</code>接口，只提供了全<code>Message</code>接口方法的子集。</p>

<pre><code>  option optimize_for = CODE_SIZE;
</code></pre></li>
</ul>
</li>
<li><p><code>cc_enable_arenas</code>（文件级别选项）：为产生的C++代码使能<a href="https://developers.google.com/protocol-buffers/docs/reference/arenas">arena allocation</a></p></li>
<li><code>objc_class_prefix</code>（文件级别选项）：为产生的Objective-C代码添加前缀。没有默认值，应该按照Apple推荐的惯例设置此选项。</li>
<li><p><code>deprecated</code>（文件级别选项）：如果设置为<code>true</code>，指示这个字段已弃用。在大多数语言中，这个选项无效。Java代码中，这个选项变成<code>@Deprecated</code>注解。</p>

<pre><code>  int32 old_field = 6 [deprecated=true];
</code></pre>

<h2>自定义选项</h2>

Protocol Buffers also allows you to define and use your own options. This is an advanced feature which most people don&rsquo;t need. If you do think you need to create your own options, see the Proto2 Language Guide for details. Note that creating custom options uses extensions, which are permitted only for custom options in proto3.

<h2><a name="protoc"></a>生成代码</h2>

<p>使用<code>protoc</code>编译器根据<code>.proto</code>文件生成Java，Python，C++，Go，Ruby，JavaNano，Objective-C，或者C#代码。如果格式调用程序：</p>

<pre><code>  protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR --ruby_out=DST_DIR --javanano_out=DST_DIR --objc_out=DST_DIR --csharp_out=DST_DIR path/to/file.proto
</code></pre></li>
<li><p><code>IMPORT_PATH</code> 指定目录，在目录中查找<code>import</code>指令引入的文件。如果没有制定，使用当前目录。可以多次使用<code>--proto_path</code>参数指定多个路径；按照顺序查找。<code>-I=IMPORT_PATH</code>可以作为<code>--proto_path</code>的短形式</p></li>
<li>可以设置多个输出指令：

<ul>
<li><code>--cpp_out</code>在<code>DST_DIR</code>中生成C++代码。</li>
<li><code>--java_out</code>在<code>DST_DIR</code>中生成Java代码</li>
<li><code>--python_out</code>在<code>DST_DIR</code>中生成Python代码</li>
<li><code>--go_out</code>在<code>DST_DIR</code>中生成Go代码</li>
<li><code>--ruby_out</code>在<code>DST_DIR</code>中生成Ruby代码</li>
<li><code>--javanano_out</code>在<code>DST_DIR</code>中生成JavaNano代码</li>
<li><code>--objc_out</code>在<code>DST_DIR</code>中生成Objective-C代码</li>
<li><code>--csharp_out</code>在<code>DST_DIR</code>中生成C#代码</li>
<li><code>--php_out</code>在<code>DST_DIR</code>中生成PHP代码</li>
</ul>
</li>
<li>必须指定一个或者多个<code>.proto</code>文件作为参数。多个<code>.proto</code>文件可以同时指定。每个文件必须在<code>IMPORT_PATH</code>指定的路径中能够查找到</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Defer Panic 和Recover介绍和实践]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/07/golang-defer-panic-he-recoverjie-shao/"/>
    <updated>2017-03-07T11:08:41+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/07/golang-defer-panic-he-recoverjie-shao</id>
    <content type="html"><![CDATA[<p>Golang语言提供了正常的流程控制：if、for、switch和goto。还提供了go表达式创建goroutine协程。接下来将要介绍的是：<code>defer</code>、<code>panic</code>和<code>recovery</code></p>

<h2>defer</h2>

<p>defer表达式将一个函数放到一个list中。包裹defer函数的函数return时，这个defer函数将会被执行。<code>Defer</code>通常被用来简化资源清理动作。  <br/>
下面的代码片段，完成的功能是打开两个文件，将一个文件的内容拷贝到另外一个文件中：</p>

<pre><code>func CopyFile(dstName, srcName string) (written int64, err error) {
    src, err := os.Open(srcName)
    if err != nil {
        return
    }

    dst, err := os.Create(dstName)
    if err != nil {
        return
    }

    written, err = io.Copy(dst, src)
    dst.Close()
    src.Close()
    return
}
</code></pre>

<p>这个片段有bug。当调用os.Createa失败时，函数返回，但是没有将已经打开的源文件关闭。在第二个return语句之前执行src.Close可以修复bug。但是如果存在多个资源需要关闭或者多个return语句时，这样就比较繁琐。使用defer表达式，可以方便确保资源关闭：</p>

<pre><code>func CopyFile(dstName, srcName string) (written int64, err error) {
    src, err := os.Open(srcName)
    if err != nil {
        return
    }
    defer src.Close()

    dst, err := os.Create(dstName)
    if err != nil {
        return
    }
    defer dst.Close()

    return io.Copy(dst, src)
}
</code></pre>

<p>Defer表达式会提醒我们在打开文件之后关闭资源，并且确保无论多少return语句都会将资源关闭。<br/>
defer表达式的行为是简单和可预测的。下面有三条简单规则：</p>

<ol>
<li><p>注册defer函数时，计算deferred函数的参数
下面的例子中，defer表达式注册fmt.Println函数时确定了入参为0，下面函数执行return语句时，fmt.Println将会打印出0</p>

<pre><code>  func a() {
      i := 0
      defer fmt.Println(i)
      i++
      return
  }
</code></pre></li>
<li><p>注册函数按照先进后出的的顺序进行执行</p>

<pre><code> func b() {
     for i := 0; i &lt; 4; i++ {
         defer fmt.Print(i)
      }
 }
</code></pre>

<p> 打印结果是“3210”</p></li>
<li><p>Deferred函数可以读写包裹函数的命名返回值
下面的例子中，包裹函数返回后，deferred函数修改了命名返回值i。因此，包裹函数的返回值为2</p>

<pre><code>  func c() (i int) {
      defer func() { i++ }()
      return 1
  }
</code></pre>

<p>  这个特点可以用来修改函数返回的error返回值</p></li>
</ol>


<!-- more -->


<h2>Panic</h2>

<p><code>panic</code>是Golang内建函数，它会停止当前流程，开始<code>panicking</code>。当函数F调用panic时，F将会停止执行正常流程，执行F函数中注册的defer函数，然后F函数返回。对于F函数的调用函数，F函数表现为panic。F函数的调用函数按照F函数panic时的行为一样，执行deferred函数后返回，这样沿着沿着调用栈，直到最上层，之后程序崩溃。<code>Panic</code>可以由程序调用<code>panic</code>函数后触发，也会有运行时错误触发，比如slice越界访问。</p>

<h2>Recover</h2>

<p><code>recover</code>内建函数，可以用来从处于<code>panic</code>状态的goroutine中重新获取控制。<code>recover</code>只有在defer函数中才有用。在正常状态下，调用recover函数返回nil，不会有其他作用。如果当前goroutine处于<code>panicking</code>状态，那么调用<code>recover</code>函数，可以获取<code>panic</code>函数的参数，并终止<code>panicking</code>状态，进入正常状态。
下面的例子演示如何利用<code>defer</code>、<code>panic</code>和<code>recover</code>：</p>

<pre><code>package main

import "fmt"

func main() {
    f()
    fmt.Println("Returned normally from f.")
}

func f() {
    defer func() {
        if r := recover(); r != nil {
            fmt.Println("Recovered in f", r)
        }
    }()
    fmt.Println("Calling g.")
    g(0)
    fmt.Println("Returned normally from g.")
}

func g(i int) {
    if i &gt; 3 {
    fmt.Println("Panicking!")
        panic(fmt.Sprintf("%v", i))
    }
    defer fmt.Println("Defer in g", i)
    fmt.Println("Printing in g", i)
    g(i + 1)
}
</code></pre>

<p>程序输出如下：</p>

<pre><code>Calling g.
Printing in g 0
Printing in g 1
Printing in g 2
Printing in g 3
Panicking!
Defer in g 3
Defer in g 2
Defer in g 1
Defer in g 0
Recovered in f 4
Returned normally from f.
</code></pre>

<p>如果我们删除F函数中的defer函数，那么panic将不会得到恢复，一直到到goroutine调用栈的最顶层，终止程序执行。这样程序的输出如下：</p>

<pre><code>Calling g.
Printing in g 0
Printing in g 1
Printing in g 2
Printing in g 3
Panicking!
Defer in g 3
Defer in g 2
Defer in g 1
Defer in g 0
panic: 4

panic PC=0x2a9cd8
[stack trace omitted]
</code></pre>

<h2>实践</h2>

<p>使用<code>defer</code>和<code>recover</code>构造一个带recover的goroutine包裹函数</p>

<pre><code>func defaultPanicHandler(e interface{}) {
    fmt.Println(e)
    debug.PrintStack()
    // log here
}

var PanicHandler func(interface{}) = defaultPanicHandler

func withRecover(fn func()) {
    defer func() {
        handler := PanicHandler
        if handler != nil {
            if err := recover(); err != nil {
                handler(err)
            }
        }
    }()
    fn()
}

func main () {
    go withRecover(
        func () {
            fmt.Println("aaaa")
            panic("panicking")
        }
    )
    for {
        time.Sleep(3 * time.Second)
    }
}
</code></pre>

<p>参考：</p>

<ol>
<li><a href="https://blog.golang.org/defer-panic-and-recover">https://blog.golang.org/defer-panic-and-recover</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Reflect介绍]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/03/06/golang-reflectjie-shao/"/>
    <updated>2017-03-06T17:44:02+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/03/06/golang-reflectjie-shao</id>
    <content type="html"><![CDATA[<p>Golang <a href="https://golang.org/pkg/reflect/">reflect</a>包实现了运行时反射，允许程序管理任意类型对象。典型应用是使用<code>TypeOf</code>从静态类型<code>interface{}</code>中抽取动态类型信息。<br/>
使用<code>ValueOf</code>返回一个<code>Value</code>类型变量代表运行时数据。<br/>
<a href="https://golang.org/doc/articles/laws_of_reflection.html">The Laws of Reflection</a>介绍了Golang reflect机智中的几条规则：</p>

<h2>从interface反射到对象</h2>

<p>反射基本功能是用来检查interface变量中保存的<code>类型</code>和<code>数据</code>对。<a href="http://golang.org/pkg/reflect/">package reflect</a>中提供了两种类型：<a href="http://golang.org/pkg/reflect/#Type">Type</a>和<a href="http://golang.org/pkg/reflect/#Value">Value</a>。这两种类型提供了反问interface内部数据的机制。调用<code>reflect.TypeOf</code>和<code>reflect.ValueOf</code>函数分别返回<code>reflect.Type</code>和<code>reflect.Value</code>变量：</p>

<pre><code>ackage main

import (
"fmt"
"reflect"
)

func main() {
    var x float64 = 3.4
    fmt.Println("type:", reflect.TypeOf(x))
}
</code></pre>

<p>程序输出如下：</p>

<pre><code>type: float64
</code></pre>

<p><code>reflect.TypeOf</code>函数定义如下：</p>

<pre><code>// TypeOf returns the reflection Type of the value in the interface{}.
func TypeOf(i interface{}) Type
</code></pre>

<p>当我们调用<code>TypeOf(x)</code>时，x首先存在一个空interface中，之后作为参数，reflect.TypeOf解析参数获取实际类型。  <br/>
调用<code>Value(x)</code>时，从接口参数中获取实参值。</p>

<pre><code>var x float64 = 3.4
fmt.Println("value:", reflect.ValueOf(x))
</code></pre>

<p>打印结果如下：</p>

<pre><code>value: &lt;float64 Value&gt;
</code></pre>

<!-- more -->


<p></p>

<h2>从反射对象逆转回接口值</h2>

<p>给定一个<code>reflect.Value</code>对象，调用<code>Interface</code>方法可以恢复一个接口值。实际上，<code>Interface</code>方法将Value对象的值和类型信息打包到一个接口值中并返回：</p>

<pre><code>// Interface returns v's value as an interface{}.
func (v Value) Interface() interface{}
</code></pre>

<p>接上面的例子：</p>

<pre><code>y := v.Interface().(float64) // y will have type float64.
fmt.Println(y)
</code></pre>

<p>将反射对象v代表的float64值打印。</p>

<h2>如果修改一个反射对象，value必须可设置</h2>

<p><code>reflect.ValueOf</code>返回的Value值，并不是所有情况下都是可修改的。下面示例：</p>

<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
v.SetFloat(7.1) // Error: will panic.
</code></pre>

<p>执行代码时，报如下panic错误：</p>

<pre><code>panic: reflect.Value.SetFloat using unaddressable value
</code></pre>

<p>反射对象v不是可设置的。可设置是<code>reflect.Value</code>类型对象的一个属性，不是所有<code>Value</code>对象有此属性。<br/>
Value对象<code>CanSet</code>方法返回Value对象是否可以设置，在我们的例子中：</p>

<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
fmt.Println("settability of v:", v.CanSet())
</code></pre>

<p>将会输出：</p>

<pre><code>settability of v: false
</code></pre>

<p><code>Settability</code>是反射对象的一个属性，它反映的是是否能够修改创建这个反射对象的原对象。<code>Settability</code>由反射对象是否持有原对象决定。</p>

<pre><code>var x float64 = 3.4
v := reflect.ValueOf(x)
</code></pre>

<p>当我们执行上面代码时，根据x生成一个interface对象作为是实参调用<code>reflect.Value</code>，interface对象保存的是x值拷贝。</p>

<pre><code>v.SetFloat(7.1)
</code></pre>

<p>上面代码修改的并不是x值。<br/>
对于函数调用，如果想修改实参，那必须传递实参地址到函数中。</p>

<pre><code>var x float64 = 3.4
p := reflect.ValueOf(&amp;x) // Note: take the address of x.
fmt.Println("type of p:", p.Type())
fmt.Println("settability of p:", p.CanSet())
</code></pre>

<p>上面代码，我们创建了一个x地址的反射对象，代码的输出如下：</p>

<pre><code>type of p: *float64
settability of p: false
</code></pre>

<p>反射对象p是不可设置的，我们不是要修改p，而是要修改p指向的x对象。  调用<code>Elem</code>方法可以获取p所指向的原对象：</p>

<pre><code>v := p.Elem()
fmt.Println("settability of v:", v.CanSet())
</code></pre>

<p>现在v对象就是可以修改的了：</p>

<pre><code>settability of v: true
</code></pre>

<p>现在v对象代表了原对象x，现在可以对v对象进行设置：</p>

<pre><code>v.SetFloat(7.1)
fmt.Println(v.Interface())
fmt.Println(x)
</code></pre>

<p>结果输出如下：<br/>
    7.1
    7.1</p>

<h3>Structs</h3>

<p>当我们拥有struct结构体对象地址时，可以对结构体对象进行修改<br/>
接下来是一个小的示例，使用结构体对象地址创建一个反射对象，然后使用reflect包中提供的结构体相关的方法，对结构体对象进行遍历和修改。</p>

<pre><code>type T struct {
    A int
    B string
}
t := T{23, "skidoo"}
s := reflect.ValueOf(&amp;t).Elem()
typeOfT := s.Type()
for i := 0; i &lt; s.NumField(); i++ {
    f := s.Field(i)
    fmt.Printf("%d: %s %s = %v\n", i,
    typeOfT.Field(i).Name, f.Type(), f.Interface())
}
</code></pre>

<p>上面代码的输出如下：</p>

<pre><code>0: A int = 23
1: B string = skidoo
</code></pre>

<p>因为s是可设置的反射对象，我们可以修改原对象的字段值：</p>

<pre><code>s.Field(0).SetInt(77)
s.Field(1).SetString("Sunset Strip")
fmt.Println("t is now", t)
</code></pre>

<p>结果如下：</p>

<pre><code>t is now {77 Sunset Strip}
</code></pre>

<h2>案例</h2>

<p>参考：</p>

<p>1、<a href="https://golang.org/pkg/reflect/">https://golang.org/pkg/reflect/</a>   <br/>
2、<a href="https://blog.golang.org/laws-of-reflection">https://blog.golang.org/laws-of-reflection</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang使用protobuf搭建rpc]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/02/03/golangshi-yong-protobufda-jian-rpc/"/>
    <updated>2017-02-03T19:55:10+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/02/03/golangshi-yong-protobufda-jian-rpc</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Go并发模型之Context]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/18/gobing-fa-mo-xing-zhi-context/"/>
    <updated>2017-01-18T15:26:37+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/18/gobing-fa-mo-xing-zhi-context</id>
    <content type="html"><![CDATA[<p>Go语言中go和channel是开发高并发程序的基础。我们使用channel进行goroutine程序通讯，传送数据和控制信号，<a href="https://blog.golang.org/pipelines">Pipelines and Cancelation</a>向我们讲解了如何利用Done通道来向goroutine发送结束信号：</p>

<pre><code>func main() {
    var done = make(chan struct {})
    go func(done chan struct{}) {
        select {
        case &lt;- done:
            fmt.Println("receive exit signal")
        }
    }(done)

    done &lt;- struct {}{}
    time.Sleep(3 * time.Second)
}
</code></pre>

<p>在Go服务端，每一个请求都对应会有一个goroutine进行处理。处理函数通常又会开启另外的goroutine去访问后段服务，比如数据库和RPC服务。对应一个请求创建的这一系列的goroutine通常会需要访问请求相关的信息，比如终端用户名，授权token和请求的deadline等等。当一个请求被取消或者处理超时，与这个请求相关的一些列goroutine应该尽快退出，以便系统回收资源。<br/>
Go中<code>context</code>包提供了这样的功能，利用context包可以进行请求范围内的数据传递，发送请求信号和deadline查看。本文简单示例如何使用<code>context</code>包进行goroutine并发编程。</p>

<!-- more -->


<h2>Context</h2>

<p><code>Context</code>接口定义如下：</p>

<pre><code>// A Context carries a deadline, cancelation signal, and request-scoped values
// across API boundaries. Its methods are safe for simultaneous use by multiple
// goroutines.
type Context interface {
    // Done returns a channel that is closed when this Context is canceled
    // or times out.
    Done() &lt;-chan struct{}

    // Err indicates why this context was canceled, after the Done channel
    // is closed.
    Err() error

    // Deadline returns the time when this Context will be canceled, if any.
    Deadline() (deadline time.Time, ok bool)

    // Value returns the value associated with key or nil if none.
    Value(key interface{}) interface{}
}
</code></pre>

<p><code>Context</code>接口包含四个方法。<br/>
当Context被取消或者超时时，<code>Done</code>返回的通道将会被关闭。<br/>
<code>Err</code>函数返回关闭原因。  <br/>
<code>Deadline</code>返回Context将要被取消的时间，如果设置了超时时间的话,程序可以利用Deadline的返回值判断是否需要有必要开始操作，或者利用返回值设置I/O超时时间。<br/>
<code>Value</code>方法返回与key相对应的value数据。<br/>
<code>Context</code>接口是并发安全的。可以将同一个Context对象传递给任意goroutine。</p>

<h3>派生contexts</h3>

<p>context包提供函数从已存在Conext接口对象派生新接口对象。这些对象形成了一个树，当一个Context被取消时，所有从此Context对象派生的对象都被取消。<br/>
<code>Background</code>是任何Context树的根；Background永远不会被取消</p>

<pre><code>// Background returns an empty Context. It is never canceled, has no deadline,
// and has no values. Background is typically used in main, init, and tests,
// and as the top-level Context for incoming requests.
func Background() Context
</code></pre>

<p><code>WithCancle</code>和<code>WithTimeout</code>返回一个可以比parent Context更早取消的Context接口对象。</p>

<h3>WithCancle示例</h3>

<pre><code>func f1(ctx context.Context) {
    fmt.Println("f1 running...")
    withCancel, cancel := context.WithCancel(ctx)
    defer cancel()
    go f2(withCancel)
    // wait f2 to run
    time.Sleep(time.Second)
    fmt.Println("f1 cancel f2", )
    cancel()
    ticker := time.NewTicker(time.Second)
    for ; ;  {
        select {
        case &lt;- ctx.Done():
            fmt.Println("f1, parent call canceled", ctx.Err())
        case t := &lt;- ticker.C:
            fmt.Println("f1 running at ", t)
        }

    }
}

func f2(ctx context.Context)  {
    fmt.Println("f2 running...")
    ticker := time.NewTicker(time.Second)
    for ; ;  {
        select {
        case &lt;- ctx.Done():
            fmt.Println("f2, parent call canceled", ctx.Err())
            return
        case t := &lt;- ticker.C:
            fmt.Println("f2 running at", t)
        }
    }
}

func main()  {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    go f1(ctx)
    for {
        time.Sleep(5 * time.Second)
    }
    //cancel()
    //time.Sleep(5 * time.Second)
}
</code></pre>

<p><code>WithCancel</code>从parent派生出一个新Context接口对象和一个CancelFunc函数。调用CancelFunc函数时关闭<code>Done</code>返回的通道，通知子goroutine退出。</p>

<h3>WithDeadline</h3>

<p><code>WithDeadline</code> 返回一个Context接口对象，当设置的deadline时间到达时，<code>Context</code>对象<code>Done</code>可读。</p>

<pre><code>func main()  {
    n := time.Now()
    ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(5 * time.Second))
    defer cancel()
    ticker := time.NewTicker(1 * time.Second)
    for {
        select {
        case &lt;-ticker.C:
            fmt.Println("ticker timeout")
        case &lt;-ctx.Done():
            fmt.Println("context timeout", time.Since(n))
            return
        }
    }
}                                                                                                }
</code></pre>

<h3>WithTimeout示例</h3>

<p><code>WithTimeout</code>与<code>WithDeadline</code>类似，当设置的超时时间到达时，<code>Done</code>可读  <br/>
    func main()  {
        ctx, cancel := context.WithTimeout(context.Background(), 5 * time.Second)
        defer cancel()
        ticker := time.NewTicker(1 * time.Second)
        for {
            select {
            case &lt;-ticker.C:
                fmt.Println(&ldquo;ticker timeout&rdquo;)
            case &lt;-ctx.Done():
                fmt.Println(&ldquo;context timeout&rdquo;)
                return
            }
        }
    }</p>

<h3>WithValue示例</h3>

<p>使用<code>WithValue</code>来传递请求相关数据</p>

<pre><code>func WithValue(parent Context, key, val interface{}) Context
func main()  {
    ctx := context.WithValue(context.Background(), "test", "value")
    go func(ctx context.Context) {
        fmt.Println(ctx.Value("test"))
    }(ctx)
    time.Sleep(5 * time.Second)
}
</code></pre>

<h2>参考</h2>

<p>更多关于Go并发模型的讲解：<br/>
<a href="https://blog.golang.org/pipelines">Go Concurrency Patterns: Pipelines and cancellation</a>         <br/>
<a href="http://talks.golang.org/2012/concurrency.slide#1">Go Concurrency Patterns</a>         <br/>
<a href="http://blog.golang.org/advanced-go-concurrency-patterns">Advanced Go Concurrency Patterns</a>      <br/>
<a href="https://blog.golang.org/context">Go Concurrency Patterns: Context</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Go命令详解]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/13/golang-goming-ling-xiang-jie/"/>
    <updated>2017-01-13T19:17:12+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/13/golang-goming-ling-xiang-jie</id>
    <content type="html"><![CDATA[<h1>go命令</h1>

<p><a href="#compile">Compile packages and dependencies</a>    <br/>
<a href="#clean">Remove object files</a><br/>
<a href="#testing">Description of testing flags</a></p>

<p><code>Go</code>工具用来管理Go语音源代码。
使用：</p>

<pre><code>go command [arguments]
</code></pre>

<p>命令为：</p>

<pre><code>build       compile packages and dependencies
clean       remove object files
doc         show documentation for package or symbol
env         print Go environment information
fix         run go tool fix on packages
fmt         run gofmt on package sources
generate    generate Go files by processing source
get         download and install packages and dependencies
install     compile and install packages and dependencies
list        list packages
run         compile and run Go program
test        test packages
tool        run specified go tool
version     print Go version
vet         run go tool vet on packages
</code></pre>

<p>使用<code>go help [command]</code>查看命令相信信息。<br/>
更多topic：</p>

<pre><code>c           calling between Go and C
buildmode   description of build modes
filetype    file types
gopath      GOPATH environment variable
environment environment variables
importpath  import path syntax
packages    description of package lists
testflag    description of testing flags
testfunc    description of testing functions
</code></pre>

<p>使用<code>go help [topic]</code>查看topic帮助信息</p>

<!-- more -->


<h2><a name="compile"></a>编译包及其依赖</h2>

<p>使用：</p>

<pre><code>go build [-o output] [-i] [build flags] [packages]
</code></pre>

<p><code>Build</code>编译包，及其依赖，但是不进行安装。</p>

<p>如果输入的是一些.go文件，build认为是编译由这些文件组成的单独包。
当单独编译main包时，build将可执行程序写入输出文件，输出文件以列出的第一个.go源文件名称命名，或者以main包源文件所在的文件夹名称命名，Windows环境下，可执行成后后缀为.exe。</p>

<p>当编译多个包或者一个非main包，build命令只是编译这些包，丢弃结果文件，只是查看包是否能够编译成功。</p>

<p>编译包时，build忽略以<code>_test.go</code>为后缀的文件。</p>

<p><code>-o</code>参数，可以用来指定编译结果存放路径。<br/>
<code>-i</code>参数，设置将目标程序依赖的包进行安装。</p>

<p>build 标志是<code>build,clean,get,install,list,run,test</code>共享的：</p>

<pre><code>-a
    force rebuilding of packages that are already up-to-date.
-n
    print the commands but do not run them.
-p n
    the number of programs, such as build commands or
    test binaries, that can be run in parallel.
    The default is the number of CPUs available.
-race
    enable data race detection.
    Supported only on linux/amd64, freebsd/amd64, darwin/amd64 and windows/amd64.
-msan
    enable interoperation with memory sanitizer.
    Supported only on linux/amd64,
    and only with Clang/LLVM as the host C compiler.
-v
    print the names of packages as they are compiled.
-work
    print the name of the temporary work directory and
    do not delete it when exiting.
-x
    print the commands.

-asmflags 'flag list'
    arguments to pass on each go tool asm invocation.
-buildmode mode
    build mode to use. See 'go help buildmode' for more.
-compiler name
    name of compiler to use, as in runtime.Compiler (gccgo or gc).
-gccgoflags 'arg list'
    arguments to pass on each gccgo compiler/linker invocation.
-gcflags 'arg list'
    arguments to pass on each go tool compile invocation.
-installsuffix suffix
    a suffix to use in the name of the package installation directory,
    in order to keep output separate from default builds.
    If using the -race flag, the install suffix is automatically set to race
    or, if set explicitly, has _race appended to it.  Likewise for the -msan
    flag.  Using a -buildmode option that requires non-default compile flags
    has a similar effect.
-ldflags 'flag list'
    arguments to pass on each go tool link invocation.
-linkshared
    link against shared libraries previously created with
    -buildmode=shared.
-pkgdir dir
    install and load all packages from dir instead of the usual locations.
    For example, when building with a non-standard configuration,
    use -pkgdir to keep generated packages in a separate location.
-tags 'tag list'
    a list of build tags to consider satisfied during the build.
    For more information about build tags, see the description of
    build constraints in the documentation for the go/build package.
-toolexec 'cmd args'
    a program to use to invoke toolchain programs like vet and asm.
    For example, instead of running asm, the go command will run
    'cmd args /path/to/asm &lt;arguments for asm&gt;'.
</code></pre>

<p>上面列的参数标志接收以空格为分隔符的字符串列表。如果参数中包含空格，那么需要将参数用单引号或者双引号包裹。</p>

<p>使用<code>go help packages</code>查看更多关于包的信息，使用<code>go help gopath</code>查看更多关于编译和安装路径的信息，使用<code>go help c</code>查看更多关于Go和C/C++调用的帮助信息。</p>

<p><code>Build</code>依附于<code>go help gopath</code>中描述的惯例。并不是所有项目遵从惯例。使用不同构建惯例或者构建系统可能会选择使用更低层的构建工具如<code>go tool compile</code>和<code>go tool link</code>。</p>

<h2><a name="clean"></a>删除目标文件</h2>

<p>使用：</p>

<pre><code>go clean [-i] [-r] [-n] [-x] [build flags] [packages]
</code></pre>

<p>将包源代码路径中的目标文件删除。<code>go</code>命令通常在临时目录构建目标对象，所以<code>go clean</code>通常用来删除其他工具或者手动执行<code>go build</code>生成的结果文件。</p>

<p>特别的，clena命令将包源码路径下生成的如下文件删除：</p>

<pre><code>_obj/            old object directory, left from Makefiles
_test/           old test directory, left from Makefiles
_testmain.go     old gotest file, left from Makefiles
test.out         old test log, left from Makefiles
build.out        old test log, left from Makefiles
*.[568ao]        object files, left from Makefiles

DIR(.exe)        from go build
DIR.test(.exe)   from go test -c
MAINFILE(.exe)   from go build MAINFILE.go
*.so             from SWIG
</code></pre>

<p><code>-i</code>参数指定go clean 命令将go install命令安装的包文件或者二进制文件删除。 <br/>
<code>-n</code>参数指定go clean把要执行的删除命令打印，但是不实际执行。<br/>
<code>-r</code>参数指定go clean对于指定包的所有依赖进行go clean命令。<br/>
<code>-x</code>参数指定go clean在执行删除操作时将命令打印。</p>

<h2><a name="testing"></a>Description of testing flags</h2>

<pre><code>-bench regexp
    Run (sub)benchmarks matching a regular expression.
    The given regular expression is split into smaller ones by top-level '/', where each must match the corresponding part of a benchmark's identifier.
    By default, no benchmarks run. To run all benchmarks,
    use '-bench .' or '-bench=.'.

-benchmem
    Print memory allocation statistics for benchmarks.

-benchtime t
    Run enough iterations of each benchmark to take t, specified as a time.Duration (for example, -benchtime 1h30s).
    The default is 1 second (1s).

-blockprofile block.out
    Write a goroutine blocking profile to the specified file when all tests are complete.
    Writes test binary as -c would.

-blockprofilerate n
    Control the detail provided in goroutine blocking profiles by calling runtime.SetBlockProfileRate with n.
    See 'go doc runtime.SetBlockProfileRate'.
    The profiler aims to sample, on average, one blocking event every n nanoseconds the program spends blocked.  By default, if -test.blockprofile is set without this flag, all blocking events are recorded, equivalent to -test.blockprofilerate=1.

-count n
    Run each test and benchmark n times (default 1).
    If -cpu is set, run n times for each GOMAXPROCS value.
    Examples are always run once.

-cover
    Enable coverage analysis.

-covermode set,count,atomic
    Set the mode for coverage analysis for the package[s] being tested. The default is "set" unless -race is enabled, in which case it is "atomic".
    The values:
        set: bool: does this statement run?
        count: int: how many times does this statement run?
        atomic: int: count, but correct in multithreaded tests; significantly more expensive.
    Sets -cover.

-coverpkg pkg1,pkg2,pkg3
    Apply coverage analysis in each test to the given list of packages.
    The default is for each test to analyze only the package being tested.
    Packages are specified as import paths.
    Sets -cover.

-coverprofile cover.out
    Write a coverage profile to the file after all tests have passed.
    Sets -cover.

-cpu 1,2,4
    Specify a list of GOMAXPROCS values for which the tests or benchmarks should be executed.  The default is the current value of GOMAXPROCS.

-cpuprofile cpu.out
    Write a CPU profile to the specified file before exiting.
    Writes test binary as -c would.

-memprofile mem.out
    Write a memory profile to the file after all tests have passed.
    Writes test binary as -c would.

-memprofilerate n
    Enable more precise (and expensive) memory profiles by setting runtime.MemProfileRate.  See 'go doc runtime.MemProfileRate'.
    To profile all memory allocations, use -test.memprofilerate=1 and pass --alloc_space flag to the pprof tool.

-outputdir directory
    Place output files from profiling in the specified directory, by default the directory in which "go test" is running.

-parallel n
    Allow parallel execution of test functions that call t.Parallel. The value of this flag is the maximum number of tests to run simultaneously; by default, it is set to the value of GOMAXPROCS.
    Note that -parallel only applies within a single test binary.
    The 'go test' command may run tests for different packages in parallel as well, according to the setting of the -p flag
    (see 'go help build').

-run regexp
    Run only those tests and examples matching the regular expression.
    For tests the regular expression is split into smaller ones by top-level '/', where each must match the corresponding part of a test's identifier.

-short
    Tell long-running tests to shorten their run time.
    It is off by default but set during all.bash so that installing the Go tree can run a sanity check but not spend time running exhaustive tests.

-timeout t
    If a test runs longer than t, panic. The default is 10 minutes (10m).

-trace trace.out
    Write an execution trace to the specified file before exiting.

-v
    Verbose output: log all tests as they are run. Also print all text from Log and Logf calls even if the test succeeds.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang 通过http服务获取程序性能统计数据]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/08/golang-tong-guo-httpfu-wu-huo-qu-cheng-xu-xing-neng-tong-ji-shu-ju/"/>
    <updated>2017-01-08T22:55:07+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/08/golang-tong-guo-httpfu-wu-huo-qu-cheng-xu-xing-neng-tong-ji-shu-ju</id>
    <content type="html"><![CDATA[<p>Golang标准库<code>net/http/pprof</code>通过HTTP服务对外提供性能统计数据，以便<code>pprof</code>这样的可视化工具使用。</p>

<p>引入此<code>pprof</code>库向http服务注册路径处理函数。此库注册的http服务路径都是以<code>/debug/pprof</code>开头。</p>

<h2>使用方法</h2>

<h3>方式引入库</h3>

<pre><code>import _ "net/http/pprof"
</code></pre>

<h3>开启HTTP服务</h3>

<p>如果程序中已经运行了一个或者多个HTTP服务，那么就无需再开启HTTP服务，否则需要像如下代码片段，开启一个HTTP服务：</p>

<pre><code>go func() {
    log.Println(http.ListenAndServe("localhost:6060",   nil))
}()
</code></pre>

<p>其中地址也可以不绑定到localhost,可以选择监听所有端口,比如:</p>

<pre><code>go func() {
    log.Println(http.ListenAndServe(":6060",    nil))
}()
</code></pre>

<h3>获取性能数据</h3>

<p>1、查看堆栈性能数据</p>

<pre><code>go tool pprof http://localhost:6060/debug/pprof/heap
</code></pre>

<p>2、查看30s CPU性能数据</p>

<pre><code>go tool pprof http://localhost:6060/debug/pprof/profile
</code></pre>

<p>3、查看goroutine阻塞性能数据</p>

<pre><code>go tool pprof http://localhost:6060/debug/pprof/block
</code></pre>

<p>4、查看5s执行栈</p>

<pre><code>wget http://localhost:6060/debug/pprof/trace?seconds=5
</code></pre>

<p>5、查看所有可用性能数据</p>

<pre><code>浏览器打开  http://localhost:6060/debug/pprof/
</code></pre>

<p>参考：<br/>
<a href="https://golang.org/pkg/net/http/pprof/">Golang官博</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[golang创建、解压.tar.gz文件简单库]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/05/golangchuang-jian-,-jie-ya-dot-tar-dot-gzwen-jian/"/>
    <updated>2017-01-05T19:17:06+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/05/golangchuang-jian-,-jie-ya-dot-tar-dot-gzwen-jian</id>
    <content type="html"><![CDATA[<p>golang提供了<code>tar</code>包和<code>compress/gzip</code>包进行文件打包和压缩，但是没有函数同时进行打包和压缩，下面利用打包和压缩功能，实现一个简单的制作和解压.tar.gz文件的功能。</p>

<h2>tar打包功能</h2>

<p>利用tar中<code>Writer</code>和<code>Reader</code>可以实现将文件和文件夹进行打包的功能。</p>

<h3>打包</h3>

<p>创建目标文件</p>

<pre><code>f, err := os.Create(dstPath)
</code></pre>

<p>创建<code>Writer</code></p>

<pre><code>tw := tar.NewWriter(f)
</code></pre>

<p>循环遍历文件夹，写入Writer</p>

<pre><code>fileInfo, err := os.Stat(path)
if err != nil {
    return err
}
if fileInfo.Mode().IsRegular() {
    header, err := tar.FileInfoHeader(fileInfo, "")
    if err != nil {
        return err
    }
    header.Name = path
    if err = tw.WriteHeader(header); err != nil {
        return err
    }
    file, err := os.Open(path)
    if err != nil {
        return err
    }
    if _, err = io.Copy(tw, file); err != nil {
        return err
    }
}

if fileInfo.Mode().IsDir() {
    // tar each file and dir in the dir
    var file *os.File
    if file, err = os.Open(path); err != nil {
        return err
    }
    fileInfos, err := file.Readdir(0)
    if err != nil {
        return err
    }
    for _, info := range fileInfos {
        if err = tarPath(filepath.Join(path, info.Name()), tw); err != nil {
            return err
        }
    }
}
</code></pre>

<!-- more -->


<h3>解包</h3>

<p>打开源文件</p>

<pre><code>tarFile, err := os.Open(srcPath)
</code></pre>

<p>创建Reader</p>

<pre><code>tr := tar.NewReader(tarFile)
</code></pre>

<p>循环遍历解压文件</p>

<pre><code>for {
    hdr, err := tr.Next()
    if err == io.EOF {
        break
    }
    fullPath := filepath.Join(dstPath, hdr.Name)
    os.MkdirAll(filepath.Dir(fullPath), os.ModePerm)
    log.Println("fullPath", fullPath)
    file, err := os.Create(fullPath)
    if err != nil {
        return err
    }
    if _, err := io.Copy(file, tr); err != nil {
        return err
    }
    file.Close()
}
</code></pre>

<h2>Gzip压缩功能</h2>

<h3>压缩</h3>

<p>创建目标文件</p>

<pre><code>dstFile, err := os.Create(dstPath)
</code></pre>

<p>创建Writer</p>

<pre><code>gw := gzip.NewWriter(dstFile)
</code></pre>

<p>将源内容写入Writer</p>

<pre><code>if _, err = io.Copy(gw, srcFile); err != nil {
    return err
}
</code></pre>

<h3>解压</h3>

<p>打开源文件</p>

<pre><code>srcFile, err := os.Open(srcPath)
</code></pre>

<p>创建Reader</p>

<pre><code>gr, err := gzip.NewReader(srcFile)
</code></pre>

<p>进行解压</p>

<pre><code>if _, err = io.Copy(dstFile, gr); err != nil {
    return err
}
</code></pre>

<h2>.tar.gz文件</h2>

<p>将上面tar包进行打包和解包湿的的<code>io.Writer</code>和 <code>io.Reader</code>实参传入<code>gzip.Writer</code>和<code>gzip.Reader</code> ，即可将打包的目的文件进行压缩和解包时的源文件进行解压</p>

<h3>打包压缩</h3>

<pre><code>func Targz(srcPath, dstPath string) error {
dstFile, err := os.Create(dstPath)
if err != nil {
    return err
}
defer dstFile.Close()
gw := gzip.NewWriter(dstFile)
defer gw.Close()
tw := tar.NewWriter(gw)
defer tw.Close()
if err = tarPath(srcPath, tw); err != nil {
    dstFile.Close()
    os.Remove(dstPath)
    return err
}
return nil
</code></pre>

<p>}</p>

<h3>解压解包</h3>

<pre><code>srcFile, err := os.Open(srcPath)
if err != nil {
    return err
}
gr, err := gzip.NewReader(srcFile)
if err != nil {
    return err
}
tr := tar.NewReader(gr)
for {
    hdr, err := tr.Next()
    if err == io.EOF {
        break
    }
    fullPath := filepath.Join(dstPath, hdr.Name)
    os.MkdirAll(filepath.Dir(fullPath), os.ModePerm)
    file, err := os.Create(fullPath)
    if err != nil {
        return err
    }
    if _, err := io.Copy(file, tr); err != nil {
        return err
    }
    file.Close()
}
</code></pre>

<h3>备注</h3>

<p>完整源代码请参考<a href="https://github.com/jintao-zero/targz">targz</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang Cpu性能优化]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/01/golang-cpuxing-neng-you-hua/"/>
    <updated>2017-01-01T17:18:20+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/01/golang-cpuxing-neng-you-hua</id>
    <content type="html"><![CDATA[<p>本文根据<a href="https://blog.golang.org/profiling-go-programs">Profiling Go Programs</a>文章，进行演示如何利用Golang性能工具进行cpu性能统计和优化。</p>

<h2>准备工作</h2>

<p>1、Golang编译运行环境。</p>

<pre><code>go version go1.7 darwin/amd64
</code></pre>

<p>2、下载<a href="https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/benchgraffiti/source-archive.zip">测试源码</a></p>

<pre><code>-rw-r--r-- 1 jintao staff 16594  1  1 16:58 havlak1.go
-rw-r--r-- 1 jintao staff 16597  1  1 16:58 havlak2.go
-rw-r--r-- 1 jintao staff 16832  1  1 16:58 havlak3.go
-rw-r--r-- 1 jintao staff 16905  1  1 16:58 havlak4.go
-rw-r--r-- 1 jintao staff 17501  1  1 16:58 havlak5.go
-rw-r--r-- 1 jintao staff  9467  1  1 16:58 havlak6.go
</code></pre>

<p>havlak1-6是源文件，以及优化后的源文件</p>

<h2>采集CPU性能数据</h2>

<p>优化程序之前，需要采集性能数据。多种方法可以使用，本文中采用的方法是引入<code>runtime/pprof</code>包，在代码文件main函数中添加如下代码片段:</p>

<pre><code>var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to file")

func main() {
    flag.Parse()
    if *cpuprofile != "" {
        f, err := os.Create(*cpuprofile)
        if err != nil {
          log.Fatal(err)
        }
        pprof.StartCPUProfile(f)
        defer pprof.StopCPUProfile()
    }
    ... 
</code></pre>

<p>利用flag包设置并解析cpuprofile参数，传入文件名，创建文件，调用<code>ppfof.StartCPUProfile</code>方法开始进行采样，并将采样结果保存在文件中，在程序返回之前调用<code>pprof.StopCPUProfile</code>方法确保所有采样数据刷新到结果文件中。</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ time ./havlak1 -cpuprofile=havlak1.prof
# of loops: 76000 (including 1 artificial root node)

real    0m21.768s
user    0m31.026s
sys 0m0.284s
</code></pre>

<p>产生性能文件havlak1.prof</p>

<!-- more -->


<h2>分析性能文件</h2>

<p><code>go tool pprof</code>是<a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools">Google&rsquo;s pprof C++ profiler</a>一个变种，利用go tool pprof命令读取分析性能文件:</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go tool pprof havlak1 havlak1.prof
Entering interactive mode (type "help" for commands)
(pprof)
</code></pre>

<p>输入<code>help</code>可以查看哪些可用命令，最常用是<code>top n</code>命令，查看前n个样本：</p>

<pre><code>(pprof) top
18750ms of 27430ms total (68.36%)
Dropped 95 nodes (cum &lt;= 137.15ms)
Showing top 10 nodes out of 80 (cum &gt;= 790ms)
      flat  flat%   sum%        cum   cum%
    3360ms 12.25% 12.25%     6790ms 24.75%  runtime.scanobject
    2890ms 10.54% 22.79%    14430ms 52.61%  main.FindLoops
    2470ms  9.00% 31.79%     2760ms 10.06%  runtime.mapaccess1_fast64
    1950ms  7.11% 38.90%     5140ms 18.74%  runtime.mapassign1
    1690ms  6.16% 45.06%     4080ms 14.87%  runtime.mallocgc
    1630ms  5.94% 51.00%     1630ms  5.94%  runtime.heapBitsForObject
    1580ms  5.76% 56.76%     3440ms 12.54%  main.DFS
    1250ms  4.56% 61.32%     1250ms  4.56%  runtime.memmove
    1140ms  4.16% 65.48%     1890ms  6.89%  runtime.greyobject
     790ms  2.88% 68.36%      790ms  2.88%  runtime/internal/atomic.Or8
(pprof)
</code></pre>

<p>启动性能分析时，Go程序每秒钟停止100次并对当前正在执行的goroutine调用栈进行采样。从上面数据可以看到，程序总执行时间为27430ms，采样top10函数一共占用18750ms（68.36%）。每行是一个函数的统计数据，前两列数据分别为采样时goroutine正在当前函数中的时间和占比，后两列为采样时此函数出现（正在执行或正在等待调用函数返回）的时间和占比。sum%列为前n行消耗时间之和对于总时间的占比。<code>main.FindLoops</code>函数正在执行的时间是2890ms占10.54%，在调用栈中出现的时间为14430ms占比为52.61%。<code>runtime.mapaccess1_fast64</code>执行的时间为2470ms占9.00%，在调用栈中出现的时间为2760ms占比为10.06%。使用-cum参数，按照第四第五列排序</p>

<pre><code>(pprof) top5 -cum
2.89s of 27.43s total (10.54%)
Dropped 95 nodes (cum &lt;= 0.14s)
Showing top 5 nodes out of 80 (cum &gt;= 14.43s)
  flat  flat%   sum%        cum   cum%
     0     0%     0%     22.79s 83.08%  runtime.goexit
     0     0%     0%     14.52s 52.93%  main.main
     0     0%     0%     14.52s 52.93%  runtime.main
     0     0%     0%     14.43s 52.61%  main.FindHavlakLoops
 2.89s 10.54% 10.54%     14.43s 52.61%  main.FindLoops
(pprof)
</code></pre>

<p>调用栈采样数据中关于函数间的调用关系可以有其他的有趣方式进行展现。比如<code>web</code>命令输出一个图片并用浏览器打开。<code>gv</code>命令写PostScript并在Ghostview中打开。</p>

<pre><code>(pprof) web
(pprof)
</code></pre>

<p>以下为图片部分截图： <br/>
<img src="http://jintao-zero.github.io/images/havlak1.png" alt="web" />
    图中每个方块对应一个单独函数，方块的大小与函数消耗的时间相对应。从X到Y的边显示X调用Y；边上的数字代表在被调用函数中消耗的时间。从图中我们可以发现在runtime.mapaccess1_fast64和runtime.mapassign1函数上消耗了较多时间。<br/>
    可以只显示包含某个函数的调用关系图：</p>

<pre><code>(pprof) web mapaccess
(pprof)
</code></pre>

<p><img src="http://jintao-zero.github.io/images/havlak1-mapaccess.png" alt="mapaccess" /><br/>
从上图我们可以发现主要是main.DFS和main.FindLoops函数调用了runtime.mapaccess<br/>
接下来重点分析<code>main.DFS</code>和<code>main.FindLoops</code>两个函数的时间消耗情况：</p>

<pre><code>(pprof) list DFS
Total: 27.43s
ROUTINE ======================== main.DFS in /Users/jintao/Project/opensource/benchgraffiti/havlak_new/havlak1.go
     1.58s      6.84s (flat, cum) 24.94% of Total
         .          .    235:   return false
         .          .    236:}
         .          .    237:
         .          .    238:// DFS - Depth-First-Search and node numbering.
         .          .    239://
      20ms       20ms    240:func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
     140ms      140ms    241:   nodes[current].Init(currentNode, current)
         .      310ms    242:   number[currentNode] = current
         .          .    243:
         .          .    244:   lastid := current
        1s         1s    245:   for _, target := range currentNode.OutEdges {
     160ms      1.31s    246:       if number[target] == unvisited {
      40ms      3.44s    247:           lastid = DFS(target, nodes, number, last, lastid+1)
         .          .    248:       }
         .          .    249:   }
     200ms      600ms    250:   last[number[currentNode]] = lastid
      20ms       20ms    251:   return lastid
         .          .    252:}
         .          .    253:
         .          .    254:// FindLoops
         .          .    255://
         .          .    256:// Find loops and build loop forest using Havlak's algorithm, which
(pprof)
</code></pre>

<p><code>list DFS</code> 会列出所有匹配DFS函数名的函数。从上面的代码我们发现耗时的语句分别在<code>242 246 247 250</code>行其中 247行是与DFS行数调用有关，其他三行都是与number变量有关，number是一个map数据结构，可以考虑改为采用slice，使用block number作为索引。</p>

<p>对文件进行修改，diff修改如下：</p>

<pre><code>240c240
&lt; func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
---
&gt; func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number []int, last []int, current int) int {
242c242
&lt;   number[currentNode] = current
---
&gt;   number[currentNode.Name] = current
246c246
&lt;       if number[target] == unvisited {
---
&gt;       if number[target.Name] == unvisited {
250c250
&lt;   last[number[currentNode]] = lastid
---
&gt;   last[number[currentNode.Name]] = lastid
271c271
&lt;   number := make(map[*BasicBlock]int)
---
&gt;   number := make([]int, size)
287c287
&lt;       number[bb] = unvisited
---
&gt;       number[bb.Name] = unvisited
315c315
&lt;               v := number[nodeV]
---
&gt;               v := number[nodeV.Name]
</code></pre>

<p>测试修改后的cpu性能：</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go build havlak2.go
MacBook-Pro-2:havlak_new jintao$ time ./havlak2 -   cpuprofile=havlak2.prof
# of loops: 76000 (including 1 artificial root node)

real    0m11.685s
user    0m19.647s
sys 0m0.268s
</code></pre>

<p>再次使用go tool profile工具查看topn数据：</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go tool pprof havlak2 havlak2.prof
Entering interactive mode (type "help" for commands)
(pprof) top
11460ms of 16610ms total (68.99%)
Dropped 92 nodes (cum &lt;= 83.05ms)
Showing top 10 nodes out of 87 (cum &gt;= 540ms)
   flat  flat%   sum%        cum   cum%
2950ms 17.76% 17.76%     5630ms 33.90%  runtime.scanobject
1500ms  9.03% 26.79%     4100ms 24.68%  runtime.mallocgc
1260ms  7.59% 34.38%     1260ms  7.59%  runtime.heapBitsForObject
1250ms  7.53% 41.90%     8700ms 52.38%  main.FindLoops
 920ms  5.54% 47.44%     1450ms  8.73%  runtime.greyobject
 920ms  5.54% 52.98%     2120ms 12.76%  runtime.mapassign1
 770ms  4.64% 57.62%      780ms  4.70%  runtime.heapBitsSetType
 760ms  4.58% 62.19%      760ms  4.58%  runtime.memmove
 590ms  3.55% 65.74%     1500ms  9.03%  runtime.makemap
 540ms  3.25% 68.99%      540ms  3.25%  runtime/internal/atomic.Or8
(pprof)
</code></pre>

<p>从上面可以看到<code>main.DFS</code>已经不在topn列表上，其他函数的时间也在显著下降。现在累计有24.68%的时间用在分配内存和垃圾回收（<code>runtime.mallocgc</code>）。下面需要使用进行内存性能优化。</p>

<h2>参考</h2>

<p>1、<a href="https://blog.golang.org/profiling-go-programs">Golang官方博客</a><br/>
2、<a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools">C++ pprof</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang日期转化处理]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/10/30/golangri-qi-zhuan-hua-chu-li/"/>
    <updated>2016-10-30T22:13:12+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/10/30/golangri-qi-zhuan-hua-chu-li</id>
    <content type="html"><![CDATA[<p>golang中time包提供了时间操作函数。</p>

<h2>获取时间</h2>

<pre><code>type Time struct {
    // contains filtered or unexported fields
}

func Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time
func Now() Time
</code></pre>

<p>一个Time结构体代表一个纳米精度的时间实例。now函数可以获取当前时间：</p>

<pre><code>now := time.Now()
fmt.Println(now)
</code></pre>

<p>结果如下：</p>

<pre><code>2016-11-27 22:46:17.666418725 +0800 CST 
</code></pre>

<!-- more -->


<h2>格式化时间</h2>

<pre><code>func (t Time) Format(layout string) string
</code></pre>

<p>Format方法可以按照layout定义的格式格式化时间字符串。<br/>
Golang中以2006 01 02 03 04 05 分别定义年、月、日 时、分、秒字段，03的24表示法为15。<br/>
比如将当前时间格式化为YYYY-mm-dd hh:MM:ss，则layout为<code>2006-01-02 15:04:05</code></p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
</code></pre>

<p> 输出为：</p>

<pre><code>2016-11-27 22:56:40
</code></pre>

<p>控制精度的方法为在秒后面加0, 000、000000、000000000分别代表毫秒、微秒、纳秒：</p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
fmt.Println(now.Format("2006-01-02 15:04:05.000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000000"))
</code></pre>

<p>输出：</p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
fmt.Println(now.Format("2006-01-02 15:04:05.000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000000"))
</code></pre>

<h2>解析时间</h2>

<pre><code>func Parse(layout, value string) (Time, error)
func ParseInLocation(layout, value string, loc *Location) (Time, error)
</code></pre>

<p>Parse函数将格式化字符串解析为一个时间实例。<code>layout</code>定义了时间字符串的表现格式，比如：</p>

<pre><code>Mon Jan 2 15:04:05 -0700 MST 2006
</code></pre>

<p>当待解析时间字符串中没有时区时，<code>Parse</code>默认按照<code>UTC</code>时区解析时间。<code>ParseInLocation</code>按照loc参数指定的的location解析时间。</p>

<h2>定时器</h2>

<p>定时器通过<code>NewTimer</code>或者<code>AfterFunc</code>创建，用AfterFunc创建的定时器超时后，在定时器goroutine中调用func函数，其他定时器则通过C通道发送一个时间对象。</p>

<pre><code>type Timer struct {
    C &lt;-chan Time
    // contains filtered or unexported fields
}

func AfterFunc(d Duration, f func()) *Timer  
func NewTimer(d Duration) *Timer
</code></pre>

<p>定时器在使用过程中需要注意<code>Reset</code>和<code>Stop</code>方法的使用：</p>

<pre><code>func (t *Timer) Stop() bool
</code></pre>

<p>Stop方法用来停止定时器触发。停止定时器则返回true，如果定时器已经超时或者已经被停止则返回false。Stop方法不关闭定时器中的channel。<br/>
为了防止调用Stop方法后，定时器仍然触发，需要检查方法返回值并且读取定时器时间channel，代码片段：</p>

<pre><code>if !t.Stop() {
    &lt;-t.C
}

func (t *Timer) Reset(d Duration) bool
</code></pre>

<p><strong>需要特别注意的是，不要并发执行上面的代码。</strong></p>

<p>Reset修改定时器的超时时间为d。修改成功则返回true，如果定时器已经超时或者被停止则返回false。</p>

<pre><code>func (t *Timer) Reset(d Duration) bool
</code></pre>

<p>为了重复一个已经激活的定时器，需要先调用定时器<code>Stop</code>方法，如果定时器已经超时，则例如一下代码片段，先读取channel中的时间：</p>

<pre><code>if !t.Stop() {
    &lt;-t.C
}
t.Reset(d)
</code></pre>

<p><strong>需要特别注意的是，不要并发执行上面的代码。</strong>  <br/>
在读取通道和定时器超时之间存在竞态条件，所以几乎不可能正确使用Reset方法的返回值。Reset方法应该总是与Stop方法一起使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grep命令]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/10/05/grepming-ling/"/>
    <updated>2016-10-05T20:48:14+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/10/05/grepming-ling</id>
    <content type="html"><![CDATA[<h1>grep命令</h1>

<p>grep, egrep, fgrep, zgrep, zegrep, zfgrep 文件模式搜索</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]] [-e pattern] [-f file] [--binary-files=value] [--color[=when]]
</span><span class='line'>          [--colour[=when]] [--context[=num]] [--label] [--line-buffered] [--null] [pattern] [file ...]</span></code></pre></td></tr></table></div></figure>


<p>grep搜索输入文件，输出匹配一个或者多个模式的文件行。通常情况，不包括结尾换行符的文件行匹配指定模式中的表达式即为匹配成功。空表达式匹配所有行。匹配行将会打印到标准输出。<br/>
grep命令用于简单模式和基本正则表达式（BRES）；egrep命令可以处理扩展正则表达式。查看re_format(7）关于正则表达式的详细信息。fgre较grep和egrep更快，但是只能处理固定模式（比如，它不能解析正则表达式）。匹配模式可以由一行或者多行组成，以便于匹配输入内容的一部分。<br/>
zgrep，zegrep，zfgrep分别与grep，egrep，fgrep功能类似，只是可以接收由compress或者gzip压缩工具压缩过的文件作为输入。</p>

<!-- more -->


<h2>参数</h2>

<pre><code>-A num, --after-context=num
</code></pre>

<p>打印匹配行后面的num行文本，与-B和-C选项功能类似</p>

<pre><code>-a, --text
</code></pre>

<p>将所有输入当作文本文件处理。如果文件包含二进制字符，grep简单打印<code>Binary file ... matches</code>。使用这个参数强制grep输出匹配行。</p>

<pre><code>-B num, --before-context=num
</code></pre>

<p>打印每个匹配行前面num行文本。</p>

<pre><code>-b, --byte-offset  
</code></pre>

<p>打印匹配模式在文件中的字节偏移数</p>

<pre><code>-C[num, --context=num]
</code></pre>

<p>指定打印匹配行前后文本行数。默认为2，相当于设置-A 2 -B 2</p>

<pre><code>-c, --count
</code></pre>

<p>只向标准输出打印匹配文本行的行数</p>

<pre><code>--colour=[when, --color=[when]]
</code></pre>

<p>打印时，用GREP_COLOR环境变量里面保存的颜色设置标记匹配到的模式</p>

<pre><code>-D action, --devices=action
</code></pre>

<p>为devices，FIFOS和sockets指定动作。默认动作是读，把他们当作普通文件处理。如果action指定为skip，这些设备将会被跳过。</p>

<pre><code>-d action, --directories=action
</code></pre>

<p>为目录指定特殊的动作。默认是读动作，把目录当作普通文件处理。<code>skip</code>动作是默默跳过目录，<code>recurse</code>动作是循环读取目录。</p>

<pre><code>-E, --extended-regexp
</code></pre>

<p>按照扩展正则表达式来解析pattern模式（强制grep表现为egrep）</p>

<pre><code>-e pattern, --regexp=pattern
</code></pre>

<p>指定匹配用的模式。可以多次使用-e选项来指定多个模式串</p>

<pre><code>--exclude
</code></pre>

<p>使用此选项将匹配参数模式的文件去除，不尽兴模式串的匹配。</p>

<pre><code>--exclude-dir
</code></pre>

<p>将某些目录去除，不进行模式匹配</p>

<pre><code>-F, --fixed-strings
</code></pre>

<p>将模式解析为固定字符串集合（强制grep为fgrep）</p>

<pre><code>-f file, --file=file
</code></pre>

<p>从file文件中读取匹配用的模式串</p>

<pre><code>-G, --basic-regexp
</code></pre>

<p>按照基本正则表达式解析模式串（强制grep工作模式为传统grep）</p>

<pre><code>-H
</code></pre>

<p>在匹配文本行前头打印所属文件名</p>

<pre><code>-h, --no-filename
</code></pre>

<p>在匹配文本行前头不打印文件名</p>

<pre><code>--help
</code></pre>

<p>打印简要帮助信息</p>

<pre><code>-I
</code></pre>

<p>忽略二进制文件</p>

<pre><code>-i, --ignore-case
</code></pre>

<p>进行大小无关匹配，grep默认是大小相关</p>

<pre><code>--include
</code></pre>

<p>指定符合文件名模式的文件进行模式匹配</p>

<pre><code>--include-dir
</code></pre>

<p>如果指定-R参数，只有符合模式的目录才进行模式匹配</p>

<pre><code>-J, --bz2decompress
</code></pre>

<p>进行文本匹配之前，解压bzip压缩过的文件</p>

<pre><code>-L, --files-without-match
</code></pre>

<p>只打印不包含指定模式文本行文件的文件名</p>

<pre><code>-l, --files-with-matches
</code></pre>

<p>只打印包含指定模式文本行文件的文件名，不打印文本行</p>

<pre><code>--mmap
</code></pre>

<p>使用mmap代替read来读取输入，在某些环境下能够达到更高性能，也可能引起为定义行为</p>

<pre><code>-m num, --max-count=num
</code></pre>

<p>达到<code>num</code>处匹配后，停止继续读取输入</p>

<pre><code>-n, --line-number
</code></pre>

<p>输出结果时，每行前面打印匹配行在文件中的行数。</p>

<pre><code>--null
</code></pre>

<p>打印文件名时，后面跟零字节</p>

<pre><code>-O
</code></pre>

<p>8888</p>

<pre><code>-o, --only-matching
</code></pre>

<p>只打印每行中匹配的部分</p>

<pre><code>-p
</code></pre>

<p>如果指定<code>-R</code>选项，不跟随符号链接，这个是默认选项</p>

<pre><code>-q, --quiet, --silent
</code></pre>

<p>安静模式：压制正常输出。grep程序只是搜索文件，直到达到一个匹配，使grep命令更少的花销。</p>

<pre><code>-R, -r, --recursive
</code></pre>

<p>循环搜索子文件夹</p>

<pre><code>-S
</code></pre>

<p>如果指定<code>-R</code>参数，所有符号连接也会参与匹配，默认不匹配符号连接</p>

<pre><code>-s, --no-messages
</code></pre>

<p>安静模式。不存在或者不可达的文件将被忽略</p>

<pre><code>-U, --binary
</code></pre>

<p>搜索二进制文件，但是不尝试打印他们</p>

<pre><code>-V, --version
</code></pre>

<p>打印版本信息</p>

<pre><code>-v, --invert-match
</code></pre>

<p>搜索不匹配给定模式的行文本</p>

<pre><code>-w, --word-regexp
</code></pre>

<p>表达式被当做是一个单词来进行匹配（形如被<code>[[:&lt;:]]</code>和<code>[[:&gt;:]]</code>包裹）</p>

<pre><code>-x, --line-regexp
</code></pre>

<p>只有一整行匹配给定模式才算成功匹配行</p>

<pre><code>-Z, -z, --decompress
</code></pre>

<p>强制grep像zgrep</p>

<pre><code>--binary-files=value
</code></pre>

<p>控制搜索和打印二进制文件。选项<code>binary</code>，默认选项，搜索但是不打印；<code>without-match</code>:不搜索二进制文件；<code>text</code>：将二进制文件视为文本文件</p>

<pre><code>--context[=num]
</code></pre>

<p>打印匹配行前后文本，默认是2行</p>

<pre><code>--line-buffered
</code></pre>

<p>强制输出行缓存。</p>

<h2>例子</h2>

<p>搜索一个文件中的单词</p>

<pre><code>grep 'patricia' myfile
</code></pre>

<p>所有行首包含<code>.Pp</code>的行</p>

<pre><code>grep '^\.Pp' myfile
</code></pre>

<p>搜索不包含<code>foo</code>和<code>bar</code>的所有行</p>

<pre><code>grep -v -e 'foo' -e 'bar' myfile
</code></pre>

<p>扩展正则表达式</p>

<pre><code>egrep '19|20|25' calendar
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MapReduce WordCount实例]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/03/06/mapreduce-wordcountshi-li/"/>
    <updated>2016-03-06T15:08:34+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/03/06/mapreduce-wordcountshi-li</id>
    <content type="html"><![CDATA[<p>搭建开发环境，开发mapreduce job程序，部署mapreduce程序。</p>

<h1>开发环境搭建</h1>

<p>开发mapreduce程序的环境有可能与运行环境不同，我是Windows环境上开发mapreduce job程序，编译没有错误后，打包放到hadoop集群中调试和运行。这样就要求开发环境依赖的jar包，在hadoop集群环境中存在并且版本一致。<br/>
我的开发环境是Windows＋eclipse＋maven，hadoop集群环境上部署的版本号为：</p>

<pre><code>jintao@node0:~/Project$ hadoop  version
Hadoop 2.7.1
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a
Compiled by jenkins on 2015-06-29T06:04Z
Compiled with protoc 2.5.0
From source with checksum fc0a1a23fc1868e4d5ee7fa2b28a58a
This command was run using /usr/local/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar
</code></pre>

<p>maven配置文件pom.xml的配置如下：</p>

<pre><code>&lt;dependencies&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
    &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
    &lt;version&gt;2.7.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>

<p>maven工程会自动将依赖的jar下载到build path中。<br/>
你也可以建立一个普通java工程，手动将依赖的jar添加到build path中，这样需要找依赖的jar，比较麻烦，但是可以让新手更快的了解mapreduce相关类分布情况。</p>

<!-- more -->


<h1>开发mapreduce job程序</h1>

<p>一般情况下，一个job包含一个map类和一个reduce类，但是也可以只有一个类，或者都不包含。本文例子中的WordCount是mapreduce程序开发的helloworld程序，包含map和reduce类，通过WordCount我们可以了解mapreduce程序开发的基本框架。</p>

<h2>Mapper</h2>

<p>map程序的基类为：</p>

<pre><code>@InterfaceAudience.Public
@InterfaceStability.Stable
public class Mapper&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; extends Object
</code></pre>

<p>Maps将输入的key/value对处理并输出一个key/value形式的中间结果集。</p>

<p>Maps是一个个独立的任务线程分别处理不同的记录集合，输出中间结果集。输出结果集的类型不一定与初始的输入记录相同。一个输入key/value对，有可能输出零个或多个key/value结果对。</p>

<p>Hadoop Map-Reduce框架对于job的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html">InputFormat</a>输入数据产生的每个<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputSplit.html">InputSplit</a>派生一个map任务。Mapper的具体实现可以通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/JobContext.html#getConfiguration(">JobContext.getConfiguration()</a>)获取job的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">Configuration配置</a>。</p>

<p>框架首先调用Mapper实现类的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#setup(org.apache.hadoop.mapreduce.Mapper.Context">setup(org.apache.hadoop.mapreduce.Mapper.Context)</a>)，然后对于对于获取的每一个输入记录，调用map方法进行处理。最后调用<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#cleanup(org.apache.hadoop.mapreduce.Mapper.Context">cleanup(org.apache.hadoop.mapreduce.Mapper.Context)</a>)。</p>

<p>框架将与某个key相关的所有value值形成一组，传给Reducer来产生最后结果。通过指定key比较类，用户可以控制key/value的排序和分组。</p>

<p>Mapper的输出结果对于每个Reducer进行分片。通过实现一个特定的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Partitioner.html">Partitioner</a>，用户可以控制keys分片到Reducer。</p>

<p>视情况，通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Job.html#setCombinerClass(java.lang.Class">Job.setCombinerClass(Class)</a>)用户可以指定一个combiner，combiner可以在Mapper本地对输出结果进行聚合，这样可以减少从Mapper传输到Reducer的数据量。</p>

<p>通过对Configuration程序可以指定是否并且如何对Mapper结果进行压缩。</p>

<p>如果reducer个数为0，那么不会对Mapper的结果不对结果进行排序，并且直接输出到<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/OutputFormat.html">OutputFormat</a>。<br/>
WordCount对应Mapper实现类如下：</p>

<pre><code>public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
    private static Logger logger = Logger.getLogger(WordCountMapper.class);

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException{
        StringTokenizer iTokenizer = new StringTokenizer(value.toString());
        while (iTokenizer.hasMoreTokens()) {
            word.set(iTokenizer.nextToken());
            context.write(word, one);
        }
    }   
}
</code></pre>

<p>应用也可以重写<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#run(org.apache.hadoop.mapreduce.Mapper.Context"> run(org.apache.hadoop.mapreduce.Mapper.Context)</a>)来更多的控制map处理，比如multi-threaded Mapper。</p>

<h2>Reducer</h2>

<p>Reducer的基类定义如下：</p>

<pre><code>@Checkpointable
@InterfaceAudience.Public
@InterfaceStability.Stable
public class Reducer&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; extends Object
</code></pre>

<p>Reducer将Mapper输出的中间结果集处理输出最终结果集。<br/>
Reducer实现类可以通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/JobContext.html#getConfiguration("> JobContext.getConfiguration()</a>)获取job的配置信息<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">Configuration</a>。<br/>
Reducer主要有三个步骤：</p>

<ol>
<li><p>Shuffle<br/>
 Reducer使用Http从个Mapper拷贝传输中间结果集到本地。</p></li>
<li><p>Sort<br/>
 框架将从不同Mapper传输过来的结果集按照key进行合并排序。</p></li>
<li>Reduce
 在这一阶段，对于每个&lt;key, (collection of values)>调用<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html#reduce(KEYIN,%20java.lang.Iterable,%20org.apache.hadoop.mapreduce.Reducer.Context">reduce(Object, Iterable, org.apache.hadoop.mapreduce.Reducer.Context)</a>)方法进行处理。<br/>
 reduce任务调用<a href="TaskInputOutputContext.write(Object,%20Object">TaskInputOutputContext.write(Object, Object)</a>)将最终结果写到<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/RecordWriter.html">RecordWriter</a>。<br/>
 Reducer的输出不是有序的。</li>
</ol>


<p>WordCount的Reduce实现类为：</p>

<pre><code>public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
            Context context) throws IOException, InterruptedException {
        int total = 0;
        for (IntWritable count : values) {
            total += count.get();
        }
        result.set(total);
        context.write(key, result);
    }
}
</code></pre>

<h2>Driver</h2>

<p>已经完成mapper和reducer的编写。接下来写一个job driver用来提交程序到hadoop中运行。<br/>
可以有两种方式编写job driver：</p>

<ol>
<li>实现一个普通Java类，在类中设置job属性信息，提交job</li>
<li>实现<a href="http://hadoop.apache.org/docs/current/api/index.html">Tool</a>接口</li>
</ol>


<p>实际应用中，我们采用实现Tool接口的方式，这种方式能够更好的控制程序运行。<br/>
WordCount Job的属性设置如下：</p>

<pre><code>public class WordCountDriver extends Configured implements Tool {

    public int run(String[] arg0) throws Exception {
        // TODO Auto-generated method stub
        if (arg0.length != 2) {
            System.err.printf("Usage: %s [generic options] &lt;input&gt; &lt;output&gt;\n", 
                    getClass().getSimpleName());
            ToolRunner.printGenericCommandUsage(System.err);
            return -1;
        }

        //Create new job
        Job job = Job.getInstance();
        job.setJarByClass(getClass());

        job.setJobName("WordCount");

        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        job.setNumReduceTasks(1);

        FileInputFormat.addInputPath(job, new Path(arg0[0]));
        FileOutputFormat.setOutputPath(job, new Path(arg0[1]));

        return job.waitForCompletion(true) ? 0 : 1;
    }   

    public static void main(String[] args) {
        // TODO Auto-generated method stub
        try {
            int exitCode = ToolRunner.run(new WordCountDriver(), args);
            System.exit(exitCode);
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
    }

}   
</code></pre>

<p>WordCountDriver实现了Tool接口，这样我们运行程序时可以使用GenericOptionParser支持的参数项。<br/>
调用Job.getInstance()获取一个Job实例。设置Job名称。设置输入路径和输出路径。设置mapper和reducer类名。设置输出key和value类型（输入类型由数据源格式确定，数据源缺省为TextInputFormat文本格式，默认key类型为LongWritable，value类型为Text）。</p>

<h2>本地运行WordCount</h2>

<p>将程序打成jar包，放到hadoop集群一台机器上去。在jar包文件所在目录，新建一个input目录，input目录中放置一个文本文件words.txt，运行以下命令：</p>

<pre><code>$ hadoop jar hadoopjob.jar com.hugedata.jobs.WordCountDriver -fs file:/// -jt local input/ output/
</code></pre>

<p>-fs file:///指定使用本地文件系统，-jt local 指定mapreduce任务运行在本地。<br/>
当前目录会产生一个output目录，里面有两个文件（part-r-00000、_SUCCESS），其中part-r-00000即为</p>

<pre><code>jintao@node0:~/Project$ cat output/part-r-00000
is  2
jintao  1
jintao. 1
mx  1
my  2
mz  1
name    2
name.   1
too.    1
whit's  1
your    1
</code></pre>

<h2>集群运行WordCount</h2>

<p>前提是集群环境已经运行正常。将本地目录下的input拷贝到hdfs上：</p>

<pre><code>jintao@node0:~/Project$ hdfs dfs -put input
jintao@node0:~/Project$ hdfs dfs -ls
Found 2 items
drwxr-xr-x   - jintao supergroup          0 2016-03-07 16:51 input
drwxr-xr-x   - jintao supergroup          0 2016-03-05 14:04 tmp
</code></pre>

<p>屏幕上打印的过程信息如下：</p>

<pre><code>16/03/07 16:55:18 INFO client.RMProxy: Connecting to ResourceManager at node0/192.168.88.120:8032
16/03/07 16:55:20 INFO input.FileInputFormat: Total input paths to process : 1
16/03/07 16:55:20 INFO mapreduce.JobSubmitter: number of splits:1
16/03/07 16:55:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457076326520_0001
16/03/07 16:55:21 INFO impl.YarnClientImpl: Submitted application application_1457076326520_0001
16/03/07 16:55:21 INFO mapreduce.Job: The url to track the job: http://node0:8088/proxy/application_1457076326520_0001/
16/03/07 16:55:21 INFO mapreduce.Job: Running job: job_1457076326520_0001
16/03/07 16:55:32 INFO mapreduce.Job: Job job_1457076326520_0001 running in uber mode : false
16/03/07 16:55:32 INFO mapreduce.Job:  map 0% reduce 0%
16/03/07 16:55:43 INFO mapreduce.Job:  map 100% reduce 0%
16/03/07 16:55:51 INFO mapreduce.Job:  map 100% reduce 100%
16/03/07 16:55:52 INFO mapreduce.Job: Job job_1457076326520_0001 completed successfully
16/03/07 16:55:52 INFO mapreduce.Job: Counters: 49
File System Counters
    FILE: Number of bytes read=156
    FILE: Number of bytes written=230351
    FILE: Number of read operations=0
    FILE: Number of large read operations=0
    FILE: Number of write operations=0
    HDFS: Number of bytes read=177
    HDFS: Number of bytes written=77
    HDFS: Number of read operations=6
    HDFS: Number of large read operations=0
    HDFS: Number of write operations=2
Job Counters
    Launched map tasks=1
    Launched reduce tasks=1
    Data-local map tasks=1
    Total time spent by all maps in occupied slots (ms)=8022
    Total time spent by all reduces in occupied slots (ms)=4886
    Total time spent by all map tasks (ms)=8022
    Total time spent by all reduce tasks (ms)=4886
    Total vcore-seconds taken by all map tasks=8022
    Total vcore-seconds taken by all reduce tasks=4886
    Total megabyte-seconds taken by all map tasks=8214528
    Total megabyte-seconds taken by all reduce tasks=5003264
Map-Reduce Framework
    Map input records=3
    Map output records=14
    Map output bytes=122
    Map output materialized bytes=156
    Input split bytes=110
    Combine input records=0
    Combine output records=0
    Reduce input groups=11
    Reduce shuffle bytes=156
    Reduce input records=14
    Reduce output records=11
    Spilled Records=28
    Shuffled Maps =1
    Failed Shuffles=0
    Merged Map outputs=1
    GC time elapsed (ms)=243
    CPU time spent (ms)=2860
    Physical memory (bytes) snapshot=444420096
    Virtual memory (bytes) snapshot=3891036160
    Total committed heap usage (bytes)=348651520
Shuffle Errors
    BAD_ID=0
    CONNECTION=0
    IO_ERROR=0
    WRONG_LENGTH=0
    WRONG_MAP=0
    WRONG_REDUCE=0
File Input Format Counters
    Bytes Read=67
File Output Format Counters
    Bytes Written=77
jintao@node0:~/Project$ 
</code></pre>

<p>程序执行成功后，会产生一个output目录，执行一下命令，可以产看结果：</p>

<pre><code>jintao@node0:~/Project$ hdfs dfs -cat output/part-r-00000
is  2
jintao  1
jintao. 1
mx  1
my  2
mz  1
name    2
name.   1
too.    1
whit's  1
your    1
</code></pre>

<p>至此，讲述了最基本的mapreduce程序开发、运行过程，后续需要学习的有如果查看日志，如何调试优化程序等方面。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hdfs文件系统java Api介绍]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao/"/>
    <updated>2015-12-21T17:29:19+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao</id>
    <content type="html"><![CDATA[<h1>Hadoop Filesystems</h1>

<p>Hadoop对于文件系统有一个抽象设计，HDFS只是一个实现。客户端使用Java 抽象类org.apache.hadoop.fs.FileSystem来访问Hadoop中的文件系统，有多个具体实现类:</p>

<pre><code>FileSystem      URI scheme      Java implementaion  
Local           file            fs.LocalFileSystem  

HDFS            hdfs            hdfs.DistributedFileSystem

WebHDFS         webhdfs         hdfs.web.WebHdfsFileSystem

Secure
WebHDFs         swebhdfs        hdfs.web.SWebHdfsFileSystem

HAR             har             fs.HarFileSystem

View            viewfs          viewfs.ViewFileSystem

FTP             ftp             fs.ftp.FTPFileSystem

S3              s3a             fs.s3a.S3AFileSystem

Azure           wasb            fs.azure.NativeAzureFileSystem

Swift           swift           fs.swift.snative.SwiftNative
</code></pre>

<p>Hadoop提供多个接口访问文件系统，接口利用URI的scheme来创建对应的实例与文件系统进行通讯。hdfs命令可以用来操作Hadoop各种文件系统，比如列出本地文件系统根目录内容：</p>

<pre><code>[root@yun1 ~]# hdfs dfs -ls file:///
Found 25 items
-rw-r--r--   1 root root          0 2015-10-19 11:06 file:///.autofsck
-rw-r--r--   1 root root          0 2014-07-04 14:16 file:///.autorelabel
dr-xr-xr-x   - root root       4096 2014-07-04 14:36 file:///bin
dr-xr-xr-x   - root root       1024 2014-09-17 15:54 file:///boot
drwxr-xr-x   - root root       4096 2014-07-04 09:17 file:///data
-rw-r--r--   1 root root       1001 2014-07-29 16:28 file:///dataplatform.log
drwxr-xr-x   - root root       3580 2015-10-19 11:08 file:///dev
</code></pre>

<h1>Java Interface</h1>

<!-- more -->


<p>访问HDFS文件系统需要先获取一个文件系统实例，FileSystem是一个文件系统统一访问接口。通过以下接口可以获取访问hdfs文件系统的实例：</p>

<pre><code>public static FileSystem get(Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf, String user) throws IOException
</code></pre>

<p>Configuration对象封装客户端或者服务端的配置信息，这些信息由classpath目录下配置文件初始化，比如etc/hadoop/core-site.xml。第一个接口根据conf中的信息，返回文件系统。第二个接口使用URI的scheme和授权来觉得使用哪个文件系统，如果没有设置scheme，则使用conf中配置的文件系统。第三个接口是以user用户的身份获取文件系统。 使用FileSystem实例，调用open方法可以获取一个输入文件流：</p>

<pre><code>public FSDataInputStream open(Path f) throws IOException
public abstract FSDataInputStream open(Path f, int bufferSize) throws IOException 
</code></pre>

<p>下面的代码实例用于读取hdfs文件输出到标准输出：</p>

<pre><code>public class FileSystemCat {

    public static void main(String[] args) throws Exception {
        String uri = args[0];
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(uri), conf);
        InputStream in = null;
        try {
            in = fs.open(new Path(uri));
            IOUtils.copyBytes(in, System.out, 4096, false);
        } finally {
            IOUtils.closeStream(in);
        }
    }
}
</code></pre>

<p>编译文件后，使用hadoop命令运行class文件：</p>

<pre><code># hadoop FileSystemCat hdfs://localhost/user/tom/quangle.txt
On the top of the Crumpetty Tree
The Quangle Wangle sat, 
But his face you could not see,
On account of his Beaver Hat.
</code></pre>

<h2>Writing Data</h2>

<p>FileSystem提供多个接口来创建文件，最简单的是输入一个路径作为参数，返回一个输出流：</p>

<pre><code>public FSDataOutputStream create(Path f) throws IOException 存在多个重载接口，允许指定是否重写已存在文件，文件的副本个数，写文件的缓冲区大小，文件的块大小和文件权限等等。存在append接口对已存在文件进行追加：
public FSDataOutputStream append(Path f) throws IOException
</code></pre>

<p>下面的代码实例是拷贝一个本地文件到Hadoop文件系统中：</p>

<pre><code>public class FileCopyWithProgress {
    public static void main(String []args) throws Exception {
        String localSrc = args[0];
        String dst = args[1];

        InputStream in = new BufferedInputStream(new FileInputStream(localSrc));

        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(dst), conf);
        OutputStream out = fs.create(new Path(dst), new Progressable() {
            public void progress() {
                System.out.print(".");
            }
        });

        IOUtils.copyBytes(in, out, 4096, true);
    }
}
</code></pre>

<p>运行程序结果如下：
    #hadoop FileCopyWithProgress input/docs/1400-8.txt hdfs://localhost/user/tom/1400-8.txt</p>

<p>创建目录使用下面的接口：</p>

<pre><code>public boolean mkdirs(Path f) throws IOException
</code></pre>

<h2>Quering the FileSystem</h2>

<p>FilsSystem提供了接口来获取文件或者文件夹信息，信息包括文件长度，块大小，复制，修改时间，所有权，访问权限属性。</p>

<pre><code>abstract FileStatus getFileStatus(Path f)
</code></pre>

<p>FileSystem提供了接口来列出一个目录中包含的内容：</p>

<pre><code>abstract FileStatus[]   listStatus(Path f)
FileStatus[]    listStatus(Path[] files)
FileStatus[]    listStatus(Path[] files, PathFilter filter)
FileStatus[]    listStatus(Path f, PathFilter filter)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hiredis C语言Redis客户端库使用]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/11/22/hiredis-cyu-yan-rediske-hu-duan-ku-shi-yong/"/>
    <updated>2015-11-22T11:21:43+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/11/22/hiredis-cyu-yan-rediske-hu-duan-ku-shi-yong</id>
    <content type="html"><![CDATA[<p>Redis是一款依据BSD开源协议发型的高性能Key-Value存储系统(cache and store)。它通常称为数据结构服务器，因为值(value)可以是字符串(String)，哈希(Hase)，列表(List)，集合(Set)和有序集合(sorted sets)等类型。</p>

<p>本文对RedisC语言客户端库<a href="https://github.com/redis/hiredis#using-replies">hireis</a>的安装、使用进行简单介绍。</p>

<h2>Redis安装</h2>

<p>参考<a href="http://redis.io/download">Redis</a>官网中的安装指导进行安装：<br/>
1、下载、解压和编译安装</p>

<pre><code>$ wget http://download.redis.io/releases/redis-3.0.5.tar.gz
$ tar xzf redis-3.0.5.tar.gz
$ cd redis-3.0.5
$ make
</code></pre>

<p>2、运行服务端
    编译声称的二进制文件在redis目录下的src子目录中，如下运行：</p>

<pre><code>$ src/redis-server
</code></pre>

<p>3、使用命令行工具与redis-server进行交互：</p>

<pre><code>$ src/redis-cli
redis&gt; set foo bar
OK
redis&gt; get foo
"bar"
</code></pre>

<p>详细的redis使用文档请参考<a href="http://redis.io/documentation">官网</a></p>

<!-- more -->


<h2>hiredis安装</h2>

<p>上面下载的Redis源代码目录的deps/hiredis目录中包含了hiredis的源代码，也可以从hiredis在github的网址下载：</p>

<pre><code>$ git clonet https://github.com/redis/hiredis.git
$ make
$ make install
</code></pre>

<p>以上命令会将相关.h头文件拷贝到/usr/local/include/hiredis/目录，<br/>
同时将hiredis相关库文件拷贝到/usr/local/lib/目录。</p>

<pre><code>-rw-rw-r--  1 jintao jintao 431534 11月  9 21:28 libhiredis.a
lrwxrwxrwx  1 root   root       15 11月  9 21:50 libhiredis.so -&gt; libhiredis.so.0*
lrwxrwxrwx  1 root   root       18 11月  9 21:50 libhiredis.so.0 -&gt; libhiredis.so.0.11*
-rwxrwxr-x  1 jintao jintao 219340 11月  9 21:50 libhiredis.so.0.11*
</code></pre>

<h2>hiredis接口</h2>

<p>hiredis库接口分为同步和异步两种接口，本文主要使用的是同步接口，主要涉及一下几个:</p>

<pre><code>redisContext *redisConnect(const char *ip, int port);
void *redisCommand(redisContext *c, const char *format, ...);
void freeReplyObject(void *reply);
</code></pre>

<h3>建立连接</h3>

<pre><code>redisContext *redisConnect(const char *ip, int port);
</code></pre>

<p>redisConnect函数用来创建一个到redis服务器的连接，并返回一个redisContext类型的指针。redisContext对象用来维护连接的状态。<br/>
redisContext对象中err字段非0表示连接处于异常状态。 <br/>
redisContext对象errstr字段包含错误信息描述字符串。<br/>
使用redisConnect接口连接Redis服务器后，需要判断是否连接成功：</p>

<pre><code>redisContext *c = redisConnect("127.0.0.1", 6379);
if (c != NULL &amp;&amp; c-&gt;err) {
    printf("Error: %s\n", c-&gt;errstr);
    // handle error
}
</code></pre>

<h3>发送命令</h3>

<p>有多个方法发送命令到Redis。现在介绍redisCommand函数，redisCommand函数类似printf。最简单的形式如下：</p>

<pre><code>reply = redisCommand(context, "SET foo bar");
</code></pre>

<p>%s标识符用来将字符串格式到命令中。</p>

<pre><code>reply = redisCommand(context, "SET foo %s", value);
</code></pre>

<p>%b标识符可以用来将二进制数据格式化到命令中，valuelen为数据长度。</p>

<pre><code>reply = redisCommand(context, "SET foo %b", value, (size_t) valuelen);
</code></pre>

<h3>处理命令结果</h3>

<p><code>redisCommand</code>执行成功后，返回一个<code>redisReply</code>对象保存执行结果。<br/>
当命令执行异常，redisCommand返回<code>NULL</code>,设置<code>context</code>对象<code>err</code>字段记录错误原因。<br/>
当执行命令异常，<code>context</code>失效，必须重新建立到redis服务器的连接。<br/>
<code>redisReply</code>对象中的<code>type</code>字段标识返回类型：</p>

<ul>
<li><p>REDIS_REPLY_STRING:<br/>
命令返回值类型为字符串。reply->str代表返回的字符串值。</p></li>
<li><p>REDIS_REPLY_STATUS:<br/>
  命令返回一个状态。通过reply->str获取状态字符串。状态字符串的长度为reply->len。</p></li>
<li><p>REDIS_REPLY_ERROR:
  命令执行失败，返回一个错误。错误原因字符串通过reply->str获取。</p></li>
<li><p>REDIS_REPLY_INTEGER:<br/>
  命令返回一个整型。整型的值可以通过reply->integer字段获取，整型类型为long long。</p></li>
<li><p>REDIS_REPLY_NIL:<br/>
  命令返回一个nil对象。没有数据可以获取。</p></li>
<li><p>REDIS_REPLY_ARRAY:  <br/>
  返回值为一个数组。reply->elements中保存对象个数。每个对象都是一个<code>redisReply</code>对象。通过reply->element[..index..]获取这些对象。</p></li>
</ul>


<p><code>redisReply</code>对象需要使用<code>freeReplyObject()</code>进行释放，返回对象中的子对象无需使用<code>freeReplyObject()</code>进行释放。</p>

<h3>管道批量发送命令</h3>

<p>当redisCommand命令被调用时，Hiredis首先根据Redis协议格式化命令。格式化后的命令被放到context维护的输出缓冲区中。输出缓冲区是动态的，可以容纳很多命令。命令被放置到输出缓冲区以后，调用redisGetReply获取返回值。redisGetReply有如下两条执行路径：</p>

<pre><code>1. 输入缓冲区非空：  
    从输入缓冲区中解析一个reply应答并返回。
    如果不能解析出一个reply，则走到第二条路径  

2. 输入缓冲区为空：
    将输出缓冲区写到socket。
    读取socket并解析出一个reply。
</code></pre>

<p>使用管道批量发送命令，就是使用如下命令填充输出缓冲区：</p>

<pre><code>void redisAppendCommand(redisContext *c, const char *format, ...);
void redisAppendCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen);
</code></pre>

<p>调用数次上面函数发送命令后，调用<code>redisGetReply</code>获取随后的返回值。<br/>
下面例子是一个简单的使用管道发送命令的例子（只有一次调用write（2）和一次调用read（2））：</p>

<pre><code>redisReply *reply;
redisAppendCommand(context,"SET foo bar");
redisAppendCommand(context,"GET foo");
redisGetReply(context,&amp;reply); // reply for SET
freeReplyObject(reply);
redisGetReply(context,&amp;reply); // reply for GET
freeReplyObject(reply);  
</code></pre>

<h3>示例：</h3>

<pre><code>#include &lt;hiredis/hiredis.h&gt;

int main()
{
    // create a connection
    redisContext *context = redisConnect("127.0.0.1", 6379);
    if ( context != NULL &amp;&amp; context-&gt;err) {
        printf("connect to redis fail.%s\n", context-&gt;errstr);
        return -1;
    }

    redisReply *reply = redisCommand(context, "select 0");
    if (NULL != reply) {
        if (REDIS_REPLY_STATUS == reply-&gt;type &amp;&amp; strcmp(reply-&gt;str,"OK") == 0) {
            printf("command:select 0 suc.type: %d, str:%s\n", REDIS_REPLY_STATUS, "OK");
        } 
        else {
            printf("command:select 0 fail.type: %d, str:%s\n", reply-&gt;type, reply-&gt;str);
            freeReplyObject(reply);
            redisFree(context);
            return -1;
        }
    } else {
        printf("command:select 0 fail.\n");
        redisFree(context);
        return -1;
    }
    freeReplyObject(reply);

    char *c1 = "set key1 eeee";
    reply = redisCommand(context, c1);
    if (NULL != reply) {
        if (reply-&gt;type == REDIS_REPLY_ERROR) {
            printf("command:%s excute fail: type: %d, str:%s\n", c1, reply-&gt;type, reply-&gt;str);
        }
        printf("command:%s excute ret: type: %d, str:%s\n", c1, reply-&gt;type, reply-&gt;str);
    } else {
        printf("command:%s fail\n", c1);
        redisFree(context);
        return -1;
    }
    freeReplyObject(reply);

    char *c2 = "set key2 222";
    char *c3 = "get list_key1";
    redisAppendCommand(context, c2);
    redisAppendCommand(context, c3);

    char *get_cmd = "get key1";
    reply = redisCommand(context, get_cmd);
    if (reply != NULL) {
        if (reply-&gt;type == REDIS_REPLY_ERROR) {
            printf("%s fail.type:%d value:%s\n", get_cmd, reply-&gt;type, reply-&gt;str);
        } else if (reply-&gt;type == REDIS_REPLY_STRING) {
            printf("%s suc.type:%d value:%s\n", get_cmd, reply-&gt;type, reply-&gt;str);
        }
        freeReplyObject(reply);
    } else {
        printf("%s execute fail.\n", get_cmd);
        redisFree(context);
        return -1;
    }

// list
// hash
char *hgetall = "hgetall hash_key1";
reply = redisCommand(context, hgetall);
if (reply != NULL) {
    if (reply-&gt;type == REDIS_REPLY_ERROR) {
        printf("%s ,type:%d result:%s\n", hgetall, REDIS_REPLY_ERROR, reply-&gt;str);
    } else if (reply-&gt;type == REDIS_REPLY_NIL) {
        printf("%s ,type:%d result:%s\n", hgetall, REDIS_REPLY_NIL, reply-&gt;str);
    } else if (reply-&gt;type == REDIS_REPLY_ARRAY) {
        printf("%s ,type:%d elements:%lu \n", hgetall, REDIS_REPLY_ARRAY, reply-&gt;elements);
        int i;
        for (i = 0; i &lt; reply-&gt;elements; i++) {
            redisReply *tmp = reply-&gt;element[i];
            if (tmp-&gt;type == REDIS_REPLY_INTEGER){
                printf("elements[%d],type:%d result:%lld\n", i, REDIS_REPLY_INTEGER, tmp-&gt;integer);
            } else if (tmp-&gt;type == REDIS_REPLY_STRING) {
                printf("elements[%d] ,type:%d result:%s\n", i, REDIS_REPLY_STRING, tmp-&gt;str);
            }
            printf("index:%d ,type:%d \n", i, tmp-&gt;type);
        }
    }
    freeReplyObject(reply);
} else {
    printf("%s fail\n", hgetall);
}
redisFree(context);
return 0;
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crontab任务设置及路径、动态库、产生多个进程问题解决]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/11/21/crontabren-wu-she-zhi-ji-lu-jing-,-dong-tai-ku-,-chan-sheng-duo-ge-jin-cheng-wen-ti-jie-jue/"/>
    <updated>2015-11-21T11:17:04+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/11/21/crontabren-wu-she-zhi-ji-lu-jing-,-dong-tai-ku-,-chan-sheng-duo-ge-jin-cheng-wen-ti-jie-jue</id>
    <content type="html"><![CDATA[<p>crontab文件中包含了cron守护进程需要执行的指令：某个时间执行这条命令。每个用户拥有自己的crontab，crontab中的命令以crontab所属用户运行。</p>

<pre><code>crontab [ -u user ] file
crontab [ -u user ] [ -i ] { -e | -l | -r }
</code></pre>

<p>命令第一种形式是用file中的命令设置crontab任务<br/>
-l 参数是打印当前crontab任务到标准输出<br/>
-e 参数是使用VISUAL或者EDITOR环境变量定义的编辑器编辑当前crontab定时任务<br/>
-r 参数删除当前定时任务<br/>
-i 与用户进行交互</p>

<h2>任务设置</h2>

<p>crontab文件中可以包含三种语句：<br/>
1、注释
以#开头的语句都是注释</p>

<pre><code>#this is a comment in crontab 
</code></pre>

<p>2、设置环境变量</p>

<pre><code>LD_LIBRARY_PATH = /homt/lib/
</code></pre>

<p>3、设置定时任务<br/>
每一行定义一条定时任务，包括五个时间、日期字段，时间日期后面的内容都是命令<br/>
时间日期包括分、时、天、月和一周某天字段：</p>

<pre><code>ield          allowed values
-----          --------------
minute         0-59
hour           0-23
day of month   1-31
month          1-12 (or names, see below)
day of week    0-7 (0 or 7 is Sun, or use names)
</code></pre>

<p>字段可以是＊，代表范围内所有<br/>
字段也可以是一个范围，比如hour字段8-10，代表8，9，10<br/>
字段也可以是一个列表，比如hour字段8，9，10<br/>
字段也可以是一个范围和列表的混合，比如hour字段1-7，9－12<br/>
字段也可以为一个间隔，比如hour 1-8/2,代表1,3,5,7</p>

<!-- more -->


<h2>路径问题</h2>

<p>crontab任务是根据所属用户从/etc/passwd文件中获取bashshell工具类型、logname和当前路径的。<br/>
代码中如果使用的是相对路径，那么在会导致程序找不到文件，可以在程序入口处利用chdir类似功能函数修改程序的当前工作路径：</p>

<pre><code>int chdir(const char *path);
</code></pre>

<h2>动态库问题</h2>

<p>如果程序使用了动态库，而动态库放置的位置没有在等标准路径下的话，程序会因为加载不到动态库而执行失败，可能报如下的错误：</p>

<pre><code>/root/server/demo_linux/server: error while loading shared libraries: libTDFAPI30.so: cannot open shared object file: No such file or directory
</code></pre>

<p>解决办法有两个：<br/>
1、链接程序时指定绝对路径：</p>

<pre><code>-Wl,-rpath=/root/server/lib
</code></pre>

<p>2、在crontab中设置LD_LIBRARY_PATH环境变量</p>

<pre><code>LD_LIBRARY_PATH=/root/server/lib
</code></pre>

<h2>创建两个相关进程</h2>

<pre><code>root     19400  0.0  0.0 113116  1208 ?        Ss   18:10   0:00 /bin/sh -c /root/test/cron 1&gt; stdout 2&gt; stderr
root     19402  0.0  0.0  12620  1072 ?        S    18:10   0:00 /root/test/cron
</code></pre>

<p>看到两个进程是因为crontab使用/bin/sh来启动定时任务程序:</p>

<pre><code>[root@iZ235ne7v0iZ demo_linux]# ps -o ppid -p 19402
PPID
19400
</code></pre>

<p>可以将crontab任务修改为下列情况：</p>

<pre><code>10 18  * * * exec /root/test/cron 1&gt; stdout 2&gt; stderr
</code></pre>

<p>或者</p>

<pre><code>10 18  * * * bash -c '/root/test/cron 1&gt; stdout 2&gt; stderr'
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop环境搭建]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/09/19/hadoophuan-jing-da-jian/"/>
    <updated>2015-09-19T15:41:51+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/09/19/hadoophuan-jing-da-jian</id>
    <content type="html"><![CDATA[<p>最近开始进行Hadoop分布式计算相关内容的学习，先从搭建开发环境开始。下面记录一下搭建Hadoop开发环境的过程，以及注意点。
本节介绍如何快速搭建和配置一个单节点Hadoop环境，便于使用Hadoop MapReduce和Hadoop Distributed File System(HDFS)。</p>

<h2>依赖条件</h2>

<p>支持的操作系统平台  <br/>
GNU/Linux支持作为Hadoop的开发和生产环境，Hadoop已经证明可以在GNU/Linux集群上运行2000节点。本文使用Ubuntu操作系统做为实验环境。</p>

<pre><code>Linux node8 3.16.0-30-generic #40~14.04.1-Ubuntu SMP Thu Jan 15 17:43:14 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
</code></pre>

<p>Windows系统也可以搭建Hadoop集群，本文暂时没有涉及，可以参考<a href="http://wiki.apache.org/hadoop/Hadoop2OnWindows">wiki page</a></p>

<p>依赖的软件</p>

<ul>
<li><p>Java环境<br/>
  安装方法：</p>

<p>  1、到oracle官网下载<a href="http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.tar.gz">JDK二进制压缩包</a><br/>
  2、将压缩包解压到/usr/local/lib/目录下，安装目录也可以换到其他路径  <br/>
      sudo tar xzvf jdk-8u45-linux-x64.tar.gz -C /usr/local/lib/<br/>
  3、修改/etc/profile文件配置JAVA_HOME、PATH、CLASSPATH环境变量<br/>
      JAVA_HOME=/usr/local/lib/jdk1.8.0_45<br/>
      PATH=$JAVA_HOME/bin:$PATH<br/>
      CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar <br/>
  4、运行java -version查看是否显示java版本信息</p></li>
<li><p>ssh远程控制软件<br/>
  如果系统没有运行sshd服务，则Ubuntu下运行apt-get命令安装ssh服务端
  sudo apt-get install openssh-server</p></li>
</ul>


<h2>下载Hadoop软件</h2>

<p>本文采用的是Hadoop最新的稳定版本<a href="http://apache.fayea.com/hadoop/common/current/hadoop-2.7.1.tar.gz">2.7.1</a></p>

<!-- more -->


<p></p>

<h2>准备运行集群</h2>

<p>1、将压缩包解压到一个安装目录下</p>

<pre><code>sudo tar xzvf hadoop-2.7.1.tar.gz -C /home/jintao/toolkit/
</code></pre>

<p>2、打开安装目录下etc/hadoop/hadoop-env.sh</p>

<pre><code>添加一句 export JAVA_HOME=/usr/local/lib/jdk1.8.0_45
</code></pre>

<p>3、运行bin/hadoop命令，查看hadoop命令使用帮助</p>

<h2>单机模式</h2>

<p>默认情况，Hadoop运行在非分布式模式，一个单独Java进程。这种模式调试时很有用。下面的例子，拷贝hadoop目录下面的etc/hadoop/*.xml作为输入，运行hadoop打印文件中匹配正则表达式的内容，输出到指定的output目录。</p>

<pre><code>$ mkdir input  
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
$ cat output/*
</code></pre>

<h2>伪分布式</h2>

<p>Hadoop可以在单个节点运行在伪分布式模式，每个Hadoop守护进程运行在不同的Java进程。</p>

<h3>配置</h3>

<p>编辑以下文件：
etc/hadoop/core-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>etc/hadoop/hdfs-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3>设置ssh无密码登录</h3>

<p>查看当前是否可以无密码登录：</p>

<pre><code>$ ssh localhost
</code></pre>

<p>如果不可以无密码登录，则执行一下命令：</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<h3>执行</h3>

<p>以下指令在本地运行一个MapReduce任务。<br/>
1、格式化hdfs文件系统</p>

<pre><code>$ bin/hdfs namenode -format
</code></pre>

<p>默认namenode存储路径：/tmp/hadoop-jintao/dfs/name</p>

<p>2、运行NameNode和DataNode守护进程：</p>

<pre><code>$ sbin/start-dfs.sh
</code></pre>

<p>hadoop守护进程日志输出到$HADOOP_LOG_DIR目录（默认在$HADOOP_HOME/logs安装目录的logs目录下）。使用jps查看java进行：</p>

<pre><code>jintao@node8:~/toolkit/hadoop-2.7.1$ jps
5248 DataNode
5473 SecondaryNameNode
5105 NameNode
13380 Jps
</code></pre>

<p>3、通过web接口查看NameNode信息；默认路径：</p>

<pre><code>http://localhost:50070/
</code></pre>

<p>4、创建执行MapReduce任务需要的HDFS路径：/user/&lt;username></p>

<pre><code>$ bin/hdfs dfs -mkdir /user 
$ bin/hdfs dfs -mkdir /user/jintao
</code></pre>

<p>5、将试验用的数据放到hdfs上input目录下：</p>

<pre><code>$ bin/hdfs dfs -put etc/hadoop input
</code></pre>

<p>6、运行hadoop自带的grep任务：</p>

<pre><code>$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>7、将结果文件从hdfs上获取到本地目录outpu中，并查看结果：</p>

<pre><code>$ bin/hdfs -get output output
$ cat output/*
</code></pre>

<p>或者直接查看hdfs上面的结果文件：</p>

<pre><code>$ bin/hdfs -cat output/*
</code></pre>

<p>8、关闭hadoop后台进程</p>

<pre><code>$ sbin/stop-dfs.sh
</code></pre>

<h3>伪分布式运行YARN</h3>

<p>设置一些参数，可以在伪分布式环境下运行YARN框架管理MapReduce任务，YARN框架会启动ResourceManager和NodeManager守护进程。<br/>
在上面1到4步完成的基础上，进行如下设置：<br/>
1、配置etc/hadoop/mapred-site.xml，如果不存在mapred-site.xml，则拷贝一份mapred-site.xml.template命名为mapred-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>配置etc/hadoop/yarn-site.xml：</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>2、启动ResourceManager和NodeManager后台进程：</p>

<pre><code>$ sbin/start-yarn.sh
$ jps
15858 NodeManager
15301 DataNode
15542 SecondaryNameNode
16119 Jps
15160 NameNode
15723 ResourceManager
</code></pre>

<p>3、浏览ResourceMnaager信息：</p>

<pre><code>http://localhost:8088/
</code></pre>

<p>4、运行一个MapReduce任务：</p>

<pre><code>$ bin/hdfs dfs -rm -r -f output
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>5、关闭yarn框架进程</p>

<pre><code>$ sbin/stop-yarn.sh
</code></pre>

<h2>集群环境</h2>

<p>搭建四台机器（node1、node2、node3、node4）的Hadoop集群环境：<br/>
1、node1部署NameNode和ResourceManager<br/>
2、node2、node3、node4作为slave节点部署DataNode和NodeManager</p>

<p>典型集群环境下，应该将单独一台机器运行NameNode，另外一台机器运行ResourceManager，这些是主控节点。其他服务（比如Web App Proxy Server和MapReduce Job History server）通常运行在一台指定机器或者共享设备上，依赖于系统负载。集群中其他机器都同时部署DataNode和NodeManager，这些都是slaves节点。</p>

<h3>准备工作</h3>

<p>1、每台机器都安装JAVA环境<br/>
   参考上面单机环境搭建，进行安装、配置环境变量</p>

<p>2、编辑hosts文件
    编辑每台机器的hosts文件，将hostname和ip的对应关系添加到/etc/hosts中</p>

<pre><code>192.168.88.120 node0
192.168.88.121 node1
192.168.88.122 node2
192.168.88.123 node3
</code></pre>

<p>在各台机器上通过主机名ping各台机器，查看是否能够ping通</p>

<p>3、配置ssh无密码登录
每台机上运行，生存密钥</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<p>ssh集群启动时，主控节点会通过ssh远程登录到slaves节点执行脚本启动slaves节点，因此我们需要配置主控节点到slaves节点的无密码登录：<br/>
将主控节点的pub密钥拷贝到各个slaves节点~/.ssh/目录下</p>

<pre><code>scp id_rsa.pub jintao@node1:~/.ssh/node0.pub
</code></pre>

<p>将node0.pub文件的内容追加到各个节点的authorized_keys文件中：</p>

<pre><code>cat node0.pub &gt;&gt; authorized_keys
</code></pre>

<p>从node0节点ssh到slaves节点上，查看是否不需要密码</p>

<p>4、创建hadoop工作目录</p>

<pre><code>mkdir /home/jintao/hadoop_dir
</code></pre>

<p>如果将hadoop工作目录配置在其他目录下，则需要使hadoop的运行账户对该目录具有读写权限</p>

<p>5、下载Hadoop安装程序<br/>
从官网下载安装程序，解压到~/toolkit/目录下，toolkit后面陆续会安装其他zookeeper、hbase等项目</p>

<h3>配置Hadoop</h3>

<p>管理员应该使用etc/haddop-env.sh和etc/hadoop/mapred-env.sh和etc/hadoop/yarn-env.sh三个相关脚本来配置Hadoop进程环境。</p>

<p>1、打开安装目录下etc/hadoop/hadoop-env.sh</p>

<pre><code>添加一句 export JAVA_HOME=/usr/local/lib/jdk1.8.0_45
</code></pre>

<p>2、vim core-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;fs.defaultFS&lt;/name&gt;
            &lt;value&gt;hdfs://node0:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
            &lt;value&gt;/home/jintao/hadoop_dir&lt;/value&gt;
            &lt;description&gt;A base for other temporary directories.&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>设置fs.defaultFS和hadoop.tmp.dir属性</p>

<p>3、vim hdfs-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>4、vim mapred-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>5、vim yarn-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;node0&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>6、vim slaves</p>

<pre><code>ode1
node2
node3
</code></pre>

<p>7、将配置好的hadoop程序同步到slaves节点上</p>

<pre><code>scp -r toolkit/ node1:~
scp -r toolkit/ node2:~
scp -r toolkit/ node3:~
</code></pre>

<p>8、启动namenode节点</p>

<pre><code>1、cd ~/toolkit/hadoop-2.7.1/
2、bin/hdfs namenode -format
3、sbin/start-all.sh
</code></pre>

<p>9、node0上查看jps</p>

<pre><code>9904 Jps
9426 SecondaryNameNode
9190 NameNode
9607 ResourceManager
</code></pre>

<p>10、node1、node2、node3上查看jps</p>

<pre><code>9507 Jps
9323 NodeManager
9213 DataNode
</code></pre>

<p>11、系统启动日志记录在hadoop-2.7.1/logs目录下</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[冒泡、选择、插入、归并、快速、堆排序]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/08/02/mou-pao-,-xuan-ze-,-cha-ru-,-gui-bing-,-kuai-su-,-dui-pai-xu/"/>
    <updated>2015-08-02T20:40:24+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/08/02/mou-pao-,-xuan-ze-,-cha-ru-,-gui-bing-,-kuai-su-,-dui-pai-xu</id>
    <content type="html"><![CDATA[<p>本篇文章对一些常用的排序算法进行简单介绍和实现，包括冒泡排序，选择排序，插入排序、归并排序、快速排序和堆排序。</p>

<h1>冒泡排序</h1>

<p><a href="http://baike.baidu.com/view/254413.htm#ref_[1]_254413">冒泡排序算法</a>（百度百科）的运作如下：（从后往前）<br/>
1. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。<br/>
2. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。<br/>
3. 针对所有的元素重复以上的步骤，除了最后一个。<br/>
4. 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</p>

<p>代码实现</p>

<pre><code>void BubbleSort(int array[], int len)    
{  
    for (int i = 0; i &lt; len-1; i++) {
        for (int j = 0; j &lt; len-i-1; j++) {
            if (array[j+1] &lt; array[j]) {
                int tmp = array[j+1];
                array[j+1] = array[j];
                array[j] = tmp;
            }
        }
    }
}
</code></pre>

<!-- more -->


<h1>选择排序</h1>

<p><a href="http://baike.baidu.com/view/547263.htm">选择排序（Selection sort）</a>（百度百科）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或者最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。选择排序是不稳定的排序方法（比如序列[5, 5, 3]）第一次就将第一个[5]与[3]交换，导致第一个5挪到第二个5后面。<br/>
代码实现：</p>

<pre><code>void SelectSort(int array[], int len)
{
    for (int i = 0; i &lt; len-1; i++) {
        int maxindex = 0;
        int j;
        for (j = 0; j &lt; len-i; j++) {
            if (array[maxindex] &lt; array[j])
            maxindex = j;
        }
        if (maxindex != j-1) {
            int tmp = array[maxindex];
            array[maxindex] = array[j-1];
            array[j-1] = tmp;
        }
    }
}
</code></pre>

<h1>插入排序</h1>

<p><a href="http://baike.baidu.com/view/1443814.htm">插入排序</a>基本思想是，有一个已经有序的数据列表，要求在这个已经排好的数据序列中插入一个数，但要求插入后此数据序列依然有序，当最后一个元素放入合适位置时，该数组排序完毕。</p>

<p>代码实现：</p>

<pre><code>void InsertSort(int array[], int len)
{
    for (int i = 0; i &lt; len-1; i++) {
        int tmp = array[i+1];
        int j;
        for (j = i; j &gt;= 0; j--) {
            if (array[j] &gt; tmp)
                array[j+1] = array[j];
            else
            break;
        }
        array[j+1] = tmp;
    }
}
</code></pre>

<h1>归并排序</h1>

<p><a href="http://baike.baidu.com/link?url=ntO_kb7I3p3zA69jUzemm9fGlNCnRTYujLs3bOn8OSxJ_qQ8uWhIXYXEWAcuMnpLsBWkZ7cWVPG0z9OQGSBmklD2mMslu_ybumqBYdFvBkoRX0UIgDXg6rESkppoX4jX-1dwTRL-6_jlMQvghncKxUGEPA6MOVPjHsOEr3l8CiF0WLrbOgcaN_qOVrjxtbHBLUbEZ7AT_9PP8A6YhxTTmK">归并排序</a>是建立在归并操作上的一种有效的排序算法，该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。<br/>
归并过程为：比较a[i]和a[j]的大小，若a[i]&lt;=a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中规格有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。</p>

<p>代码实现：</p>

<pre><code>void MergeSort(int array[], int low, int high)
{   
    if (low &lt; high) {
        int mid = (low + high)/2;
        MergeSort(array, low, mid);
        MergeSort(array, mid+1, high);
        Merge(array, low, mid, high);
    }
}

void Merge(int array[], int low, int mid, int high)
{
    int tmp[high-low+1];
    int i = low;
    int j = mid+1;
    int k = 0;
    while((i &lt; mid+1) &amp;&amp; (j &lt; high+1)) {
        if (array[i] &lt; array[j]) {
            tmp[k++] = array[i++];
        } else {
            tmp[k++] = array[j++];
        }
    }
    if (i &lt; mid+1)
        memcpy(&amp;tmp[k], &amp;array[i], sizeof(int)*(mid+1-i));
    else
        memcpy(&amp;tmp[k], &amp;array[j], sizeof(int)*(high+1-j));
    memcpy(&amp;array[low], tmp, sizeof(int)*(high-low+1));
}
</code></pre>

<h1>快速排序</h1>

<p><a href="http://baike.baidu.com/link?url=HP5tLiQM-gSmzKFE8mLK2iTkDvv6CfSE02u7ZGHoVYBJpPbFQTG9kr7hTGNYzHR-gejxXqfsyE46qW9yq58itjMK0nw0wwxqINW25Cfr-bypjbWHg35SSk9Sw7XCG0gJRnQEMcQJw_cObpiQDh77Si7o0w_CKa9jYtjOiAua6s1D5xOpgDbPCanOmgJiK6mY">快速排序</a>（Quicksort）使对冒泡排序的一种改进。<br/>
快速排序由C.A.R.Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要笑，然后再按此方法对着两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p>

<p>算法介绍：
设要排序的数组是A[0]&hellip;.A[N-1]，首先任意选取一个数据（通常选用数组的第一个数）作为关键数据，然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，整个过程称为一趟快速排序。值得注意的是，快速排序不是一种稳定的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动。<br/>
一趟快速排序的算法是：<br/>
1）设置两个变量i、j，排序开始的时候：i=0，j＝N-1;<br/>
2）以第一个数组元素做为关键数据，赋值给key，即key＝A[0];<br/>
3) 从j开始向前搜索，即由后开始向前搜索(j&ndash;),找到第一个小于key的值A[j], 将A[j]和A[j]互换；<br/>
4）从i开始向后搜索，即由前开始向后搜索(i++),找到第一大于key的A[i],将A[i]和A[j]互换；<br/>
5)重复第3、4步，直到i＝j；(3,4步中，没有找到符合条件的值，即3种A[j]步小于key，4中A[i]不大于key的时候改变j、i的值，使得j＝j-1, i = i+1,直到找到为止。找到符合条件的值，进行交换的时候i，j指针位置不变。另外，i＝＝j这一过程一定正好是i+或j-完成的时候，此时令循环结束)。</p>

<p>代码实现：</p>

<pre><code>void QuickSort(int array[], int low ,int high)
{
    if (low &gt;= high)
    return;
    int pivot = FindPivot(array, low, high);
    QuickSort(array, low, pivot-1);
    QuickSort(array, pivot+1, high);
}

int FindPivot(int array[], int low, int high)
{
    int i = low;
    int j = high;
    int tmp = array[low];
    while(i &lt; j) {
        while((i &lt; j) &amp;&amp; (array[j] &gt;= tmp))
        j--;
        array[i] = array[j];
        while((i &lt; j) &amp;&amp; (array[i] &lt;= tmp))
        i++;
        array[j] = array[i];
    }
    array[i] = tmp;
    return i;
}   
</code></pre>

<h1>堆排序</h1>

<p><a href="http://baike.baidu.com/link?url=MQ3FCTrGuunRTE_A8KhSLxF5JZtTAlbsSv5Otj1uB0l6xb2NsFCML-8zsQp0iZ6KC2RS4vSj7bvHoSfpnzudXa">堆排序</a>是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位制定索引的元素。堆分为大根堆和小跟堆，是完全二叉树。大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]]&gt;=A[i]。在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶。<br/>
算法介绍：<br/>
堆排序利用了大根堆（或小根堆）堆顶记录的关键字最大（或最小）这一特征，使得在当前无序区中选取最大（或最小）关键字的记录变得简单。
基本操作：<br/>
1）建堆，建堆是不断调整堆的过程，从len/2处开始调整，一直到第一个节点，此处len是堆中元素的个数。建堆的过程是线性的过程，从len/2到0处一直调用调整堆的过程，相当于o(h1)+o(h2)&hellip;+o(hlen/2)其中h表示节点的深度，len/2表示节点的个数，这是一个求和的过程，结果是线性的O(n)。<br/>
2）调整堆：调整堆在构建堆的过程中会用到，而且在堆排序过程中也会用到。利用的思想是比较节点i和它的孩子节点left(i),right(i),选出三者最大（或者最小）者，如果最大（小）值不是节点i而是它的一个孩子节点，那边交换节点i和该节点，然后再调用调整堆过程，这是一个递归的过程。调整堆的过程时间复杂度与堆的深度有关系，是lgn的操作，因为是沿着深度方向进行调整的。
3）堆排序：堆排序是利用上面的两个过程来进行的。首先是根据元素构建堆。然后将堆的根节点取出（一般是与最后一个节点进行交换），将前面len-1个节点继续继续堆调整的过程，然后再将根节点取出，这样一支到所有节点都取出。堆排序过程的时间复杂度时O(nlgn)。因为建堆的时间复杂度时O(n)(调整一次)；调整堆的时间复杂度时lgn，调整用了n-1次，所以堆排序的时间复杂度是O(nlgn)。
代码实现：</p>

<pre><code>void HeapAdjust(int array[], int begin, int high)
{
    int i = begin;
    while(i &lt;= high) {
        int max = i;
        int leftchild = 2*i + 1;
        int rightchild = 2*i +2;
        if (leftchild &lt;= high &amp;&amp; array[max] &lt; array[leftchild])
            max = leftchild;
        if (rightchild &lt;= high &amp;&amp; array[max] &lt; array[rightchild])
        max = rightchild;
        if (i != max) {
            int tmp = array[i];
            array[i] = array[max];
            array[max] = tmp;
            i = max;
        } else {
            break;
        }
    }
}

void InitHeap(int array[], int low, int high)
{
    for (int i = high/2; i &gt;= low; i--) {
        HeapAdjust(array, i, high);
    }
}

void HeapSort(int array[], int low, int high)
{
    InitHeap(array, low, high);
    for (int i = high; i &gt; low; i--) {
        int tmp = array[i];
        array[i] = array[low];
        array[low] = tmp;
        HeapAdjust(array, low, i-1);
    }
}   
</code></pre>

<p>测试代码：</p>

<pre><code>int main()
{
    int a[] = {100, 2,4,5,1,10, -1};
    //BubbleSort(a, sizeof(a)/sizeof(a[0]));
    size_t len = sizeof(a)/sizeof(a[0]);
    //InsertSort(a, len);
    // SelectSort(a, len);
    //MergeSort(a, 0, len-1);
    // QuickSort(a, 0, len-1);
    HeapSort(a, 0, len-1);
    for (int i = 0; i &lt; len;  i++)
    printf("%d: %d\n", i, a[i]);
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Libnetfilter_queue学习笔记]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/06/16/libnetfilter-queuexue-xi-bi-ji/"/>
    <updated>2015-06-16T18:53:42+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/06/16/libnetfilter-queuexue-xi-bi-ji</id>
    <content type="html"><![CDATA[<p>项目需要将某个进程发出的报文截获，待用户态业务处理后再将报文送回系统协议栈中处理。调研后，采用iptables添加防火墙规则截获报文传递到用户态队列，用户态进程使用libnetfilter_queue库接受报文，待业务处理后，将报文送回系统协议栈这样的方案完成。下面介绍下，学习的几个知识点：</p>

<h1>netfilter</h1>

<h2>简介</h2>

<p><a href="http://netfilter.org/">netfilter</a>是Linux 2.4.x开始以后内核版本中的报文过滤框架。netfilter框架的用户态工具是<a href="http://netfilter.org/projects/iptables/index.html">iptables</a>防火墙配置工具。<br/>
netfilter框架实现了报文过滤，网络地址转换，端口转换和其他报文管理。它是对Linux 2.2.x ipchains和Linux 2.0.x ipfwadm系统的重构和显著改进。<br/>
netfilter是位于Linux内核中的一组回调函数集合，各个模块可以在网络协议栈注册回调函数。每个报文到来时，将会遍历协议栈中的回调函数并调用。<br/>
iptables定义了规则集的通用格式。IP table中的每一条规则是有一些分类和相关的目标组成。<br/>
netfilter，ip_tables，connection tracking（ip_conntrack，nf_conntrack）和NAT子系统是netfilter的主要组成部分。</p>

<h2>主要特性</h2>

<ul>
<li>无状态报文过滤</li>
<li>有状态报文过滤</li>
<li>所有网络地址和端口转换，比如NAT/NAPT(IPv4和IPv6)</li>
<li>灵活的、可扩展的框架</li>
<li>为第三方扩展提供API访问网络各层</li>
</ul>


<h2>可以做哪些</h2>

<ul>
<li>基于无状态或者有状态报文过滤构建互联网防火墙</li>
<li>托管高可用有状态或者无状态的防火墙集群</li>
<li>使用NAT和ip伪装共享共网ip</li>
<li>使用NAT实现传输代理</li>
<li>与tc和iproute2系统一起构建复杂Qos和策略路由器</li>
<li>更进一步进行报文管理，比如修改IP头中的TOS/DSCP/ECN</li>
</ul>


<!-- more -->


<h1>libnetfilter_queue</h1>

<p>libnetfilter_queue是一个用户态库，它提供了接口用来访问已经被内核报文过滤模块放置在队列中的报文。libnetfilter_queue的前身是libnfnetlink_queue。<br/>
libnetfilter_queue需要libnfnetlink和包含nfnetlink_queue子系统的内核（2.6.14以后）。<br/>
主要特性：</p>

<ul>
<li>接收来自内核nfnetlink_queue子系统的报文</li>
<li>做出裁决，是否将修改后的报文重新注入内核nfnetlink_queue子系统</li>
</ul>


<h2>安装</h2>

<p>libnetfilter_queue需要libnfnetlink和libmnl库<br/>
1、安装libnfnetlink</p>

<pre><code>#wget http://netfilter.org/projects/libnfnetlink/files/libnfnetlink-1.0.1.tar.bz2
#tar jxvf libnfnetlink-1.0.1.tar.bz2
#cd libnfnetlink-1.0.1  
#./configure
#make &amp;&amp; make install
</code></pre>

<p>2、安装libmnl</p>

<pre><code>#wget http://netfilter.org/projects/libmnl/files/libmnl-1.0.3.tar.bz2
#tar jxvf libmnl-1.0.3.tar.bz2
#cd libmnl-1.0.3
#./configure
#make &amp;&amp; make install
</code></pre>

<p>3、安装libnetfilter_queue</p>

<pre><code>#wget http://netfilter.org/projects/libnetfilter_queue/files/libnetfilter_queue-1.0.2.tar.bz2
#tar jxvf libnetfilter_queue-1.0.2.tar.bz2
#cd libnetfilter_queue-1.0.2
#./configure
#make &amp;&amp; make install
</code></pre>

<h2>接口</h2>

<h3>初始化库</h3>

<pre><code>struct nfq_handle *     nfq_open (void)
int     nfq_close (struct nfq_handle *h)
int     nfq_bind_pf (struct nfq_handle *h, u_int16_t pf)
int     nfq_unbind_pf (struct nfq_handle *h, u_int16_t pf)
</code></pre>

<p>libnetfilter_queue初始化分为两部。<br/>
第一步调用nfq_open打开一个NFQUEUE句柄。<br/>
第二部通知内核指定协议的用户空间队列由NFQUEUE处理。调用nfq_unbind_pf()和nfq_bind接口进行绑定。<br/>
以下为初始化片段：</p>

<pre><code>h = nfq_open();
if (!h) {
    fprintf(stderr, "error during nfq_open()\n");
    exit(1);
}

printf("unbinding existing nf_queue handler for AF_INET (if any)\n");
if (nfq_unbind_pf(h, AF_INET) &lt; 0) {
    fprintf(stderr, "error during nfq_unbind_pf()\n");
    exit(1);
}

printf("binding nfnetlink_queue as nf_queue handler for AF_INET\n");
if (nfq_bind_pf(h, AF_INET) &lt; 0) {
    fprintf(stderr, "error during nfq_bind_pf()\n");
    exit(1);
}
</code></pre>

<p>nfq_open</p>

<pre><code>struct nfq_handle* nfq_open (void) 
</code></pre>

<p>nfq_open返回一个netfilter队列连接句柄。当使用完毕，调用nfq_close销毁句柄。在系统内部，会新创建一个netlink连接并与队列连接句柄相关联。</p>

<p>nfq_bind_pf</p>

<pre><code>int nfq_bind_pf (   struct nfq_handle *     h,
                    u_int16_t   pf   
                )   
</code></pre>

<p>nfq_bind_pf绑定一个协议域到nfqueue句柄。<br/>
队列连接句柄将会处理属于pf指定的协议报文，比如（PF_INET，PF_INET6）。
<a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/group__LibrarySetup.html">详细说明文档</a></p>

<h3>处理报文队列</h3>

<pre><code>int     nfq_fd (struct nfq_handle *h)   
struct nfq_q_handle *   nfq_create_queue (struct nfq_handle *h, u_int16_t num, nfq_callback *cb, void *data)
int     nfq_destroy_queue (struct nfq_q_handle *qh)
int     nfq_handle_packet (struct nfq_handle *h, char *buf,     int len)
int     nfq_set_mode (struct nfq_q_handle *qh, u_int8_t mode, u_int32_t range)
int     nfq_set_queue_maxlen (struct nfq_q_handle *qh, u_int32_t queuelen)
int     nfq_set_verdict (struct nfq_q_handle *qh, u_int32_t id, u_int32_t verdict, u_int32_t data_len, const unsigned char *buf)
int     nfq_set_verdict2 (struct nfq_q_handle *qh, u_int32_t id, u_int32_t verdict, u_int32_t mark, u_int32_t data_len, const unsigned char *buf)
int     nfq_set_verdict_mark (struct nfq_q_handle *qh, u_int32_t id, u_int32_t verdict, u_int32_t mark, u_int32_t data_len, const unsigned char *buf)
</code></pre>

<p>libnetfilter_queue库初始化后，可以绑定程序到具体报文队列。使用nfq_create_queue()进行绑定。
使用nfq_set_mode()和nfq_set_queue_maxlen()函数设置队列。
下面是创建队列0的代码片段：</p>

<pre><code>printf("binding this socket to queue '0'\n");
qh = nfq_create_queue(h,  0, &amp;cb, NULL);
if (!qh) {
    fprintf(stderr, "error during nfq_create_queue()\n");
    exit(1);
}

printf("setting copy_packet mode\n");
if (nfq_set_mode(qh, NFQNL_COPY_PACKET, 0xffff) &lt; 0) {
    fprintf(stderr, "can't set packet_copy mode\n");
    exit(1);
}
</code></pre>

<p>下一步是，循环读取队列中的报文进行处理：</p>

<pre><code>fd = nfq_fd(h);

while ((rv = recv(fd, buf, sizeof(buf), 0)) &gt;= 0) {
    printf("pkt received\n");
    nfq_handle_packet(h, buf, rv);
}
</code></pre>

<p>我们需要对每一个报文做出处理结果，通过nfq_set_verdict()或者nfq_set_verdict2()结果来传递结果。裁决结果决定报文的命运：</p>

<ul>
<li>NF_DROP   丢弃此报文</li>
<li>NF_ACCEPT 接受报文，继续迭代</li>
<li>NF_STOLEN gone away</li>
<li>NF_QUEUE  将报文注入另外一个队列</li>
<li>NF_REPEAT 重新再迭代一次</li>
<li>NF_STOP 接受，但是不再继续迭代</li>
</ul>


<p><a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/group__Queue.html">详细说明文档</a></p>

<h3>解析报文</h3>

<p>主要涉及以下接口：</p>

<pre><code>struct nfqnl_msg_packet_hdr *   nfq_get_msg_packet_hdr (struct nfq_data *nfad)
uint32_t    nfq_get_nfmark (struct nfq_data *nfad)
int     nfq_get_timestamp (struct nfq_data *nfad, struct timeval *tv)
u_int32_t   nfq_get_indev (struct nfq_data *nfad)
u_int32_t   nfq_get_physindev (struct nfq_data *nfad)
u_int32_t   nfq_get_outdev (struct nfq_data *nfad)
u_int32_t   nfq_get_physoutdev (struct nfq_data *nfad)
int     nfq_get_indev_name (struct nlif_handle *nlif_handle,    struct nfq_data *nfad, char *name)
int     nfq_get_physindev_name (struct nlif_handle *nlif_handle, struct nfq_data *nfad, char *name)
int     nfq_get_outdev_name (struct nlif_handle *nlif_handle, struct nfq_data *nfad, char *name)
int     nfq_get_physoutdev_name (struct nlif_handle *nlif_handle, struct nfq_data *nfad, char *name)
struct nfqnl_msg_packet_hw *    nfq_get_packet_hw (struct nfq_data *nfad)
int     nfq_get_payload (struct nfq_data *nfad, unsigned char **data)
</code></pre>

<p><a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/group__Parsing.html">详细说明文档</a></p>

<h2>示例</h2>

<p>示例源自libnetfilter_queue源代码中的例子<a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/nfqnl__test_8c_source.html">nfqnl_test.c</a></p>

<pre><code>00001 
00002 #include &lt;stdio.h&gt;
00003 #include &lt;stdlib.h&gt;
00004 #include &lt;unistd.h&gt;
00005 #include &lt;netinet/in.h&gt;
00006 #include &lt;linux/types.h&gt;
00007 #include &lt;linux/netfilter.h&gt;            /* for NF_ACCEPT */
00008 
00009 #include &lt;libnetfilter_queue/libnetfilter_queue.h&gt;
00010 
00011 /* returns packet id */
00012 static u_int32_t print_pkt (struct nfq_data *tb)
00013 {
00014         int id = 0;
00015         struct nfqnl_msg_packet_hdr *ph;
00016         struct nfqnl_msg_packet_hw *hwph;
00017         u_int32_t mark,ifi; 
00018         int ret;
00019         unsigned char *data;
00020 
00021         ph = nfq_get_msg_packet_hdr(tb); // 返回报文头信息
00022         if (ph) {
00023                 id = ntohl(ph-&gt;packet_id);
00024                 printf("hw_protocol=0x%04x hook=%u id=%u ",
00025                         ntohs(ph-&gt;hw_protocol), ph-&gt;hook, id);
00026         }
00027 
00028         hwph = nfq_get_packet_hw(tb); // 返回报文硬件地址信息
00029         if (hwph) {
00030                 int i, hlen = ntohs(hwph-&gt;hw_addrlen);
00031 
00032                 printf("hw_src_addr=");
00033                 for (i = 0; i &lt; hlen-1; i++)
00034                         printf("%02x:", hwph-&gt;hw_addr[i]);
00035                 printf("%02x ", hwph-&gt;hw_addr[hlen-1]);
00036         }
00037 
00038         mark = nfq_get_nfmark(tb); // 返回报文标记
00039         if (mark)
00040                 printf("mark=%u ", mark);
00041 
00042         ifi = nfq_get_indev(tb); // 获取报文接收网卡的索引
00043         if (ifi)
00044                 printf("indev=%u ", ifi);
00045 
00046         ifi = nfq_get_outdev(tb); // 获取报文发送网卡的索引
00047         if (ifi)
00048                 printf("outdev=%u ", ifi); 
00049         ifi = nfq_get_physindev(tb); // 接收此报文的物理网卡索引
00050         if (ifi)
00051                 printf("physindev=%u ", ifi);
00052  
00053         ifi = nfq_get_physoutdev(tb); // 发送次报文的物理网卡索引
00054         if (ifi)
00055                 printf("physoutdev=%u ", ifi);
00056 
00057         ret = nfq_get_payload(tb, &amp;data); // 获取报文内容的长度
00058         if (ret &gt;= 0)
00059                 printf("payload_len=%d ", ret);
00060 
00061         fputc('\n', stdout);
00062 
00063         return id;
00064 }
00065         
00066 
00067 static int cb(struct nfq_q_handle *qh, struct nfgenmsg *nfmsg,
00068               struct nfq_data *nfa, void *data)
00069 {
00070         u_int32_t id = print_pkt(nfa);
00071         printf("entering callback\n");
00072         return nfq_set_verdict(qh, id, NF_ACCEPT, 0, NULL);
00073 }
00074 
00075 int main(int argc, char **argv)
00076 {
00077         struct nfq_handle *h;
00078         struct nfq_q_handle *qh;
00079         struct nfnl_handle *nh;
00080         int fd;
00081         int rv;
00082         char buf[4096] __attribute__ ((aligned));
00083           
00084         printf("opening library handle\n");
00085         h = nfq_open(); // 获取libnetfilter 队列句柄
00086         if (!h) {
00087                 fprintf(stderr, "error during nfq_open()\n");
00088                 exit(1);
00089         }
00090 
00091         printf("unbinding existing nf_queue handler for AF_INET (if any)\n");
00092         if (nfq_unbind_pf(h, AF_INET) &lt; 0) { // 先将队列连接句柄与AF_INET地址域解绑
00093                 fprintf(stderr, "error during nfq_unbind_pf()\n");
00094                 exit(1);
00095         }
00096 
00097         printf("binding nfnetlink_queue as nf_queue handler for AF_INET\n");
00098         if (nfq_bind_pf(h, AF_INET) &lt; 0) { // 将队列连接句柄与AF_INET地址绑定
00099                 fprintf(stderr, "error during nfq_bind_pf()\n");
00100                 exit(1);
00101         }
00102 
00103         printf("binding this socket to queue '0'\n");
00104         qh = nfq_create_queue(h,  0, &amp;cb, NULL); // 创建队列句柄用来处理0队列报文
00105         if (!qh) {
00106                 fprintf(stderr, "error during nfq_create_queue()\n");
00107                 exit(1);
00108         }
00109 
00110         printf("setting copy_packet mode\n");
00111         if (nfq_set_mode(qh, NFQNL_COPY_PACKET, 0xffff) &lt; 0) { // 设置队列工作模式
00112                 fprintf(stderr, "can't set packet_copy mode\n");
00113                 exit(1);
00114         }
00115 
00116         fd = nfq_fd(h); // 获取队列连接描述符
00117 
00118         while ((rv = recv(fd, buf, sizeof(buf), 0)) &amp;&amp; rv &gt;= 0) {
00119                 printf("pkt received\n");
00120                 nfq_handle_packet(h, buf, rv); // 处理收到的每个报文
00121         }
00122 
00123         printf("unbinding from queue 0\n");
00124         nfq_destroy_queue(qh); // 从队列0解绑
00125 
00126 #ifdef INSANE
00127         /* normally, applications SHOULD NOT issue this command, since
00128          * it detaches other programs/sockets from AF_INET, too ! */
00129         printf("unbinding from AF_INET\n");
00130         nfq_unbind_pf(h, AF_INET);
00131 #endif
00132 
00133         printf("closing library handle\n");
00134         nfq_close(h); // 关闭库句柄
00135 
00136         exit(0);
00137 }
</code></pre>

<p>编译程序：</p>

<pre><code>gcc nfqnl_test.c -lnetfilter_queue -o nfqnl_test
</code></pre>

<p>配置iptables：
使用iptables命令修改防火墙规则，将发送到112.80.248.74的报文放置到队列0中：</p>

<pre><code>#iptables -t filter -A OUTPUT -d 112.80.248.74 -j NFQUEUE --queue-num 0
#iptables -t filter -L
Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
NFQUEUE    all  --  anywhere             112.80.248.74  NFQUEUE num 0
</code></pre>

<p>启动ping程序：</p>

<pre><code># ping 112.80.248.74
PING 112.80.248.74 (112.80.248.74) 56(84) bytes of data.
</code></pre>

<p>当nfqnl_test程序未启动时，ping程序不能正确发送出icmp报文，也就不能收到icmp回复。</p>

<p>启动nfqnl_test程序：</p>

<pre><code># ./nfqnl_test
opening library handle
unbinding existing nf_queue handler for AF_INET (if any)
binding nfnetlink_queue as nf_queue handler for AF_INET
binding this socket to queue '0'
setting copy_packet mode
pkt received
hw_protocol=0x0000 hook=3 id=1 outdev=2 payload_len=84
entering callback
pkt received
hw_protocol=0x0000 hook=3 id=2 outdev=2 payload_len=84
</code></pre>

<p>nfqnl_test程序从nfqueue_num 0中读取报文，打印相关信息后，将报文送回协议栈，完成了发送流程，从目标收到了icmp报文回复</p>

<pre><code>64 bytes from 112.80.248.74: icmp_req=612 ttl=58 time=1.84 ms
64 bytes from 112.80.248.74: icmp_req=613 ttl=58 time=1.83 ms
64 bytes from 112.80.248.74: icmp_req=614 ttl=58 time=1.76 ms
64 bytes from 112.80.248.74: icmp_req=615 ttl=58 time=1.83 ms
64 bytes from 112.80.248.74: icmp_req=616 ttl=58 time=1.97 ms
64 bytes from 112.80.248.74: icmp_req=617 ttl=58 time=1.92 ms
64 bytes from 112.80.248.74: icmp_req=618 ttl=58 time=2.07 ms   
</code></pre>

<h1>参考</h1>

<p>netfilter<a href="http://www.netfilter.org/">官网</a><br/>
<a href="http://bbs.chinaunix.net/forum.php?mod=viewthread&amp;tid=1196223">用户态修改网络数据包例子</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用FIFO命名管道进行进程间通讯]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/06/14/shi-yong-fifoming-ming-guan-dao-jin-xing-jin-cheng-jian-tong-xun/"/>
    <updated>2015-06-14T15:56:00+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/06/14/shi-yong-fifoming-ming-guan-dao-jin-xing-jin-cheng-jian-tong-xun</id>
    <content type="html"><![CDATA[<p>管道是进程间通讯的一种方式。使用<code>pipe</code>，<code>popen</code>，<code>pclose</code>，等接口我们可以使用管道来进行进程间通讯。但是这一种管道只能由相关进程使用，这些相关进程的共同祖先进程创建了管道。通过FIFO，也称为命名管道，不相关的进程也可以进行通讯。</p>

<h1>创建命名管道</h1>

<p>调用mkfifo接口创建命名管道：</p>

<pre><code>#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
int mkfifo(const char *path, mode_t mode);
</code></pre>

<p>创建FIFO类似于创建文件。FIFO的路径名存在于文件系统中。FIFO是一种文件类型。stat结构成员st_mode的编码指明文件是否是FIFO类型。可以用S_ISFIFO宏对此进行测试。 mkfifo函数创建一个路径名为path的fifo。mode和umask掩码规定了命名管道的访问权限。<br/>
参数：<br/>
path是管道在文件系统中的存在路径。<br/>
mode于open函数中定义的mode一样。</p>

<p>返回值：<br/>
成功返回0。失败返回-1，同时设置errno错误码。</p>

<p>错误原因：</p>

<ul>
<li>ENOTSUP       系统内核不支持fifo</li>
<li>ENOTDIR       path前缀不是合法目录</li>
<li>ENAMETOOLONG  path路径太长</li>
<li>EACCESS       用户对于path中的目录没有权限访问</li>
<li>EROFS         path指定的目录在只读文件系统</li>
<li><p>EEXIST        path指定文件已经存在</p>

<p>  <!-- more --></p></li>
</ul>


<h1>注意事项</h1>

<p>我们可以像访问普通文件一样访问命名管道文件。一般的文件I/O函数都可以用于FIFO。<br/>
当打开一个FIFO，非阻塞标志（O_NONBLOCK）产生下列影响：</p>

<ul>
<li>在一般情况下（没有指定O_NOBLOCK），只读open要阻塞到某个其他进程为写而打开此FIFO。类似地，只写open要阻塞到某个进程为读而打开此FIFO。</li>
<li>如果指定了O_NONBLOCK，则只读open立即返回。但是，如果没有进程已经为读而打开一个FIFO，那么只写open将出错返回-1，其errno是ENXIO。</li>
</ul>


<p>当多个写进程同时向同一FIFO进行写操作时，如果保证来自不同程序的数据块不相互交错，每个写操作必须原子话，FIFO的长度是需要考虑的一个很重要因素。系统对任一时刻在一个FIFO中可以存在的数据长度是有限制的。它由#define PIPE_BUF定义，在头文件limits.h中。在Linux和许多其他类UNIX系统中，它的值通常是4096字节，Red Hat Fedora9下是4096，但在某些系统中它可能会小到512字节。</p>

<ul>
<li>当要写入的数据量不大于PIPE_BUF时，Linux将保证写入的原子性。如果此时管道空闲缓冲区不足以容纳要写入的字节数，则进入睡眠，直到当缓冲区中能够容纳要写入的字节数时，才开始进行一次性写操作。即写入的数据长度小于等于PIPE_BUF时，那么或者写入全部字节，或者一个字节都不写入，它属于一个一次性行为，具体要看FIFO中是否有足够的缓冲区。</li>
<li>当要写入的数据量大于PIPE_BUF时，Linux将不再保证写入的原子性。FIFO缓冲区一有空闲区域，写进程就会试图向管道写入数据，写操作在写完所有请求写的数据后返回。</li>
</ul>


<h1>FIFO示例</h1>

<p>创建FIFO</p>

<pre><code>ret = mkfifo(FIFO_NAME,0777);
if ((-1 == ret) &amp;&amp; (errno != EEXIST)) {
    perror("create fifo fail.\n");
    exit(1);
}
</code></pre>

<p>读FIFO进程代码</p>

<pre><code>// create fifo
int ret = mkfifo(FIFO_NAME,0777);
if ((-1 == ret) &amp;&amp; (errno != EEXIST)) {
    perror("create fifo fail.\n");
    exit(1);
}

int fd = open(FIFO_NAME, O_RDONLY);
// int fd = open(FIFO_NAME, O_RDWR);
if (-1 == fd) {
    printf("open fifo %s fail\n", FIFO_NAME);
    exit(1);
}
printf("open fifo %s for read suc\n", FIFO_NAME);

char buf[1024];
while (1 ) {
    ssize_t size = read(fd, buf, sizeof(buf));
    if (size &gt; 0) {
        buf[size] = '\0';
        printf("read from fifo: %s\n", buf);
    } else if(size == 0) {
        printf("write end of fifo exit\n");
        break;
    } else {
        perror("read fail from fifo:");
        break;
    }
}
close(fd);
return 0;
</code></pre>

<p>写FIFO进程代码</p>

<pre><code>// create fifo
int ret = mkfifo(FIFO_NAME,0777);
if ((-1 == ret) &amp;&amp; (errno != EEXIST)) {
    perror("create fifo fail.\n");
    exit(1);
}

int fd = open(FIFO_NAME, O_WRONLY);
if (-1 == fd) {
    printf("open fifo %s fail\n", FIFO_NAME);
    exit(1);
}
printf("open fifo %s for write suc", FIFO_NAME);

while (1) {
    char buf[1024] = {0};
    if (gets(buf) == NULL) {
        break;
    }
    int len = strlen(buf);
    if (0 == len)
      break;
    printf("%d\n", len);
    ssize_t size = write(fd, buf, len);
    if (size &gt;= 0) {
        printf("write to fifo: %s, msg: %s, size:%ld \n", FIFO_NAME, buf, size);
    } else {
        perror("write fail\n");
        break;
    }
}
close(fd);
return 0;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux/Unix设置SUID]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/06/02/linux-slash-unixshe-zhi-suid/"/>
    <updated>2015-06-02T13:56:27+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/06/02/linux-slash-unixshe-zhi-suid</id>
    <content type="html"><![CDATA[<h1>非root用户运行tcpdump</h1>

<p>有些时候，我们希望以非root用户运行一些程序，比如以普通用户运行tcpdump命令进行抓包时，系统报如下异常信息：</p>

<p>Mac OS 系统：</p>

<pre><code>MacBook-Pro:plugins jintao$ tcpdump
tcpdump: ioctl(SIOCIFCREATE): Operation not permitted
MacBook-Pro:plugins jintao$
</code></pre>

<p>Ubuntu系统：</p>

<pre><code>[app@mp5 ~]$ tcpdump
tcpdump: no suitable device found
[app@mp5 ~]$
</code></pre>

<p>为什么会出现上述异常信息呢？是否是因为普通用户没有执行权限？下面是系统中tcpdump命令的权限信息<br/>
Mac OS 系统：</p>

<pre><code>MacBook-Pro:plugins jintao$ which tcpdump
/usr/sbin/tcpdump
MacBook-Pro:plugins jintao$ ls -l /usr/sbin/tcpdump
-rwxr-xr-x 1 root wheel 749040  9 10  2014 /usr/sbin/tcpdump*
MacBook-Pro:plugins jintao$
</code></pre>

<p>Ubuntu系统：</p>

<pre><code>[app@mp5 ~]$ which tcpdump
/usr/sbin/tcpdump
[app@mp5 ~]$ ls -l /usr/sbin/tcpdump
-rwxr-xr-x. 1 root root 742080 3月  26 2012 /usr/sbin/ tcpdump
[app@mp5 ~]$
</code></pre>

<p>根据tcpdump的权限位-rwxr-xr-x我们发现对于普通用户jintao、app是拥有可读和可执行权限的。以普通用户执行tcpdump时，tcpdump进程的实际运行用户和有效用户都是普通用户，tcpdump运行过程中需要获取系统网卡资源信息，而获取这些信息需要root权限，这样的话系统就禁止了tcpdump程序的运行。<br/>
解决这样的问题，我们可以尝试以下三种方法：</p>

<p>  <!-- more --></p>

<ul>
<li>su切换到root用户，然后再执行tcpdump，这一解决方案与我们以非root用户运行不符</li>
<li>以root用户编辑/etc/sudoers文件，赋予普通用户执行tcpdump命令的权限</li>
<li>设置tcpdump程序的用户ID权限位SUID</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MacBook-Pro:C++ jintao$ sudo chmod u+s /usr/sbin/tcpdump
</span><span class='line'>Password:
</span><span class='line'>MacBook-Pro:C++ jintao$ ls -l /usr/sbin/tcpdump
</span><span class='line'>-rwsr-xr-x 1 root wheel 749040  9 10  2014 /usr/sbin/tcpdump*
</span><span class='line'>MacBook-Pro:C++ jintao$ tcpdump
</span><span class='line'>tcpdump: data link type PKTAP
</span><span class='line'>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span></code></pre></td></tr></table></div></figure>


<p>下面着重介绍第三种方法：</p>

<h1>什么是SUID</h1>

<p>SUID(Set owner User ID)是赋予文件的一种特殊权限位。在UNIX系统中，特权（例如能改变当前日期的表示法以及访问控制（例如，能否读、写一特定文件））是基于用户和组ID的。用户运行某程序时，程序访问资源的权限基于运行此程序的用户来决定。SUID被用来赋予程序访问资源的权限与程序的拥有者相同，而不是实际执行者。一言以蔽之，运行设置SUID权限位的程序时，普通用户将会获取文件拥有者的用户ID(UID)和组ID(GID)。</p>

<h2>Example1:passwd command</h2>

<p>我们运行passwd来修改我们的登陆密码，passwd命令拥有者是root用户。passwd命令会尝试修改系统配置文件，比如/etc/passwd, /etc/shadow等。其中的一些文件，只有root权限才能访问，非root用户无法打开。如果去掉SUID权限位，只是设置passwd command文件的所有权限位，那这个命令无法访问/etc/shadow等文件，程序会返回权限禁止错误或者其他措施。所以passwd被设置SUID权限位来赋予非root用户更新/etc/shadow等文件的权限。</p>

<h2>Example2: ping command</h2>

<p>当我们运行ping命令时，ping命令会打开socket文件和端口用来发送和接收IP数据包。非root用户无法获取权限打开socket和端口。所以对ping命令文件设置SUID权限位，任何执行ping命令的用户都可以获取ping命令文件拥有者（root用户）的权限。当执行ping命令时就拥有root权限来打开socket和端口port</p>

<h1>如何设置文件SUID权限位</h1>

<p>与设置文件其他的读、写、可执行权限位类似，可以用以下方法设置</p>

<pre><code>* 字符命令方式（s代表Set）
* 八进制数字（4）
</code></pre>

<p>对file1.sh设置SUID</p>

<p>字符模式：</p>

<pre><code>chmod u+s file1.sh
</code></pre>

<p>设置owner可执行权限位为SUID位</p>

<p>数字模式：</p>

<pre><code>chmod 4750 file1.sh
</code></pre>

<p>4750，4代表设置SUID权限位，7代表owner可读、可写、可执行权限位，5代表组拥有可读、可执行权限位，0代表其他不会不具有任何权限。</p>

<p>对于file1.sh文件，设置SUID前权限位：</p>

<pre><code>MacBook-Pro:C++ jintao$ ls -l file1.sh
-rwxr--r-- 1 jintao staff 0  6  2 15:57 file1.sh*
MacBook-Pro:C++ jintao$
</code></pre>

<p>设置SUID权限位后：</p>

<pre><code>MacBook-Pro:C++ jintao$ ls -l file1.sh
-rwsr--r-- 1 jintao staff 0  6  2 15:57 file1.sh*
MacBook-Pro:C++ jintao$
</code></pre>

<h1>何时使用SUID</h1>

<p>1）当需要root用户登录来执行某些命令/程序/脚本<br/>
2）不想赋予某些特殊用户信任，但是想以owner用户运行某些命令时<br/>
3）不想使用SUDO命令而执行某些文件、脚本时</p>

<h1>参考</h1>

<p><a href="http://www.linuxnix.com/2011/12/suid-set-suid-linuxunix.html">http://www.linuxnix.com/2011/12/suid-set-suid-linuxunix.html</a></p>
]]></content>
  </entry>
  
</feed>

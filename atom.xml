<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[jintao's blog]]></title>
  <link href="http://jintao-zero.github.io/atom.xml" rel="self"/>
  <link href="http://jintao-zero.github.io/"/>
  <updated>2017-01-01T23:04:46+08:00</updated>
  <id>http://jintao-zero.github.io/</id>
  <author>
    <name><![CDATA[jintao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Golang Cpu性能优化]]></title>
    <link href="http://jintao-zero.github.io/blog/2017/01/01/golang-cpuxing-neng-you-hua/"/>
    <updated>2017-01-01T17:18:20+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2017/01/01/golang-cpuxing-neng-you-hua</id>
    <content type="html"><![CDATA[<p>本文根据<a href="https://blog.golang.org/profiling-go-programs">Profiling Go Programs</a>文章，进行演示如何利用Golang性能工具进行cpu性能统计和优化。</p>

<h2>准备工作</h2>

<p>1、Golang编译运行环境。</p>

<pre><code>go version go1.7 darwin/amd64
</code></pre>

<p>2、下载<a href="https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/benchgraffiti/source-archive.zip">测试源码</a></p>

<pre><code>-rw-r--r-- 1 jintao staff 16594  1  1 16:58 havlak1.go
-rw-r--r-- 1 jintao staff 16597  1  1 16:58 havlak2.go
-rw-r--r-- 1 jintao staff 16832  1  1 16:58 havlak3.go
-rw-r--r-- 1 jintao staff 16905  1  1 16:58 havlak4.go
-rw-r--r-- 1 jintao staff 17501  1  1 16:58 havlak5.go
-rw-r--r-- 1 jintao staff  9467  1  1 16:58 havlak6.go
</code></pre>

<p>havlak1-6是源文件，以及优化后的源文件</p>

<h2>采集CPU性能数据</h2>

<p>优化程序之前，需要采集性能数据。多种方法可以使用，本文中采用的方法是引入<code>runtime/pprof</code>包，在代码文件main函数中添加如下代码片段:</p>

<pre><code>var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to file")

func main() {
    flag.Parse()
    if *cpuprofile != "" {
        f, err := os.Create(*cpuprofile)
        if err != nil {
          log.Fatal(err)
        }
        pprof.StartCPUProfile(f)
        defer pprof.StopCPUProfile()
    }
    ... 
</code></pre>

<p>利用flag包设置并解析cpuprofile参数，传入文件名，创建文件，调用<code>ppfof.StartCPUProfile</code>方法开始进行采样，并将采样结果保存在文件中，在程序返回之前调用<code>pprof.StopCPUProfile</code>方法确保所有采样数据刷新到结果文件中。</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ time ./havlak1 -cpuprofile=havlak1.prof
# of loops: 76000 (including 1 artificial root node)

real    0m21.768s
user    0m31.026s
sys 0m0.284s
</code></pre>

<p>产生性能文件havlak1.prof</p>

<!-- more -->


<h2>分析性能文件</h2>

<p><code>go tool pprof</code>是<a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools">Google&rsquo;s pprof C++ profiler</a>一个变种，利用go tool pprof命令读取分析性能文件:</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go tool pprof havlak1 havlak1.prof
Entering interactive mode (type "help" for commands)
(pprof)
</code></pre>

<p>输入<code>help</code>可以查看哪些可用命令，最常用是<code>top n</code>命令，查看前n个样本：</p>

<pre><code>(pprof) top
18750ms of 27430ms total (68.36%)
Dropped 95 nodes (cum &lt;= 137.15ms)
Showing top 10 nodes out of 80 (cum &gt;= 790ms)
      flat  flat%   sum%        cum   cum%
    3360ms 12.25% 12.25%     6790ms 24.75%  runtime.scanobject
    2890ms 10.54% 22.79%    14430ms 52.61%  main.FindLoops
    2470ms  9.00% 31.79%     2760ms 10.06%  runtime.mapaccess1_fast64
    1950ms  7.11% 38.90%     5140ms 18.74%  runtime.mapassign1
    1690ms  6.16% 45.06%     4080ms 14.87%  runtime.mallocgc
    1630ms  5.94% 51.00%     1630ms  5.94%  runtime.heapBitsForObject
    1580ms  5.76% 56.76%     3440ms 12.54%  main.DFS
    1250ms  4.56% 61.32%     1250ms  4.56%  runtime.memmove
    1140ms  4.16% 65.48%     1890ms  6.89%  runtime.greyobject
     790ms  2.88% 68.36%      790ms  2.88%  runtime/internal/atomic.Or8
(pprof)
</code></pre>

<p>启动性能分析时，Go程序每秒钟停止100次并对当前正在执行的goroutine调用栈进行采样。从上面数据可以看到，程序总执行时间为27430ms，采样top10函数一共占用18750ms（68.36%）。每行是一个函数的统计数据，前两列数据分别为采样时goroutine正在当前函数中的时间和占比，后两列为采样时此函数出现（正在执行或正在等待调用函数返回）的时间和占比。sum%列为前n行消耗时间之和对于总时间的占比。<code>main.FindLoops</code>函数正在执行的时间是2890ms占10.54%，在调用栈中出现的时间为14430ms占比为52.61%。<code>runtime.mapaccess1_fast64</code>执行的时间为2470ms占9.00%，在调用栈中出现的时间为2760ms占比为10.06%。使用-cum参数，按照第四第五列排序</p>

<pre><code>(pprof) top5 -cum
2.89s of 27.43s total (10.54%)
Dropped 95 nodes (cum &lt;= 0.14s)
Showing top 5 nodes out of 80 (cum &gt;= 14.43s)
  flat  flat%   sum%        cum   cum%
     0     0%     0%     22.79s 83.08%  runtime.goexit
     0     0%     0%     14.52s 52.93%  main.main
     0     0%     0%     14.52s 52.93%  runtime.main
     0     0%     0%     14.43s 52.61%  main.FindHavlakLoops
 2.89s 10.54% 10.54%     14.43s 52.61%  main.FindLoops
(pprof)
</code></pre>

<p>调用栈采样数据中关于函数间的调用关系可以有其他的有趣方式进行展现。比如<code>web</code>命令输出一个图片并用浏览器打开。<code>gv</code>命令写PostScript并在Ghostview中打开。</p>

<pre><code>(pprof) web
(pprof)
</code></pre>

<p>以下为图片部分截图： <br/>
<img src="http://jintao-zero.github.io/images/havlak1.png" alt="web" />
    图中每个方块对应一个单独函数，方块的大小与函数消耗的时间相对应。从X到Y的边显示X调用Y；边上的数字代表在被调用函数中消耗的时间。从图中我们可以发现在runtime.mapaccess1_fast64和runtime.mapassign1函数上消耗了较多时间。<br/>
    可以只显示包含某个函数的调用关系图：</p>

<pre><code>(pprof) web mapaccess
(pprof)
</code></pre>

<p><img src="http://jintao-zero.github.io/images/havlak1-mapaccess.png" alt="mapaccess" /><br/>
从上图我们可以发现主要是main.DFS和main.FindLoops函数调用了runtime.mapaccess<br/>
接下来重点分析<code>main.DFS</code>和<code>main.FindLoops</code>两个函数的时间消耗情况：</p>

<pre><code>(pprof) list DFS
Total: 27.43s
ROUTINE ======================== main.DFS in /Users/jintao/Project/opensource/benchgraffiti/havlak_new/havlak1.go
     1.58s      6.84s (flat, cum) 24.94% of Total
         .          .    235:   return false
         .          .    236:}
         .          .    237:
         .          .    238:// DFS - Depth-First-Search and node numbering.
         .          .    239://
      20ms       20ms    240:func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
     140ms      140ms    241:   nodes[current].Init(currentNode, current)
         .      310ms    242:   number[currentNode] = current
         .          .    243:
         .          .    244:   lastid := current
        1s         1s    245:   for _, target := range currentNode.OutEdges {
     160ms      1.31s    246:       if number[target] == unvisited {
      40ms      3.44s    247:           lastid = DFS(target, nodes, number, last, lastid+1)
         .          .    248:       }
         .          .    249:   }
     200ms      600ms    250:   last[number[currentNode]] = lastid
      20ms       20ms    251:   return lastid
         .          .    252:}
         .          .    253:
         .          .    254:// FindLoops
         .          .    255://
         .          .    256:// Find loops and build loop forest using Havlak's algorithm, which
(pprof)
</code></pre>

<p><code>list DFS</code> 会列出所有匹配DFS函数名的函数。从上面的代码我们发现耗时的语句分别在<code>242 246 247 250</code>行其中 247行是与DFS行数调用有关，其他三行都是与number变量有关，number是一个map数据结构，可以考虑改为采用slice，使用block number作为索引。</p>

<p>对文件进行修改，diff修改如下：</p>

<pre><code>240c240
&lt; func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
---
&gt; func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number []int, last []int, current int) int {
242c242
&lt;   number[currentNode] = current
---
&gt;   number[currentNode.Name] = current
246c246
&lt;       if number[target] == unvisited {
---
&gt;       if number[target.Name] == unvisited {
250c250
&lt;   last[number[currentNode]] = lastid
---
&gt;   last[number[currentNode.Name]] = lastid
271c271
&lt;   number := make(map[*BasicBlock]int)
---
&gt;   number := make([]int, size)
287c287
&lt;       number[bb] = unvisited
---
&gt;       number[bb.Name] = unvisited
315c315
&lt;               v := number[nodeV]
---
&gt;               v := number[nodeV.Name]
</code></pre>

<p>测试修改后的cpu性能：</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go build havlak2.go
MacBook-Pro-2:havlak_new jintao$ time ./havlak2 -   cpuprofile=havlak2.prof
# of loops: 76000 (including 1 artificial root node)

real    0m11.685s
user    0m19.647s
sys 0m0.268s
</code></pre>

<p>再次使用go tool profile工具查看topn数据：</p>

<pre><code>MacBook-Pro-2:havlak_new jintao$ go tool pprof havlak2 havlak2.prof
Entering interactive mode (type "help" for commands)
(pprof) top
11460ms of 16610ms total (68.99%)
Dropped 92 nodes (cum &lt;= 83.05ms)
Showing top 10 nodes out of 87 (cum &gt;= 540ms)
   flat  flat%   sum%        cum   cum%
2950ms 17.76% 17.76%     5630ms 33.90%  runtime.scanobject
1500ms  9.03% 26.79%     4100ms 24.68%  runtime.mallocgc
1260ms  7.59% 34.38%     1260ms  7.59%  runtime.heapBitsForObject
1250ms  7.53% 41.90%     8700ms 52.38%  main.FindLoops
 920ms  5.54% 47.44%     1450ms  8.73%  runtime.greyobject
 920ms  5.54% 52.98%     2120ms 12.76%  runtime.mapassign1
 770ms  4.64% 57.62%      780ms  4.70%  runtime.heapBitsSetType
 760ms  4.58% 62.19%      760ms  4.58%  runtime.memmove
 590ms  3.55% 65.74%     1500ms  9.03%  runtime.makemap
 540ms  3.25% 68.99%      540ms  3.25%  runtime/internal/atomic.Or8
(pprof)
</code></pre>

<p>从上面可以看到<code>main.DFS</code>已经不在topn列表上，其他函数的时间也在显著下降。现在累计有24.68%的时间用在分配内存和垃圾回收（<code>runtime.mallocgc</code>）。下面需要使用进行内存性能优化。</p>

<h2>参考</h2>

<p>1、<a href="https://blog.golang.org/profiling-go-programs">Golang官方博客</a><br/>
2、<a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools">C++ pprof</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang日期转化处理]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/10/30/golangri-qi-zhuan-hua-chu-li/"/>
    <updated>2016-10-30T22:13:12+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/10/30/golangri-qi-zhuan-hua-chu-li</id>
    <content type="html"><![CDATA[<p>golang中time包提供了时间操作函数。</p>

<h2>获取时间</h2>

<pre><code>type Time struct {
    // contains filtered or unexported fields
}

func Date(year int, month Month, day, hour, min, sec, nsec int, loc *Location) Time
func Now() Time
</code></pre>

<p>一个Time结构体代表一个纳米精度的时间实例。now函数可以获取当前时间：</p>

<pre><code>now := time.Now()
fmt.Println(now)
</code></pre>

<p>结果如下：</p>

<pre><code>2016-11-27 22:46:17.666418725 +0800 CST 
</code></pre>

<!-- more -->


<h2>格式化时间</h2>

<pre><code>func (t Time) Format(layout string) string
</code></pre>

<p>Format方法可以按照layout定义的格式格式化时间字符串。<br/>
Golang中以2006 01 02 03 04 05 分别定义年、月、日 时、分、秒字段，03的24表示法为15。<br/>
比如将当前时间格式化为YYYY-mm-dd hh:MM:ss，则layout为<code>2006-01-02 15:04:05</code></p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
</code></pre>

<p> 输出为：</p>

<pre><code>2016-11-27 22:56:40
</code></pre>

<p>控制精度的方法为在秒后面加0, 000、000000、000000000分别代表毫秒、微秒、纳秒：</p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
fmt.Println(now.Format("2006-01-02 15:04:05.000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000000"))
</code></pre>

<p>输出：</p>

<pre><code>now := time.Now()
fmt.Println(now.Format("2006-01-02 15:04:05"))
fmt.Println(now.Format("2006-01-02 15:04:05.000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000"))
fmt.Println(now.Format("2006-01-02 15:04:05.000000000"))
</code></pre>

<h2>解析时间</h2>

<pre><code>func Parse(layout, value string) (Time, error)
func ParseInLocation(layout, value string, loc *Location) (Time, error)
</code></pre>

<p>Parse函数将格式化字符串解析为一个时间实例。<code>layout</code>定义了时间字符串的表现格式，比如：</p>

<pre><code>Mon Jan 2 15:04:05 -0700 MST 2006
</code></pre>

<p>当待解析时间字符串中没有时区时，<code>Parse</code>默认按照<code>UTC</code>时区解析时间。<code>ParseInLocation</code>按照loc参数指定的的location解析时间。</p>

<h2>定时器</h2>

<p>定时器通过<code>NewTimer</code>或者<code>AfterFunc</code>创建，用AfterFunc创建的定时器超时后，在定时器goroutine中调用func函数，其他定时器则通过C通道发送一个时间对象。</p>

<pre><code>type Timer struct {
    C &lt;-chan Time
    // contains filtered or unexported fields
}

func AfterFunc(d Duration, f func()) *Timer  
func NewTimer(d Duration) *Timer
</code></pre>

<p>定时器在使用过程中需要注意<code>Reset</code>和<code>Stop</code>方法的使用：</p>

<pre><code>func (t *Timer) Stop() bool
</code></pre>

<p>Stop方法用来停止定时器触发。停止定时器则返回true，如果定时器已经超时或者已经被停止则返回false。Stop方法不关闭定时器中的channel。<br/>
为了防止调用Stop方法后，定时器仍然触发，需要检查方法返回值并且读取定时器时间channel，代码片段：</p>

<pre><code>if !t.Stop() {
    &lt;-t.C
}

func (t *Timer) Reset(d Duration) bool
</code></pre>

<p><strong>需要特别注意的是，不要并发执行上面的代码。</strong></p>

<p>Reset修改定时器的超时时间为d。修改成功则返回true，如果定时器已经超时或者被停止则返回false。</p>

<pre><code>func (t *Timer) Reset(d Duration) bool
</code></pre>

<p>为了重复一个已经激活的定时器，需要先调用定时器<code>Stop</code>方法，如果定时器已经超时，则例如一下代码片段，先读取channel中的时间：</p>

<pre><code>if !t.Stop() {
    &lt;-t.C
}
t.Reset(d)
</code></pre>

<p><strong>需要特别注意的是，不要并发执行上面的代码。</strong>  <br/>
在读取通道和定时器超时之间存在竞态条件，所以几乎不可能正确使用Reset方法的返回值。Reset方法应该总是与Stop方法一起使用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grep命令]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/10/05/grepming-ling/"/>
    <updated>2016-10-05T20:48:14+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/10/05/grepming-ling</id>
    <content type="html"><![CDATA[<h1>grep命令</h1>

<p>grep, egrep, fgrep, zgrep, zegrep, zfgrep 文件模式搜索</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]] [-e pattern] [-f file] [--binary-files=value] [--color[=when]]
</span><span class='line'>          [--colour[=when]] [--context[=num]] [--label] [--line-buffered] [--null] [pattern] [file ...]</span></code></pre></td></tr></table></div></figure>


<p>grep搜索输入文件，输出匹配一个或者多个模式的文件行。通常情况，不包括结尾换行符的文件行匹配指定模式中的表达式即为匹配成功。空表达式匹配所有行。匹配行将会打印到标准输出。<br/>
grep命令用于简单模式和基本正则表达式（BRES）；egrep命令可以处理扩展正则表达式。查看re_format(7）关于正则表达式的详细信息。fgre较grep和egrep更快，但是只能处理固定模式（比如，它不能解析正则表达式）。匹配模式可以由一行或者多行组成，以便于匹配输入内容的一部分。<br/>
zgrep，zegrep，zfgrep分别与grep，egrep，fgrep功能类似，只是可以接收由compress或者gzip压缩工具压缩过的文件作为输入。</p>

<!-- more -->


<h2>参数</h2>

<pre><code>-A num, --after-context=num
</code></pre>

<p>打印匹配行后面的num行文本，与-B和-C选项功能类似</p>

<pre><code>-a, --text
</code></pre>

<p>将所有输入当作文本文件处理。如果文件包含二进制字符，grep简单打印<code>Binary file ... matches</code>。使用这个参数强制grep输出匹配行。</p>

<pre><code>-B num, --before-context=num
</code></pre>

<p>打印每个匹配行前面num行文本。</p>

<pre><code>-b, --byte-offset  
</code></pre>

<p>打印匹配模式在文件中的字节偏移数</p>

<pre><code>-C[num, --context=num]
</code></pre>

<p>指定打印匹配行前后文本行数。默认为2，相当于设置-A 2 -B 2</p>

<pre><code>-c, --count
</code></pre>

<p>只向标准输出打印匹配文本行的行数</p>

<pre><code>--colour=[when, --color=[when]]
</code></pre>

<p>打印时，用GREP_COLOR环境变量里面保存的颜色设置标记匹配到的模式</p>

<pre><code>-D action, --devices=action
</code></pre>

<p>为devices，FIFOS和sockets指定动作。默认动作是读，把他们当作普通文件处理。如果action指定为skip，这些设备将会被跳过。</p>

<pre><code>-d action, --directories=action
</code></pre>

<p>为目录指定特殊的动作。默认是读动作，把目录当作普通文件处理。<code>skip</code>动作是默默跳过目录，<code>recurse</code>动作是循环读取目录。</p>

<pre><code>-E, --extended-regexp
</code></pre>

<p>按照扩展正则表达式来解析pattern模式（强制grep表现为egrep）</p>

<pre><code>-e pattern, --regexp=pattern
</code></pre>

<p>指定匹配用的模式。可以多次使用-e选项来指定多个模式串</p>

<pre><code>--exclude
</code></pre>

<p>使用此选项将匹配参数模式的文件去除，不尽兴模式串的匹配。</p>

<pre><code>--exclude-dir
</code></pre>

<p>将某些目录去除，不进行模式匹配</p>

<pre><code>-F, --fixed-strings
</code></pre>

<p>将模式解析为固定字符串集合（强制grep为fgrep）</p>

<pre><code>-f file, --file=file
</code></pre>

<p>从file文件中读取匹配用的模式串</p>

<pre><code>-G, --basic-regexp
</code></pre>

<p>按照基本正则表达式解析模式串（强制grep工作模式为传统grep）</p>

<pre><code>-H
</code></pre>

<p>在匹配文本行前头打印所属文件名</p>

<pre><code>-h, --no-filename
</code></pre>

<p>在匹配文本行前头不打印文件名</p>

<pre><code>--help
</code></pre>

<p>打印简要帮助信息</p>

<pre><code>-I
</code></pre>

<p>忽略二进制文件</p>

<pre><code>-i, --ignore-case
</code></pre>

<p>进行大小无关匹配，grep默认是大小相关</p>

<pre><code>--include
</code></pre>

<p>指定符合文件名模式的文件进行模式匹配</p>

<pre><code>--include-dir
</code></pre>

<p>如果指定-R参数，只有符合模式的目录才进行模式匹配</p>

<pre><code>-J, --bz2decompress
</code></pre>

<p>进行文本匹配之前，解压bzip压缩过的文件</p>

<pre><code>-L, --files-without-match
</code></pre>

<p>只打印不包含指定模式文本行文件的文件名</p>

<pre><code>-l, --files-with-matches
</code></pre>

<p>只打印包含指定模式文本行文件的文件名，不打印文本行</p>

<pre><code>--mmap
</code></pre>

<p>使用mmap代替read来读取输入，在某些环境下能够达到更高性能，也可能引起为定义行为</p>

<pre><code>-m num, --max-count=num
</code></pre>

<p>达到<code>num</code>处匹配后，停止继续读取输入</p>

<pre><code>-n, --line-number
</code></pre>

<p>输出结果时，每行前面打印匹配行在文件中的行数。</p>

<pre><code>--null
</code></pre>

<p>打印文件名时，后面跟零字节</p>

<pre><code>-O
</code></pre>

<p>8888</p>

<pre><code>-o, --only-matching
</code></pre>

<p>只打印每行中匹配的部分</p>

<pre><code>-p
</code></pre>

<p>如果指定<code>-R</code>选项，不跟随符号链接，这个是默认选项</p>

<pre><code>-q, --quiet, --silent
</code></pre>

<p>安静模式：压制正常输出。grep程序只是搜索文件，直到达到一个匹配，使grep命令更少的花销。</p>

<pre><code>-R, -r, --recursive
</code></pre>

<p>循环搜索子文件夹</p>

<pre><code>-S
</code></pre>

<p>如果指定<code>-R</code>参数，所有符号连接也会参与匹配，默认不匹配符号连接</p>

<pre><code>-s, --no-messages
</code></pre>

<p>安静模式。不存在或者不可达的文件将被忽略</p>

<pre><code>-U, --binary
</code></pre>

<p>搜索二进制文件，但是不尝试打印他们</p>

<pre><code>-V, --version
</code></pre>

<p>打印版本信息</p>

<pre><code>-v, --invert-match
</code></pre>

<p>搜索不匹配给定模式的行文本</p>

<pre><code>-w, --word-regexp
</code></pre>

<p>表达式被当做是一个单词来进行匹配（形如被<code>[[:&lt;:]]</code>和<code>[[:&gt;:]]</code>包裹）</p>

<pre><code>-x, --line-regexp
</code></pre>

<p>只有一整行匹配给定模式才算成功匹配行</p>

<pre><code>-Z, -z, --decompress
</code></pre>

<p>强制grep像zgrep</p>

<pre><code>--binary-files=value
</code></pre>

<p>控制搜索和打印二进制文件。选项<code>binary</code>，默认选项，搜索但是不打印；<code>without-match</code>:不搜索二进制文件；<code>text</code>：将二进制文件视为文本文件</p>

<pre><code>--context[=num]
</code></pre>

<p>打印匹配行前后文本，默认是2行</p>

<pre><code>--line-buffered
</code></pre>

<p>强制输出行缓存。</p>

<h2>例子</h2>

<p>搜索一个文件中的单词</p>

<pre><code>grep 'patricia' myfile
</code></pre>

<p>所有行首包含<code>.Pp</code>的行</p>

<pre><code>grep '^\.Pp' myfile
</code></pre>

<p>搜索不包含<code>foo</code>和<code>bar</code>的所有行</p>

<pre><code>grep -v -e 'foo' -e 'bar' myfile
</code></pre>

<p>扩展正则表达式</p>

<pre><code>egrep '19|20|25' calendar
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MapReduce WordCount实例]]></title>
    <link href="http://jintao-zero.github.io/blog/2016/03/06/mapreduce-wordcountshi-li/"/>
    <updated>2016-03-06T15:08:34+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2016/03/06/mapreduce-wordcountshi-li</id>
    <content type="html"><![CDATA[<p>搭建开发环境，开发mapreduce job程序，部署mapreduce程序。</p>

<h1>开发环境搭建</h1>

<p>开发mapreduce程序的环境有可能与运行环境不同，我是Windows环境上开发mapreduce job程序，编译没有错误后，打包放到hadoop集群中调试和运行。这样就要求开发环境依赖的jar包，在hadoop集群环境中存在并且版本一致。<br/>
我的开发环境是Windows＋eclipse＋maven，hadoop集群环境上部署的版本号为：</p>

<pre><code>jintao@node0:~/Project$ hadoop  version
Hadoop 2.7.1
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a
Compiled by jenkins on 2015-06-29T06:04Z
Compiled with protoc 2.5.0
From source with checksum fc0a1a23fc1868e4d5ee7fa2b28a58a
This command was run using /usr/local/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar
</code></pre>

<p>maven配置文件pom.xml的配置如下：</p>

<pre><code>&lt;dependencies&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
    &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
    &lt;version&gt;2.7.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>

<p>maven工程会自动将依赖的jar下载到build path中。<br/>
你也可以建立一个普通java工程，手动将依赖的jar添加到build path中，这样需要找依赖的jar，比较麻烦，但是可以让新手更快的了解mapreduce相关类分布情况。</p>

<!-- more -->


<h1>开发mapreduce job程序</h1>

<p>一般情况下，一个job包含一个map类和一个reduce类，但是也可以只有一个类，或者都不包含。本文例子中的WordCount是mapreduce程序开发的helloworld程序，包含map和reduce类，通过WordCount我们可以了解mapreduce程序开发的基本框架。</p>

<h2>Mapper</h2>

<p>map程序的基类为：</p>

<pre><code>@InterfaceAudience.Public
@InterfaceStability.Stable
public class Mapper&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; extends Object
</code></pre>

<p>Maps将输入的key/value对处理并输出一个key/value形式的中间结果集。</p>

<p>Maps是一个个独立的任务线程分别处理不同的记录集合，输出中间结果集。输出结果集的类型不一定与初始的输入记录相同。一个输入key/value对，有可能输出零个或多个key/value结果对。</p>

<p>Hadoop Map-Reduce框架对于job的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html">InputFormat</a>输入数据产生的每个<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputSplit.html">InputSplit</a>派生一个map任务。Mapper的具体实现可以通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/JobContext.html#getConfiguration(">JobContext.getConfiguration()</a>)获取job的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">Configuration配置</a>。</p>

<p>框架首先调用Mapper实现类的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#setup(org.apache.hadoop.mapreduce.Mapper.Context">setup(org.apache.hadoop.mapreduce.Mapper.Context)</a>)，然后对于对于获取的每一个输入记录，调用map方法进行处理。最后调用<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#cleanup(org.apache.hadoop.mapreduce.Mapper.Context">cleanup(org.apache.hadoop.mapreduce.Mapper.Context)</a>)。</p>

<p>框架将与某个key相关的所有value值形成一组，传给Reducer来产生最后结果。通过指定key比较类，用户可以控制key/value的排序和分组。</p>

<p>Mapper的输出结果对于每个Reducer进行分片。通过实现一个特定的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Partitioner.html">Partitioner</a>，用户可以控制keys分片到Reducer。</p>

<p>视情况，通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Job.html#setCombinerClass(java.lang.Class">Job.setCombinerClass(Class)</a>)用户可以指定一个combiner，combiner可以在Mapper本地对输出结果进行聚合，这样可以减少从Mapper传输到Reducer的数据量。</p>

<p>通过对Configuration程序可以指定是否并且如何对Mapper结果进行压缩。</p>

<p>如果reducer个数为0，那么不会对Mapper的结果不对结果进行排序，并且直接输出到<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/OutputFormat.html">OutputFormat</a>。<br/>
WordCount对应Mapper实现类如下：</p>

<pre><code>public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
    private static Logger logger = Logger.getLogger(WordCountMapper.class);

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException{
        StringTokenizer iTokenizer = new StringTokenizer(value.toString());
        while (iTokenizer.hasMoreTokens()) {
            word.set(iTokenizer.nextToken());
            context.write(word, one);
        }
    }   
}
</code></pre>

<p>应用也可以重写<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html#run(org.apache.hadoop.mapreduce.Mapper.Context"> run(org.apache.hadoop.mapreduce.Mapper.Context)</a>)来更多的控制map处理，比如multi-threaded Mapper。</p>

<h2>Reducer</h2>

<p>Reducer的基类定义如下：</p>

<pre><code>@Checkpointable
@InterfaceAudience.Public
@InterfaceStability.Stable
public class Reducer&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt; extends Object
</code></pre>

<p>Reducer将Mapper输出的中间结果集处理输出最终结果集。<br/>
Reducer实现类可以通过<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/JobContext.html#getConfiguration("> JobContext.getConfiguration()</a>)获取job的配置信息<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">Configuration</a>。<br/>
Reducer主要有三个步骤：</p>

<ol>
<li><p>Shuffle<br/>
 Reducer使用Http从个Mapper拷贝传输中间结果集到本地。</p></li>
<li><p>Sort<br/>
 框架将从不同Mapper传输过来的结果集按照key进行合并排序。</p></li>
<li>Reduce
 在这一阶段，对于每个&lt;key, (collection of values)>调用<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html#reduce(KEYIN,%20java.lang.Iterable,%20org.apache.hadoop.mapreduce.Reducer.Context">reduce(Object, Iterable, org.apache.hadoop.mapreduce.Reducer.Context)</a>)方法进行处理。<br/>
 reduce任务调用<a href="TaskInputOutputContext.write(Object,%20Object">TaskInputOutputContext.write(Object, Object)</a>)将最终结果写到<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/RecordWriter.html">RecordWriter</a>。<br/>
 Reducer的输出不是有序的。</li>
</ol>


<p>WordCount的Reduce实现类为：</p>

<pre><code>public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
            Context context) throws IOException, InterruptedException {
        int total = 0;
        for (IntWritable count : values) {
            total += count.get();
        }
        result.set(total);
        context.write(key, result);
    }
}
</code></pre>

<h2>Driver</h2>

<p>已经完成mapper和reducer的编写。接下来写一个job driver用来提交程序到hadoop中运行。<br/>
可以有两种方式编写job driver：</p>

<ol>
<li>实现一个普通Java类，在类中设置job属性信息，提交job</li>
<li>实现<a href="http://hadoop.apache.org/docs/current/api/index.html">Tool</a>接口</li>
</ol>


<p>实际应用中，我们采用实现Tool接口的方式，这种方式能够更好的控制程序运行。<br/>
WordCount Job的属性设置如下：</p>

<pre><code>public class WordCountDriver extends Configured implements Tool {

    public int run(String[] arg0) throws Exception {
        // TODO Auto-generated method stub
        if (arg0.length != 2) {
            System.err.printf("Usage: %s [generic options] &lt;input&gt; &lt;output&gt;\n", 
                    getClass().getSimpleName());
            ToolRunner.printGenericCommandUsage(System.err);
            return -1;
        }

        //Create new job
        Job job = Job.getInstance();
        job.setJarByClass(getClass());

        job.setJobName("WordCount");

        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        job.setNumReduceTasks(1);

        FileInputFormat.addInputPath(job, new Path(arg0[0]));
        FileOutputFormat.setOutputPath(job, new Path(arg0[1]));

        return job.waitForCompletion(true) ? 0 : 1;
    }   

    public static void main(String[] args) {
        // TODO Auto-generated method stub
        try {
            int exitCode = ToolRunner.run(new WordCountDriver(), args);
            System.exit(exitCode);
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
    }

}   
</code></pre>

<p>WordCountDriver实现了Tool接口，这样我们运行程序时可以使用GenericOptionParser支持的参数项。<br/>
调用Job.getInstance()获取一个Job实例。设置Job名称。设置输入路径和输出路径。设置mapper和reducer类名。设置输出key和value类型（输入类型由数据源格式确定，数据源缺省为TextInputFormat文本格式，默认key类型为LongWritable，value类型为Text）。</p>

<h2>本地运行WordCount</h2>

<p>将程序打成jar包，放到hadoop集群一台机器上去。在jar包文件所在目录，新建一个input目录，input目录中放置一个文本文件words.txt，运行以下命令：</p>

<pre><code>$ hadoop jar hadoopjob.jar com.hugedata.jobs.WordCountDriver -fs file:/// -jt local input/ output/
</code></pre>

<p>-fs file:///指定使用本地文件系统，-jt local 指定mapreduce任务运行在本地。<br/>
当前目录会产生一个output目录，里面有两个文件（part-r-00000、_SUCCESS），其中part-r-00000即为</p>

<pre><code>jintao@node0:~/Project$ cat output/part-r-00000
is  2
jintao  1
jintao. 1
mx  1
my  2
mz  1
name    2
name.   1
too.    1
whit's  1
your    1
</code></pre>

<h2>集群运行WordCount</h2>

<p>前提是集群环境已经运行正常。将本地目录下的input拷贝到hdfs上：</p>

<pre><code>jintao@node0:~/Project$ hdfs dfs -put input
jintao@node0:~/Project$ hdfs dfs -ls
Found 2 items
drwxr-xr-x   - jintao supergroup          0 2016-03-07 16:51 input
drwxr-xr-x   - jintao supergroup          0 2016-03-05 14:04 tmp
</code></pre>

<p>屏幕上打印的过程信息如下：</p>

<pre><code>16/03/07 16:55:18 INFO client.RMProxy: Connecting to ResourceManager at node0/192.168.88.120:8032
16/03/07 16:55:20 INFO input.FileInputFormat: Total input paths to process : 1
16/03/07 16:55:20 INFO mapreduce.JobSubmitter: number of splits:1
16/03/07 16:55:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1457076326520_0001
16/03/07 16:55:21 INFO impl.YarnClientImpl: Submitted application application_1457076326520_0001
16/03/07 16:55:21 INFO mapreduce.Job: The url to track the job: http://node0:8088/proxy/application_1457076326520_0001/
16/03/07 16:55:21 INFO mapreduce.Job: Running job: job_1457076326520_0001
16/03/07 16:55:32 INFO mapreduce.Job: Job job_1457076326520_0001 running in uber mode : false
16/03/07 16:55:32 INFO mapreduce.Job:  map 0% reduce 0%
16/03/07 16:55:43 INFO mapreduce.Job:  map 100% reduce 0%
16/03/07 16:55:51 INFO mapreduce.Job:  map 100% reduce 100%
16/03/07 16:55:52 INFO mapreduce.Job: Job job_1457076326520_0001 completed successfully
16/03/07 16:55:52 INFO mapreduce.Job: Counters: 49
File System Counters
    FILE: Number of bytes read=156
    FILE: Number of bytes written=230351
    FILE: Number of read operations=0
    FILE: Number of large read operations=0
    FILE: Number of write operations=0
    HDFS: Number of bytes read=177
    HDFS: Number of bytes written=77
    HDFS: Number of read operations=6
    HDFS: Number of large read operations=0
    HDFS: Number of write operations=2
Job Counters
    Launched map tasks=1
    Launched reduce tasks=1
    Data-local map tasks=1
    Total time spent by all maps in occupied slots (ms)=8022
    Total time spent by all reduces in occupied slots (ms)=4886
    Total time spent by all map tasks (ms)=8022
    Total time spent by all reduce tasks (ms)=4886
    Total vcore-seconds taken by all map tasks=8022
    Total vcore-seconds taken by all reduce tasks=4886
    Total megabyte-seconds taken by all map tasks=8214528
    Total megabyte-seconds taken by all reduce tasks=5003264
Map-Reduce Framework
    Map input records=3
    Map output records=14
    Map output bytes=122
    Map output materialized bytes=156
    Input split bytes=110
    Combine input records=0
    Combine output records=0
    Reduce input groups=11
    Reduce shuffle bytes=156
    Reduce input records=14
    Reduce output records=11
    Spilled Records=28
    Shuffled Maps =1
    Failed Shuffles=0
    Merged Map outputs=1
    GC time elapsed (ms)=243
    CPU time spent (ms)=2860
    Physical memory (bytes) snapshot=444420096
    Virtual memory (bytes) snapshot=3891036160
    Total committed heap usage (bytes)=348651520
Shuffle Errors
    BAD_ID=0
    CONNECTION=0
    IO_ERROR=0
    WRONG_LENGTH=0
    WRONG_MAP=0
    WRONG_REDUCE=0
File Input Format Counters
    Bytes Read=67
File Output Format Counters
    Bytes Written=77
jintao@node0:~/Project$ 
</code></pre>

<p>程序执行成功后，会产生一个output目录，执行一下命令，可以产看结果：</p>

<pre><code>jintao@node0:~/Project$ hdfs dfs -cat output/part-r-00000
is  2
jintao  1
jintao. 1
mx  1
my  2
mz  1
name    2
name.   1
too.    1
whit's  1
your    1
</code></pre>

<p>至此，讲述了最基本的mapreduce程序开发、运行过程，后续需要学习的有如果查看日志，如何调试优化程序等方面。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hdfs文件系统java Api介绍]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao/"/>
    <updated>2015-12-21T17:29:19+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao</id>
    <content type="html"><![CDATA[<h1>Hadoop Filesystems</h1>

<p>Hadoop对于文件系统有一个抽象设计，HDFS只是一个实现。客户端使用Java 抽象类org.apache.hadoop.fs.FileSystem来访问Hadoop中的文件系统，有多个具体实现类:</p>

<pre><code>FileSystem      URI scheme      Java implementaion  
Local           file            fs.LocalFileSystem  

HDFS            hdfs            hdfs.DistributedFileSystem

WebHDFS         webhdfs         hdfs.web.WebHdfsFileSystem

Secure
WebHDFs         swebhdfs        hdfs.web.SWebHdfsFileSystem

HAR             har             fs.HarFileSystem

View            viewfs          viewfs.ViewFileSystem

FTP             ftp             fs.ftp.FTPFileSystem

S3              s3a             fs.s3a.S3AFileSystem

Azure           wasb            fs.azure.NativeAzureFileSystem

Swift           swift           fs.swift.snative.SwiftNative
</code></pre>

<p>Hadoop提供多个接口访问文件系统，接口利用URI的scheme来创建对应的实例与文件系统进行通讯。hdfs命令可以用来操作Hadoop各种文件系统，比如列出本地文件系统根目录内容：</p>

<pre><code>[root@yun1 ~]# hdfs dfs -ls file:///
Found 25 items
-rw-r--r--   1 root root          0 2015-10-19 11:06 file:///.autofsck
-rw-r--r--   1 root root          0 2014-07-04 14:16 file:///.autorelabel
dr-xr-xr-x   - root root       4096 2014-07-04 14:36 file:///bin
dr-xr-xr-x   - root root       1024 2014-09-17 15:54 file:///boot
drwxr-xr-x   - root root       4096 2014-07-04 09:17 file:///data
-rw-r--r--   1 root root       1001 2014-07-29 16:28 file:///dataplatform.log
drwxr-xr-x   - root root       3580 2015-10-19 11:08 file:///dev
</code></pre>

<h1>Java Interface</h1>

<!-- more -->


<p>访问HDFS文件系统需要先获取一个文件系统实例，FileSystem是一个文件系统统一访问接口。通过以下接口可以获取访问hdfs文件系统的实例：</p>

<pre><code>public static FileSystem get(Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf, String user) throws IOException
</code></pre>

<p>Configuration对象封装客户端或者服务端的配置信息，这些信息由classpath目录下配置文件初始化，比如etc/hadoop/core-site.xml。第一个接口根据conf中的信息，返回文件系统。第二个接口使用URI的scheme和授权来觉得使用哪个文件系统，如果没有设置scheme，则使用conf中配置的文件系统。第三个接口是以user用户的身份获取文件系统。 使用FileSystem实例，调用open方法可以获取一个输入文件流：</p>

<pre><code>public FSDataInputStream open(Path f) throws IOException
public abstract FSDataInputStream open(Path f, int bufferSize) throws IOException 
</code></pre>

<p>下面的代码实例用于读取hdfs文件输出到标准输出：</p>

<pre><code>public class FileSystemCat {

    public static void main(String[] args) throws Exception {
        String uri = args[0];
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(uri), conf);
        InputStream in = null;
        try {
            in = fs.open(new Path(uri));
            IOUtils.copyBytes(in, System.out, 4096, false);
        } finally {
            IOUtils.closeStream(in);
        }
    }
}
</code></pre>

<p>编译文件后，使用hadoop命令运行class文件：</p>

<pre><code># hadoop FileSystemCat hdfs://localhost/user/tom/quangle.txt
On the top of the Crumpetty Tree
The Quangle Wangle sat, 
But his face you could not see,
On account of his Beaver Hat.
</code></pre>

<h2>Writing Data</h2>

<p>FileSystem提供多个接口来创建文件，最简单的是输入一个路径作为参数，返回一个输出流：</p>

<pre><code>public FSDataOutputStream create(Path f) throws IOException 存在多个重载接口，允许指定是否重写已存在文件，文件的副本个数，写文件的缓冲区大小，文件的块大小和文件权限等等。存在append接口对已存在文件进行追加：
public FSDataOutputStream append(Path f) throws IOException
</code></pre>

<p>下面的代码实例是拷贝一个本地文件到Hadoop文件系统中：</p>

<pre><code>public class FileCopyWithProgress {
    public static void main(String []args) throws Exception {
        String localSrc = args[0];
        String dst = args[1];

        InputStream in = new BufferedInputStream(new FileInputStream(localSrc));

        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(dst), conf);
        OutputStream out = fs.create(new Path(dst), new Progressable() {
            public void progress() {
                System.out.print(".");
            }
        });

        IOUtils.copyBytes(in, out, 4096, true);
    }
}
</code></pre>

<p>运行程序结果如下：
    #hadoop FileCopyWithProgress input/docs/1400-8.txt hdfs://localhost/user/tom/1400-8.txt</p>

<p>创建目录使用下面的接口：</p>

<pre><code>public boolean mkdirs(Path f) throws IOException
</code></pre>

<h2>Quering the FileSystem</h2>

<p>FilsSystem提供了接口来获取文件或者文件夹信息，信息包括文件长度，块大小，复制，修改时间，所有权，访问权限属性。</p>

<pre><code>abstract FileStatus getFileStatus(Path f)
</code></pre>

<p>FileSystem提供了接口来列出一个目录中包含的内容：</p>

<pre><code>abstract FileStatus[]   listStatus(Path f)
FileStatus[]    listStatus(Path[] files)
FileStatus[]    listStatus(Path[] files, PathFilter filter)
FileStatus[]    listStatus(Path f, PathFilter filter)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hiredis C语言Redis客户端库使用]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/11/22/hiredis-cyu-yan-rediske-hu-duan-ku-shi-yong/"/>
    <updated>2015-11-22T11:21:43+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/11/22/hiredis-cyu-yan-rediske-hu-duan-ku-shi-yong</id>
    <content type="html"><![CDATA[<p>Redis是一款依据BSD开源协议发型的高性能Key-Value存储系统(cache and store)。它通常称为数据结构服务器，因为值(value)可以是字符串(String)，哈希(Hase)，列表(List)，集合(Set)和有序集合(sorted sets)等类型。</p>

<p>本文对RedisC语言客户端库<a href="https://github.com/redis/hiredis#using-replies">hireis</a>的安装、使用进行简单介绍。</p>

<h2>Redis安装</h2>

<p>参考<a href="http://redis.io/download">Redis</a>官网中的安装指导进行安装：<br/>
1、下载、解压和编译安装</p>

<pre><code>$ wget http://download.redis.io/releases/redis-3.0.5.tar.gz
$ tar xzf redis-3.0.5.tar.gz
$ cd redis-3.0.5
$ make
</code></pre>

<p>2、运行服务端
    编译声称的二进制文件在redis目录下的src子目录中，如下运行：</p>

<pre><code>$ src/redis-server
</code></pre>

<p>3、使用命令行工具与redis-server进行交互：</p>

<pre><code>$ src/redis-cli
redis&gt; set foo bar
OK
redis&gt; get foo
"bar"
</code></pre>

<p>详细的redis使用文档请参考<a href="http://redis.io/documentation">官网</a></p>

<!-- more -->


<h2>hiredis安装</h2>

<p>上面下载的Redis源代码目录的deps/hiredis目录中包含了hiredis的源代码，也可以从hiredis在github的网址下载：</p>

<pre><code>$ git clonet https://github.com/redis/hiredis.git
$ make
$ make install
</code></pre>

<p>以上命令会将相关.h头文件拷贝到/usr/local/include/hiredis/目录，<br/>
同时将hiredis相关库文件拷贝到/usr/local/lib/目录。</p>

<pre><code>-rw-rw-r--  1 jintao jintao 431534 11月  9 21:28 libhiredis.a
lrwxrwxrwx  1 root   root       15 11月  9 21:50 libhiredis.so -&gt; libhiredis.so.0*
lrwxrwxrwx  1 root   root       18 11月  9 21:50 libhiredis.so.0 -&gt; libhiredis.so.0.11*
-rwxrwxr-x  1 jintao jintao 219340 11月  9 21:50 libhiredis.so.0.11*
</code></pre>

<h2>hiredis接口</h2>

<p>hiredis库接口分为同步和异步两种接口，本文主要使用的是同步接口，主要涉及一下几个:</p>

<pre><code>redisContext *redisConnect(const char *ip, int port);
void *redisCommand(redisContext *c, const char *format, ...);
void freeReplyObject(void *reply);
</code></pre>

<h3>建立连接</h3>

<pre><code>redisContext *redisConnect(const char *ip, int port);
</code></pre>

<p>redisConnect函数用来创建一个到redis服务器的连接，并返回一个redisContext类型的指针。redisContext对象用来维护连接的状态。<br/>
redisContext对象中err字段非0表示连接处于异常状态。 <br/>
redisContext对象errstr字段包含错误信息描述字符串。<br/>
使用redisConnect接口连接Redis服务器后，需要判断是否连接成功：</p>

<pre><code>redisContext *c = redisConnect("127.0.0.1", 6379);
if (c != NULL &amp;&amp; c-&gt;err) {
    printf("Error: %s\n", c-&gt;errstr);
    // handle error
}
</code></pre>

<h3>发送命令</h3>

<p>有多个方法发送命令到Redis。现在介绍redisCommand函数，redisCommand函数类似printf。最简单的形式如下：</p>

<pre><code>reply = redisCommand(context, "SET foo bar");
</code></pre>

<p>%s标识符用来将字符串格式到命令中。</p>

<pre><code>reply = redisCommand(context, "SET foo %s", value);
</code></pre>

<p>%b标识符可以用来将二进制数据格式化到命令中，valuelen为数据长度。</p>

<pre><code>reply = redisCommand(context, "SET foo %b", value, (size_t) valuelen);
</code></pre>

<h3>处理命令结果</h3>

<p><code>redisCommand</code>执行成功后，返回一个<code>redisReply</code>对象保存执行结果。<br/>
当命令执行异常，redisCommand返回<code>NULL</code>,设置<code>context</code>对象<code>err</code>字段记录错误原因。<br/>
当执行命令异常，<code>context</code>失效，必须重新建立到redis服务器的连接。<br/>
<code>redisReply</code>对象中的<code>type</code>字段标识返回类型：</p>

<ul>
<li><p>REDIS_REPLY_STRING:<br/>
命令返回值类型为字符串。reply->str代表返回的字符串值。</p></li>
<li><p>REDIS_REPLY_STATUS:<br/>
  命令返回一个状态。通过reply->str获取状态字符串。状态字符串的长度为reply->len。</p></li>
<li><p>REDIS_REPLY_ERROR:
  命令执行失败，返回一个错误。错误原因字符串通过reply->str获取。</p></li>
<li><p>REDIS_REPLY_INTEGER:<br/>
  命令返回一个整型。整型的值可以通过reply->integer字段获取，整型类型为long long。</p></li>
<li><p>REDIS_REPLY_NIL:<br/>
  命令返回一个nil对象。没有数据可以获取。</p></li>
<li><p>REDIS_REPLY_ARRAY:  <br/>
  返回值为一个数组。reply->elements中保存对象个数。每个对象都是一个<code>redisReply</code>对象。通过reply->element[..index..]获取这些对象。</p></li>
</ul>


<p><code>redisReply</code>对象需要使用<code>freeReplyObject()</code>进行释放，返回对象中的子对象无需使用<code>freeReplyObject()</code>进行释放。</p>

<h3>管道批量发送命令</h3>

<p>当redisCommand命令被调用时，Hiredis首先根据Redis协议格式化命令。格式化后的命令被放到context维护的输出缓冲区中。输出缓冲区是动态的，可以容纳很多命令。命令被放置到输出缓冲区以后，调用redisGetReply获取返回值。redisGetReply有如下两条执行路径：</p>

<pre><code>1. 输入缓冲区非空：  
    从输入缓冲区中解析一个reply应答并返回。
    如果不能解析出一个reply，则走到第二条路径  

2. 输入缓冲区为空：
    将输出缓冲区写到socket。
    读取socket并解析出一个reply。
</code></pre>

<p>使用管道批量发送命令，就是使用如下命令填充输出缓冲区：</p>

<pre><code>void redisAppendCommand(redisContext *c, const char *format, ...);
void redisAppendCommandArgv(redisContext *c, int argc, const char **argv, const size_t *argvlen);
</code></pre>

<p>调用数次上面函数发送命令后，调用<code>redisGetReply</code>获取随后的返回值。<br/>
下面例子是一个简单的使用管道发送命令的例子（只有一次调用write（2）和一次调用read（2））：</p>

<pre><code>redisReply *reply;
redisAppendCommand(context,"SET foo bar");
redisAppendCommand(context,"GET foo");
redisGetReply(context,&amp;reply); // reply for SET
freeReplyObject(reply);
redisGetReply(context,&amp;reply); // reply for GET
freeReplyObject(reply);  
</code></pre>

<h3>示例：</h3>

<pre><code>#include &lt;hiredis/hiredis.h&gt;

int main()
{
    // create a connection
    redisContext *context = redisConnect("127.0.0.1", 6379);
    if ( context != NULL &amp;&amp; context-&gt;err) {
        printf("connect to redis fail.%s\n", context-&gt;errstr);
        return -1;
    }

    redisReply *reply = redisCommand(context, "select 0");
    if (NULL != reply) {
        if (REDIS_REPLY_STATUS == reply-&gt;type &amp;&amp; strcmp(reply-&gt;str,"OK") == 0) {
            printf("command:select 0 suc.type: %d, str:%s\n", REDIS_REPLY_STATUS, "OK");
        } 
        else {
            printf("command:select 0 fail.type: %d, str:%s\n", reply-&gt;type, reply-&gt;str);
            freeReplyObject(reply);
            redisFree(context);
            return -1;
        }
    } else {
        printf("command:select 0 fail.\n");
        redisFree(context);
        return -1;
    }
    freeReplyObject(reply);

    char *c1 = "set key1 eeee";
    reply = redisCommand(context, c1);
    if (NULL != reply) {
        if (reply-&gt;type == REDIS_REPLY_ERROR) {
            printf("command:%s excute fail: type: %d, str:%s\n", c1, reply-&gt;type, reply-&gt;str);
        }
        printf("command:%s excute ret: type: %d, str:%s\n", c1, reply-&gt;type, reply-&gt;str);
    } else {
        printf("command:%s fail\n", c1);
        redisFree(context);
        return -1;
    }
    freeReplyObject(reply);

    char *c2 = "set key2 222";
    char *c3 = "get list_key1";
    redisAppendCommand(context, c2);
    redisAppendCommand(context, c3);

    char *get_cmd = "get key1";
    reply = redisCommand(context, get_cmd);
    if (reply != NULL) {
        if (reply-&gt;type == REDIS_REPLY_ERROR) {
            printf("%s fail.type:%d value:%s\n", get_cmd, reply-&gt;type, reply-&gt;str);
        } else if (reply-&gt;type == REDIS_REPLY_STRING) {
            printf("%s suc.type:%d value:%s\n", get_cmd, reply-&gt;type, reply-&gt;str);
        }
        freeReplyObject(reply);
    } else {
        printf("%s execute fail.\n", get_cmd);
        redisFree(context);
        return -1;
    }

// list
// hash
char *hgetall = "hgetall hash_key1";
reply = redisCommand(context, hgetall);
if (reply != NULL) {
    if (reply-&gt;type == REDIS_REPLY_ERROR) {
        printf("%s ,type:%d result:%s\n", hgetall, REDIS_REPLY_ERROR, reply-&gt;str);
    } else if (reply-&gt;type == REDIS_REPLY_NIL) {
        printf("%s ,type:%d result:%s\n", hgetall, REDIS_REPLY_NIL, reply-&gt;str);
    } else if (reply-&gt;type == REDIS_REPLY_ARRAY) {
        printf("%s ,type:%d elements:%lu \n", hgetall, REDIS_REPLY_ARRAY, reply-&gt;elements);
        int i;
        for (i = 0; i &lt; reply-&gt;elements; i++) {
            redisReply *tmp = reply-&gt;element[i];
            if (tmp-&gt;type == REDIS_REPLY_INTEGER){
                printf("elements[%d],type:%d result:%lld\n", i, REDIS_REPLY_INTEGER, tmp-&gt;integer);
            } else if (tmp-&gt;type == REDIS_REPLY_STRING) {
                printf("elements[%d] ,type:%d result:%s\n", i, REDIS_REPLY_STRING, tmp-&gt;str);
            }
            printf("index:%d ,type:%d \n", i, tmp-&gt;type);
        }
    }
    freeReplyObject(reply);
} else {
    printf("%s fail\n", hgetall);
}
redisFree(context);
return 0;
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crontab任务设置及路径、动态库、产生多个进程问题解决]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/11/21/crontabren-wu-she-zhi-ji-lu-jing-,-dong-tai-ku-,-chan-sheng-duo-ge-jin-cheng-wen-ti-jie-jue/"/>
    <updated>2015-11-21T11:17:04+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/11/21/crontabren-wu-she-zhi-ji-lu-jing-,-dong-tai-ku-,-chan-sheng-duo-ge-jin-cheng-wen-ti-jie-jue</id>
    <content type="html"><![CDATA[<p>crontab文件中包含了cron守护进程需要执行的指令：某个时间执行这条命令。每个用户拥有自己的crontab，crontab中的命令以crontab所属用户运行。</p>

<pre><code>crontab [ -u user ] file
crontab [ -u user ] [ -i ] { -e | -l | -r }
</code></pre>

<p>命令第一种形式是用file中的命令设置crontab任务<br/>
-l 参数是打印当前crontab任务到标准输出<br/>
-e 参数是使用VISUAL或者EDITOR环境变量定义的编辑器编辑当前crontab定时任务<br/>
-r 参数删除当前定时任务<br/>
-i 与用户进行交互</p>

<h2>任务设置</h2>

<p>crontab文件中可以包含三种语句：<br/>
1、注释
以#开头的语句都是注释</p>

<pre><code>#this is a comment in crontab 
</code></pre>

<p>2、设置环境变量</p>

<pre><code>LD_LIBRARY_PATH = /homt/lib/
</code></pre>

<p>3、设置定时任务<br/>
每一行定义一条定时任务，包括五个时间、日期字段，时间日期后面的内容都是命令<br/>
时间日期包括分、时、天、月和一周某天字段：</p>

<pre><code>ield          allowed values
-----          --------------
minute         0-59
hour           0-23
day of month   1-31
month          1-12 (or names, see below)
day of week    0-7 (0 or 7 is Sun, or use names)
</code></pre>

<p>字段可以是＊，代表范围内所有<br/>
字段也可以是一个范围，比如hour字段8-10，代表8，9，10<br/>
字段也可以是一个列表，比如hour字段8，9，10<br/>
字段也可以是一个范围和列表的混合，比如hour字段1-7，9－12<br/>
字段也可以为一个间隔，比如hour 1-8/2,代表1,3,5,7</p>

<!-- more -->


<h2>路径问题</h2>

<p>crontab任务是根据所属用户从/etc/passwd文件中获取bashshell工具类型、logname和当前路径的。<br/>
代码中如果使用的是相对路径，那么在会导致程序找不到文件，可以在程序入口处利用chdir类似功能函数修改程序的当前工作路径：</p>

<pre><code>int chdir(const char *path);
</code></pre>

<h2>动态库问题</h2>

<p>如果程序使用了动态库，而动态库放置的位置没有在等标准路径下的话，程序会因为加载不到动态库而执行失败，可能报如下的错误：</p>

<pre><code>/root/server/demo_linux/server: error while loading shared libraries: libTDFAPI30.so: cannot open shared object file: No such file or directory
</code></pre>

<p>解决办法有两个：<br/>
1、链接程序时指定绝对路径：</p>

<pre><code>-Wl,-rpath=/root/server/lib
</code></pre>

<p>2、在crontab中设置LD_LIBRARY_PATH环境变量</p>

<pre><code>LD_LIBRARY_PATH=/root/server/lib
</code></pre>

<h2>创建两个相关进程</h2>

<pre><code>root     19400  0.0  0.0 113116  1208 ?        Ss   18:10   0:00 /bin/sh -c /root/test/cron 1&gt; stdout 2&gt; stderr
root     19402  0.0  0.0  12620  1072 ?        S    18:10   0:00 /root/test/cron
</code></pre>

<p>看到两个进程是因为crontab使用/bin/sh来启动定时任务程序:</p>

<pre><code>[root@iZ235ne7v0iZ demo_linux]# ps -o ppid -p 19402
PPID
19400
</code></pre>

<p>可以将crontab任务修改为下列情况：</p>

<pre><code>10 18  * * * exec /root/test/cron 1&gt; stdout 2&gt; stderr
</code></pre>

<p>或者</p>

<pre><code>10 18  * * * bash -c '/root/test/cron 1&gt; stdout 2&gt; stderr'
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop环境搭建]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/09/19/hadoophuan-jing-da-jian/"/>
    <updated>2015-09-19T15:41:51+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/09/19/hadoophuan-jing-da-jian</id>
    <content type="html"><![CDATA[<p>最近开始进行Hadoop分布式计算相关内容的学习，先从搭建开发环境开始。下面记录一下搭建Hadoop开发环境的过程，以及注意点。
本节介绍如何快速搭建和配置一个单节点Hadoop环境，便于使用Hadoop MapReduce和Hadoop Distributed File System(HDFS)。</p>

<h2>依赖条件</h2>

<p>支持的操作系统平台  <br/>
GNU/Linux支持作为Hadoop的开发和生产环境，Hadoop已经证明可以在GNU/Linux集群上运行2000节点。本文使用Ubuntu操作系统做为实验环境。</p>

<pre><code>Linux node8 3.16.0-30-generic #40~14.04.1-Ubuntu SMP Thu Jan 15 17:43:14 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
</code></pre>

<p>Windows系统也可以搭建Hadoop集群，本文暂时没有涉及，可以参考<a href="http://wiki.apache.org/hadoop/Hadoop2OnWindows">wiki page</a></p>

<p>依赖的软件</p>

<ul>
<li><p>Java环境<br/>
  安装方法：</p>

<p>  1、到oracle官网下载<a href="http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.tar.gz">JDK二进制压缩包</a><br/>
  2、将压缩包解压到/usr/local/lib/目录下，安装目录也可以换到其他路径  <br/>
      sudo tar xzvf jdk-8u45-linux-x64.tar.gz -C /usr/local/lib/<br/>
  3、修改/etc/profile文件配置JAVA_HOME、PATH、CLASSPATH环境变量<br/>
      JAVA_HOME=/usr/local/lib/jdk1.8.0_45<br/>
      PATH=$JAVA_HOME/bin:$PATH<br/>
      CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar <br/>
  4、运行java -version查看是否显示java版本信息</p></li>
<li><p>ssh远程控制软件<br/>
  如果系统没有运行sshd服务，则Ubuntu下运行apt-get命令安装ssh服务端
  sudo apt-get install openssh-server</p></li>
</ul>


<h2>下载Hadoop软件</h2>

<p>本文采用的是Hadoop最新的稳定版本<a href="http://apache.fayea.com/hadoop/common/current/hadoop-2.7.1.tar.gz">2.7.1</a></p>

<!-- more -->


<p></p>

<h2>准备运行集群</h2>

<p>1、将压缩包解压到一个安装目录下</p>

<pre><code>sudo tar xzvf hadoop-2.7.1.tar.gz -C /home/jintao/toolkit/
</code></pre>

<p>2、打开安装目录下etc/hadoop/hadoop-env.sh</p>

<pre><code>添加一句 export JAVA_HOME=/usr/local/lib/jdk1.8.0_45
</code></pre>

<p>3、运行bin/hadoop命令，查看hadoop命令使用帮助</p>

<h2>单机模式</h2>

<p>默认情况，Hadoop运行在非分布式模式，一个单独Java进程。这种模式调试时很有用。下面的例子，拷贝hadoop目录下面的etc/hadoop/*.xml作为输入，运行hadoop打印文件中匹配正则表达式的内容，输出到指定的output目录。</p>

<pre><code>$ mkdir input  
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
$ cat output/*
</code></pre>

<h2>伪分布式</h2>

<p>Hadoop可以在单个节点运行在伪分布式模式，每个Hadoop守护进程运行在不同的Java进程。</p>

<h3>配置</h3>

<p>编辑以下文件：
etc/hadoop/core-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>etc/hadoop/hdfs-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3>设置ssh无密码登录</h3>

<p>查看当前是否可以无密码登录：</p>

<pre><code>$ ssh localhost
</code></pre>

<p>如果不可以无密码登录，则执行一下命令：</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<h3>执行</h3>

<p>以下指令在本地运行一个MapReduce任务。<br/>
1、格式化hdfs文件系统</p>

<pre><code>$ bin/hdfs namenode -format
</code></pre>

<p>默认namenode存储路径：/tmp/hadoop-jintao/dfs/name</p>

<p>2、运行NameNode和DataNode守护进程：</p>

<pre><code>$ sbin/start-dfs.sh
</code></pre>

<p>hadoop守护进程日志输出到$HADOOP_LOG_DIR目录（默认在$HADOOP_HOME/logs安装目录的logs目录下）。使用jps查看java进行：</p>

<pre><code>jintao@node8:~/toolkit/hadoop-2.7.1$ jps
5248 DataNode
5473 SecondaryNameNode
5105 NameNode
13380 Jps
</code></pre>

<p>3、通过web接口查看NameNode信息；默认路径：</p>

<pre><code>http://localhost:50070/
</code></pre>

<p>4、创建执行MapReduce任务需要的HDFS路径：/user/&lt;username></p>

<pre><code>$ bin/hdfs dfs -mkdir /user 
$ bin/hdfs dfs -mkdir /user/jintao
</code></pre>

<p>5、将试验用的数据放到hdfs上input目录下：</p>

<pre><code>$ bin/hdfs dfs -put etc/hadoop input
</code></pre>

<p>6、运行hadoop自带的grep任务：</p>

<pre><code>$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>7、将结果文件从hdfs上获取到本地目录outpu中，并查看结果：</p>

<pre><code>$ bin/hdfs -get output output
$ cat output/*
</code></pre>

<p>或者直接查看hdfs上面的结果文件：</p>

<pre><code>$ bin/hdfs -cat output/*
</code></pre>

<p>8、关闭hadoop后台进程</p>

<pre><code>$ sbin/stop-dfs.sh
</code></pre>

<h3>伪分布式运行YARN</h3>

<p>设置一些参数，可以在伪分布式环境下运行YARN框架管理MapReduce任务，YARN框架会启动ResourceManager和NodeManager守护进程。<br/>
在上面1到4步完成的基础上，进行如下设置：<br/>
1、配置etc/hadoop/mapred-site.xml，如果不存在mapred-site.xml，则拷贝一份mapred-site.xml.template命名为mapred-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>配置etc/hadoop/yarn-site.xml：</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>2、启动ResourceManager和NodeManager后台进程：</p>

<pre><code>$ sbin/start-yarn.sh
$ jps
15858 NodeManager
15301 DataNode
15542 SecondaryNameNode
16119 Jps
15160 NameNode
15723 ResourceManager
</code></pre>

<p>3、浏览ResourceMnaager信息：</p>

<pre><code>http://localhost:8088/
</code></pre>

<p>4、运行一个MapReduce任务：</p>

<pre><code>$ bin/hdfs dfs -rm -r -f output
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>5、关闭yarn框架进程</p>

<pre><code>$ sbin/stop-yarn.sh
</code></pre>

<h2>集群环境</h2>

<p>搭建四台机器（node1、node2、node3、node4）的Hadoop集群环境：<br/>
1、node1部署NameNode和ResourceManager<br/>
2、node2、node3、node4作为slave节点部署DataNode和NodeManager</p>

<p>典型集群环境下，应该将单独一台机器运行NameNode，另外一台机器运行ResourceManager，这些是主控节点。其他服务（比如Web App Proxy Server和MapReduce Job History server）通常运行在一台指定机器或者共享设备上，依赖于系统负载。集群中其他机器都同时部署DataNode和NodeManager，这些都是slaves节点。</p>

<h3>准备工作</h3>

<p>1、每台机器都安装JAVA环境<br/>
   参考上面单机环境搭建，进行安装、配置环境变量</p>

<p>2、编辑hosts文件
    编辑每台机器的hosts文件，将hostname和ip的对应关系添加到/etc/hosts中</p>

<pre><code>192.168.88.120 node0
192.168.88.121 node1
192.168.88.122 node2
192.168.88.123 node3
</code></pre>

<p>在各台机器上通过主机名ping各台机器，查看是否能够ping通</p>

<p>3、配置ssh无密码登录
每台机上运行，生存密钥</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<p>ssh集群启动时，主控节点会通过ssh远程登录到slaves节点执行脚本启动slaves节点，因此我们需要配置主控节点到slaves节点的无密码登录：<br/>
将主控节点的pub密钥拷贝到各个slaves节点~/.ssh/目录下</p>

<pre><code>scp id_rsa.pub jintao@node1:~/.ssh/node0.pub
</code></pre>

<p>将node0.pub文件的内容追加到各个节点的authorized_keys文件中：</p>

<pre><code>cat node0.pub &gt;&gt; authorized_keys
</code></pre>

<p>从node0节点ssh到slaves节点上，查看是否不需要密码</p>

<p>4、创建hadoop工作目录</p>

<pre><code>mkdir /home/jintao/hadoop_dir
</code></pre>

<p>如果将hadoop工作目录配置在其他目录下，则需要使hadoop的运行账户对该目录具有读写权限</p>

<p>5、下载Hadoop安装程序<br/>
从官网下载安装程序，解压到~/toolkit/目录下，toolkit后面陆续会安装其他zookeeper、hbase等项目</p>

<h3>配置Hadoop</h3>

<p>管理员应该使用etc/haddop-env.sh和etc/hadoop/mapred-env.sh和etc/hadoop/yarn-env.sh三个相关脚本来配置Hadoop进程环境。</p>

<p>1、打开安装目录下etc/hadoop/hadoop-env.sh</p>

<pre><code>添加一句 export JAVA_HOME=/usr/local/lib/jdk1.8.0_45
</code></pre>

<p>2、vim core-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;fs.defaultFS&lt;/name&gt;
            &lt;value&gt;hdfs://node0:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
            &lt;value&gt;/home/jintao/hadoop_dir&lt;/value&gt;
            &lt;description&gt;A base for other temporary directories.&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>设置fs.defaultFS和hadoop.tmp.dir属性</p>

<p>3、vim hdfs-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>4、vim mapred-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>5、vim yarn-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;node0&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>6、vim slaves</p>

<pre><code>ode1
node2
node3
</code></pre>

<p>7、将配置好的hadoop程序同步到slaves节点上</p>

<pre><code>scp -r toolkit/ node1:~
scp -r toolkit/ node2:~
scp -r toolkit/ node3:~
</code></pre>

<p>8、启动namenode节点</p>

<pre><code>1、cd ~/toolkit/hadoop-2.7.1/
2、bin/hdfs namenode -format
3、sbin/start-all.sh
</code></pre>

<p>9、node0上查看jps</p>

<pre><code>9904 Jps
9426 SecondaryNameNode
9190 NameNode
9607 ResourceManager
</code></pre>

<p>10、node1、node2、node3上查看jps</p>

<pre><code>9507 Jps
9323 NodeManager
9213 DataNode
</code></pre>

<p>11、系统启动日志记录在hadoop-2.7.1/logs目录下</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[冒泡、选择、插入、归并、快速、堆排序]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/08/02/mou-pao-,-xuan-ze-,-cha-ru-,-gui-bing-,-kuai-su-,-dui-pai-xu/"/>
    <updated>2015-08-02T20:40:24+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/08/02/mou-pao-,-xuan-ze-,-cha-ru-,-gui-bing-,-kuai-su-,-dui-pai-xu</id>
    <content type="html"><![CDATA[<p>本篇文章对一些常用的排序算法进行简单介绍和实现，包括冒泡排序，选择排序，插入排序、归并排序、快速排序和堆排序。</p>

<h1>冒泡排序</h1>

<p><a href="http://baike.baidu.com/view/254413.htm#ref_[1]_254413">冒泡排序算法</a>（百度百科）的运作如下：（从后往前）<br/>
1. 比较相邻的元素。如果第一个比第二个大，就交换他们两个。<br/>
2. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。<br/>
3. 针对所有的元素重复以上的步骤，除了最后一个。<br/>
4. 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</p>

<p>代码实现</p>

<pre><code>void BubbleSort(int array[], int len)    
{  
    for (int i = 0; i &lt; len-1; i++) {
        for (int j = 0; j &lt; len-i-1; j++) {
            if (array[j+1] &lt; array[j]) {
                int tmp = array[j+1];
                array[j+1] = array[j];
                array[j] = tmp;
            }
        }
    }
}
</code></pre>

<!-- more -->


<h1>选择排序</h1>

<p><a href="http://baike.baidu.com/view/547263.htm">选择排序（Selection sort）</a>（百度百科）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或者最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。选择排序是不稳定的排序方法（比如序列[5, 5, 3]）第一次就将第一个[5]与[3]交换，导致第一个5挪到第二个5后面。<br/>
代码实现：</p>

<pre><code>void SelectSort(int array[], int len)
{
    for (int i = 0; i &lt; len-1; i++) {
        int maxindex = 0;
        int j;
        for (j = 0; j &lt; len-i; j++) {
            if (array[maxindex] &lt; array[j])
            maxindex = j;
        }
        if (maxindex != j-1) {
            int tmp = array[maxindex];
            array[maxindex] = array[j-1];
            array[j-1] = tmp;
        }
    }
}
</code></pre>

<h1>插入排序</h1>

<p><a href="http://baike.baidu.com/view/1443814.htm">插入排序</a>基本思想是，有一个已经有序的数据列表，要求在这个已经排好的数据序列中插入一个数，但要求插入后此数据序列依然有序，当最后一个元素放入合适位置时，该数组排序完毕。</p>

<p>代码实现：</p>

<pre><code>void InsertSort(int array[], int len)
{
    for (int i = 0; i &lt; len-1; i++) {
        int tmp = array[i+1];
        int j;
        for (j = i; j &gt;= 0; j--) {
            if (array[j] &gt; tmp)
                array[j+1] = array[j];
            else
            break;
        }
        array[j+1] = tmp;
    }
}
</code></pre>

<h1>归并排序</h1>

<p><a href="http://baike.baidu.com/link?url=ntO_kb7I3p3zA69jUzemm9fGlNCnRTYujLs3bOn8OSxJ_qQ8uWhIXYXEWAcuMnpLsBWkZ7cWVPG0z9OQGSBmklD2mMslu_ybumqBYdFvBkoRX0UIgDXg6rESkppoX4jX-1dwTRL-6_jlMQvghncKxUGEPA6MOVPjHsOEr3l8CiF0WLrbOgcaN_qOVrjxtbHBLUbEZ7AT_9PP8A6YhxTTmK">归并排序</a>是建立在归并操作上的一种有效的排序算法，该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。<br/>
归并过程为：比较a[i]和a[j]的大小，若a[i]&lt;=a[j]，则将第一个有序表中的元素a[i]复制到r[k]中，并令i和k分别加上1；否则将第二个有序表中的元素a[j]复制到r[k]中，并令j和k分别加上1，如此循环下去，直到其中规格有序表取完，然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元。归并排序的算法我们通常用递归实现，先把待排序区间[s,t]以中点二分，接着把左边子区间排序，再把右边子区间排序，最后把左区间和右区间用一次归并操作合并成有序的区间[s,t]。</p>

<p>代码实现：</p>

<pre><code>void MergeSort(int array[], int low, int high)
{   
    if (low &lt; high) {
        int mid = (low + high)/2;
        MergeSort(array, low, mid);
        MergeSort(array, mid+1, high);
        Merge(array, low, mid, high);
    }
}

void Merge(int array[], int low, int mid, int high)
{
    int tmp[high-low+1];
    int i = low;
    int j = mid+1;
    int k = 0;
    while((i &lt; mid+1) &amp;&amp; (j &lt; high+1)) {
        if (array[i] &lt; array[j]) {
            tmp[k++] = array[i++];
        } else {
            tmp[k++] = array[j++];
        }
    }
    if (i &lt; mid+1)
        memcpy(&amp;tmp[k], &amp;array[i], sizeof(int)*(mid+1-i));
    else
        memcpy(&amp;tmp[k], &amp;array[j], sizeof(int)*(high+1-j));
    memcpy(&amp;array[low], tmp, sizeof(int)*(high-low+1));
}
</code></pre>

<h1>快速排序</h1>

<p><a href="http://baike.baidu.com/link?url=HP5tLiQM-gSmzKFE8mLK2iTkDvv6CfSE02u7ZGHoVYBJpPbFQTG9kr7hTGNYzHR-gejxXqfsyE46qW9yq58itjMK0nw0wwxqINW25Cfr-bypjbWHg35SSk9Sw7XCG0gJRnQEMcQJw_cObpiQDh77Si7o0w_CKa9jYtjOiAua6s1D5xOpgDbPCanOmgJiK6mY">快速排序</a>（Quicksort）使对冒泡排序的一种改进。<br/>
快速排序由C.A.R.Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要笑，然后再按此方法对着两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p>

<p>算法介绍：
设要排序的数组是A[0]&hellip;.A[N-1]，首先任意选取一个数据（通常选用数组的第一个数）作为关键数据，然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，整个过程称为一趟快速排序。值得注意的是，快速排序不是一种稳定的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动。<br/>
一趟快速排序的算法是：<br/>
1）设置两个变量i、j，排序开始的时候：i=0，j＝N-1;<br/>
2）以第一个数组元素做为关键数据，赋值给key，即key＝A[0];<br/>
3) 从j开始向前搜索，即由后开始向前搜索(j&ndash;),找到第一个小于key的值A[j], 将A[j]和A[j]互换；<br/>
4）从i开始向后搜索，即由前开始向后搜索(i++),找到第一大于key的A[i],将A[i]和A[j]互换；<br/>
5)重复第3、4步，直到i＝j；(3,4步中，没有找到符合条件的值，即3种A[j]步小于key，4中A[i]不大于key的时候改变j、i的值，使得j＝j-1, i = i+1,直到找到为止。找到符合条件的值，进行交换的时候i，j指针位置不变。另外，i＝＝j这一过程一定正好是i+或j-完成的时候，此时令循环结束)。</p>

<p>代码实现：</p>

<pre><code>void QuickSort(int array[], int low ,int high)
{
    if (low &gt;= high)
    return;
    int pivot = FindPivot(array, low, high);
    QuickSort(array, low, pivot-1);
    QuickSort(array, pivot+1, high);
}

int FindPivot(int array[], int low, int high)
{
    int i = low;
    int j = high;
    int tmp = array[low];
    while(i &lt; j) {
        while((i &lt; j) &amp;&amp; (array[j] &gt;= tmp))
        j--;
        array[i] = array[j];
        while((i &lt; j) &amp;&amp; (array[i] &lt;= tmp))
        i++;
        array[j] = array[i];
    }
    array[i] = tmp;
    return i;
}   
</code></pre>

<h1>堆排序</h1>

<p><a href="http://baike.baidu.com/link?url=MQ3FCTrGuunRTE_A8KhSLxF5JZtTAlbsSv5Otj1uB0l6xb2NsFCML-8zsQp0iZ6KC2RS4vSj7bvHoSfpnzudXa">堆排序</a>是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位制定索引的元素。堆分为大根堆和小跟堆，是完全二叉树。大根堆的要求是每个节点的值都不大于其父节点的值，即A[PARENT[i]]&gt;=A[i]。在数组的非降序排序中，需要使用的就是大根堆，因为根据大根堆的要求可知，最大的值一定在堆顶。<br/>
算法介绍：<br/>
堆排序利用了大根堆（或小根堆）堆顶记录的关键字最大（或最小）这一特征，使得在当前无序区中选取最大（或最小）关键字的记录变得简单。
基本操作：<br/>
1）建堆，建堆是不断调整堆的过程，从len/2处开始调整，一直到第一个节点，此处len是堆中元素的个数。建堆的过程是线性的过程，从len/2到0处一直调用调整堆的过程，相当于o(h1)+o(h2)&hellip;+o(hlen/2)其中h表示节点的深度，len/2表示节点的个数，这是一个求和的过程，结果是线性的O(n)。<br/>
2）调整堆：调整堆在构建堆的过程中会用到，而且在堆排序过程中也会用到。利用的思想是比较节点i和它的孩子节点left(i),right(i),选出三者最大（或者最小）者，如果最大（小）值不是节点i而是它的一个孩子节点，那边交换节点i和该节点，然后再调用调整堆过程，这是一个递归的过程。调整堆的过程时间复杂度与堆的深度有关系，是lgn的操作，因为是沿着深度方向进行调整的。
3）堆排序：堆排序是利用上面的两个过程来进行的。首先是根据元素构建堆。然后将堆的根节点取出（一般是与最后一个节点进行交换），将前面len-1个节点继续继续堆调整的过程，然后再将根节点取出，这样一支到所有节点都取出。堆排序过程的时间复杂度时O(nlgn)。因为建堆的时间复杂度时O(n)(调整一次)；调整堆的时间复杂度时lgn，调整用了n-1次，所以堆排序的时间复杂度是O(nlgn)。
代码实现：</p>

<pre><code>void HeapAdjust(int array[], int begin, int high)
{
    int i = begin;
    while(i &lt;= high) {
        int max = i;
        int leftchild = 2*i + 1;
        int rightchild = 2*i +2;
        if (leftchild &lt;= high &amp;&amp; array[max] &lt; array[leftchild])
            max = leftchild;
        if (rightchild &lt;= high &amp;&amp; array[max] &lt; array[rightchild])
        max = rightchild;
        if (i != max) {
            int tmp = array[i];
            array[i] = array[max];
            array[max] = tmp;
            i = max;
        } else {
            break;
        }
    }
}

void InitHeap(int array[], int low, int high)
{
    for (int i = high/2; i &gt;= low; i--) {
        HeapAdjust(array, i, high);
    }
}

void HeapSort(int array[], int low, int high)
{
    InitHeap(array, low, high);
    for (int i = high; i &gt; low; i--) {
        int tmp = array[i];
        array[i] = array[low];
        array[low] = tmp;
        HeapAdjust(array, low, i-1);
    }
}   
</code></pre>

<p>测试代码：</p>

<pre><code>int main()
{
    int a[] = {100, 2,4,5,1,10, -1};
    //BubbleSort(a, sizeof(a)/sizeof(a[0]));
    size_t len = sizeof(a)/sizeof(a[0]);
    //InsertSort(a, len);
    // SelectSort(a, len);
    //MergeSort(a, 0, len-1);
    // QuickSort(a, 0, len-1);
    HeapSort(a, 0, len-1);
    for (int i = 0; i &lt; len;  i++)
    printf("%d: %d\n", i, a[i]);
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Libnetfilter_queue学习笔记]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/06/16/libnetfilter-queuexue-xi-bi-ji/"/>
    <updated>2015-06-16T18:53:42+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/06/16/libnetfilter-queuexue-xi-bi-ji</id>
    <content type="html"><![CDATA[<p>项目需要将某个进程发出的报文截获，待用户态业务处理后再将报文送回系统协议栈中处理。调研后，采用iptables添加防火墙规则截获报文传递到用户态队列，用户态进程使用libnetfilter_queue库接受报文，待业务处理后，将报文送回系统协议栈这样的方案完成。下面介绍下，学习的几个知识点：</p>

<h1>netfilter</h1>

<h2>简介</h2>

<p><a href="http://netfilter.org/">netfilter</a>是Linux 2.4.x开始以后内核版本中的报文过滤框架。netfilter框架的用户态工具是<a href="http://netfilter.org/projects/iptables/index.html">iptables</a>防火墙配置工具。<br/>
netfilter框架实现了报文过滤，网络地址转换，端口转换和其他报文管理。它是对Linux 2.2.x ipchains和Linux 2.0.x ipfwadm系统的重构和显著改进。<br/>
netfilter是位于Linux内核中的一组回调函数集合，各个模块可以在网络协议栈注册回调函数。每个报文到来时，将会遍历协议栈中的回调函数并调用。<br/>
iptables定义了规则集的通用格式。IP table中的每一条规则是有一些分类和相关的目标组成。<br/>
netfilter，ip_tables，connection tracking（ip_conntrack，nf_conntrack）和NAT子系统是netfilter的主要组成部分。</p>

<h2>主要特性</h2>

<ul>
<li>无状态报文过滤</li>
<li>有状态报文过滤</li>
<li>所有网络地址和端口转换，比如NAT/NAPT(IPv4和IPv6)</li>
<li>灵活的、可扩展的框架</li>
<li>为第三方扩展提供API访问网络各层</li>
</ul>


<h2>可以做哪些</h2>

<ul>
<li>基于无状态或者有状态报文过滤构建互联网防火墙</li>
<li>托管高可用有状态或者无状态的防火墙集群</li>
<li>使用NAT和ip伪装共享共网ip</li>
<li>使用NAT实现传输代理</li>
<li>与tc和iproute2系统一起构建复杂Qos和策略路由器</li>
<li>更进一步进行报文管理，比如修改IP头中的TOS/DSCP/ECN</li>
</ul>


<!-- more -->


<h1>libnetfilter_queue</h1>

<p>libnetfilter_queue是一个用户态库，它提供了接口用来访问已经被内核报文过滤模块放置在队列中的报文。libnetfilter_queue的前身是libnfnetlink_queue。<br/>
libnetfilter_queue需要libnfnetlink和包含nfnetlink_queue子系统的内核（2.6.14以后）。<br/>
主要特性：</p>

<ul>
<li>接收来自内核nfnetlink_queue子系统的报文</li>
<li>做出裁决，是否将修改后的报文重新注入内核nfnetlink_queue子系统</li>
</ul>


<h2>安装</h2>

<p>libnetfilter_queue需要libnfnetlink和libmnl库<br/>
1、安装libnfnetlink</p>

<pre><code>#wget http://netfilter.org/projects/libnfnetlink/files/libnfnetlink-1.0.1.tar.bz2
#tar jxvf libnfnetlink-1.0.1.tar.bz2
#cd libnfnetlink-1.0.1  
#./configure
#make &amp;&amp; make install
</code></pre>

<p>2、安装libmnl</p>

<pre><code>#wget http://netfilter.org/projects/libmnl/files/libmnl-1.0.3.tar.bz2
#tar jxvf libmnl-1.0.3.tar.bz2
#cd libmnl-1.0.3
#./configure
#make &amp;&amp; make install
</code></pre>

<p>3、安装libnetfilter_queue</p>

<pre><code>#wget http://netfilter.org/projects/libnetfilter_queue/files/libnetfilter_queue-1.0.2.tar.bz2
#tar jxvf libnetfilter_queue-1.0.2.tar.bz2
#cd libnetfilter_queue-1.0.2
#./configure
#make &amp;&amp; make install
</code></pre>

<h2>接口</h2>

<h3>初始化库</h3>

<pre><code>struct nfq_handle *     nfq_open (void)
int     nfq_close (struct nfq_handle *h)
int     nfq_bind_pf (struct nfq_handle *h, u_int16_t pf)
int     nfq_unbind_pf (struct nfq_handle *h, u_int16_t pf)
</code></pre>

<p>libnetfilter_queue初始化分为两部。<br/>
第一步调用nfq_open打开一个NFQUEUE句柄。<br/>
第二部通知内核指定协议的用户空间队列由NFQUEUE处理。调用nfq_unbind_pf()和nfq_bind接口进行绑定。<br/>
以下为初始化片段：</p>

<pre><code>h = nfq_open();
if (!h) {
    fprintf(stderr, "error during nfq_open()\n");
    exit(1);
}

printf("unbinding existing nf_queue handler for AF_INET (if any)\n");
if (nfq_unbind_pf(h, AF_INET) &lt; 0) {
    fprintf(stderr, "error during nfq_unbind_pf()\n");
    exit(1);
}

printf("binding nfnetlink_queue as nf_queue handler for AF_INET\n");
if (nfq_bind_pf(h, AF_INET) &lt; 0) {
    fprintf(stderr, "error during nfq_bind_pf()\n");
    exit(1);
}
</code></pre>

<p>nfq_open</p>

<pre><code>struct nfq_handle* nfq_open (void) 
</code></pre>

<p>nfq_open返回一个netfilter队列连接句柄。当使用完毕，调用nfq_close销毁句柄。在系统内部，会新创建一个netlink连接并与队列连接句柄相关联。</p>

<p>nfq_bind_pf</p>

<pre><code>int nfq_bind_pf (   struct nfq_handle *     h,
                    u_int16_t   pf   
                )   
</code></pre>

<p>nfq_bind_pf绑定一个协议域到nfqueue句柄。<br/>
队列连接句柄将会处理属于pf指定的协议报文，比如（PF_INET，PF_INET6）。
<a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/group__LibrarySetup.html">详细说明文档</a></p>

<h3>处理报文队列</h3>

<pre><code>int     nfq_fd (struct nfq_handle *h)   
struct nfq_q_handle *   nfq_create_queue (struct nfq_handle *h, u_int16_t num, nfq_callback *cb, void *data)
int     nfq_destroy_queue (struct nfq_q_handle *qh)
int     nfq_handle_packet (struct nfq_handle *h, char *buf,     int len)
int     nfq_set_mode (struct nfq_q_handle *qh, u_int8_t mode, u_int32_t range)
int     nfq_set_queue_maxlen (struct nfq_q_handle *qh, u_int32_t queuelen)
int     nfq_set_verdict (struct nfq_q_handle *qh, u_int32_t id, u_int32_t verdict, u_int32_t data_len, const unsigned char *buf)
int     nfq_set_verdict2 (struct nfq_q_handle *qh, u_int32_t id, u_int32_t verdict, u_int32_t mark, u_int32_t data_len, const unsigned char *buf)
int     nfq_set_verdict_mark (struct nfq_q_handle *qh, u_int32_t id, u_int32_t verdict, u_int32_t mark, u_int32_t data_len, const unsigned char *buf)
</code></pre>

<p>libnetfilter_queue库初始化后，可以绑定程序到具体报文队列。使用nfq_create_queue()进行绑定。
使用nfq_set_mode()和nfq_set_queue_maxlen()函数设置队列。
下面是创建队列0的代码片段：</p>

<pre><code>printf("binding this socket to queue '0'\n");
qh = nfq_create_queue(h,  0, &amp;cb, NULL);
if (!qh) {
    fprintf(stderr, "error during nfq_create_queue()\n");
    exit(1);
}

printf("setting copy_packet mode\n");
if (nfq_set_mode(qh, NFQNL_COPY_PACKET, 0xffff) &lt; 0) {
    fprintf(stderr, "can't set packet_copy mode\n");
    exit(1);
}
</code></pre>

<p>下一步是，循环读取队列中的报文进行处理：</p>

<pre><code>fd = nfq_fd(h);

while ((rv = recv(fd, buf, sizeof(buf), 0)) &gt;= 0) {
    printf("pkt received\n");
    nfq_handle_packet(h, buf, rv);
}
</code></pre>

<p>我们需要对每一个报文做出处理结果，通过nfq_set_verdict()或者nfq_set_verdict2()结果来传递结果。裁决结果决定报文的命运：</p>

<ul>
<li>NF_DROP   丢弃此报文</li>
<li>NF_ACCEPT 接受报文，继续迭代</li>
<li>NF_STOLEN gone away</li>
<li>NF_QUEUE  将报文注入另外一个队列</li>
<li>NF_REPEAT 重新再迭代一次</li>
<li>NF_STOP 接受，但是不再继续迭代</li>
</ul>


<p><a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/group__Queue.html">详细说明文档</a></p>

<h3>解析报文</h3>

<p>主要涉及以下接口：</p>

<pre><code>struct nfqnl_msg_packet_hdr *   nfq_get_msg_packet_hdr (struct nfq_data *nfad)
uint32_t    nfq_get_nfmark (struct nfq_data *nfad)
int     nfq_get_timestamp (struct nfq_data *nfad, struct timeval *tv)
u_int32_t   nfq_get_indev (struct nfq_data *nfad)
u_int32_t   nfq_get_physindev (struct nfq_data *nfad)
u_int32_t   nfq_get_outdev (struct nfq_data *nfad)
u_int32_t   nfq_get_physoutdev (struct nfq_data *nfad)
int     nfq_get_indev_name (struct nlif_handle *nlif_handle,    struct nfq_data *nfad, char *name)
int     nfq_get_physindev_name (struct nlif_handle *nlif_handle, struct nfq_data *nfad, char *name)
int     nfq_get_outdev_name (struct nlif_handle *nlif_handle, struct nfq_data *nfad, char *name)
int     nfq_get_physoutdev_name (struct nlif_handle *nlif_handle, struct nfq_data *nfad, char *name)
struct nfqnl_msg_packet_hw *    nfq_get_packet_hw (struct nfq_data *nfad)
int     nfq_get_payload (struct nfq_data *nfad, unsigned char **data)
</code></pre>

<p><a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/group__Parsing.html">详细说明文档</a></p>

<h2>示例</h2>

<p>示例源自libnetfilter_queue源代码中的例子<a href="http://netfilter.org/projects/libnetfilter_queue/doxygen/nfqnl__test_8c_source.html">nfqnl_test.c</a></p>

<pre><code>00001 
00002 #include &lt;stdio.h&gt;
00003 #include &lt;stdlib.h&gt;
00004 #include &lt;unistd.h&gt;
00005 #include &lt;netinet/in.h&gt;
00006 #include &lt;linux/types.h&gt;
00007 #include &lt;linux/netfilter.h&gt;            /* for NF_ACCEPT */
00008 
00009 #include &lt;libnetfilter_queue/libnetfilter_queue.h&gt;
00010 
00011 /* returns packet id */
00012 static u_int32_t print_pkt (struct nfq_data *tb)
00013 {
00014         int id = 0;
00015         struct nfqnl_msg_packet_hdr *ph;
00016         struct nfqnl_msg_packet_hw *hwph;
00017         u_int32_t mark,ifi; 
00018         int ret;
00019         unsigned char *data;
00020 
00021         ph = nfq_get_msg_packet_hdr(tb); // 返回报文头信息
00022         if (ph) {
00023                 id = ntohl(ph-&gt;packet_id);
00024                 printf("hw_protocol=0x%04x hook=%u id=%u ",
00025                         ntohs(ph-&gt;hw_protocol), ph-&gt;hook, id);
00026         }
00027 
00028         hwph = nfq_get_packet_hw(tb); // 返回报文硬件地址信息
00029         if (hwph) {
00030                 int i, hlen = ntohs(hwph-&gt;hw_addrlen);
00031 
00032                 printf("hw_src_addr=");
00033                 for (i = 0; i &lt; hlen-1; i++)
00034                         printf("%02x:", hwph-&gt;hw_addr[i]);
00035                 printf("%02x ", hwph-&gt;hw_addr[hlen-1]);
00036         }
00037 
00038         mark = nfq_get_nfmark(tb); // 返回报文标记
00039         if (mark)
00040                 printf("mark=%u ", mark);
00041 
00042         ifi = nfq_get_indev(tb); // 获取报文接收网卡的索引
00043         if (ifi)
00044                 printf("indev=%u ", ifi);
00045 
00046         ifi = nfq_get_outdev(tb); // 获取报文发送网卡的索引
00047         if (ifi)
00048                 printf("outdev=%u ", ifi); 
00049         ifi = nfq_get_physindev(tb); // 接收此报文的物理网卡索引
00050         if (ifi)
00051                 printf("physindev=%u ", ifi);
00052  
00053         ifi = nfq_get_physoutdev(tb); // 发送次报文的物理网卡索引
00054         if (ifi)
00055                 printf("physoutdev=%u ", ifi);
00056 
00057         ret = nfq_get_payload(tb, &amp;data); // 获取报文内容的长度
00058         if (ret &gt;= 0)
00059                 printf("payload_len=%d ", ret);
00060 
00061         fputc('\n', stdout);
00062 
00063         return id;
00064 }
00065         
00066 
00067 static int cb(struct nfq_q_handle *qh, struct nfgenmsg *nfmsg,
00068               struct nfq_data *nfa, void *data)
00069 {
00070         u_int32_t id = print_pkt(nfa);
00071         printf("entering callback\n");
00072         return nfq_set_verdict(qh, id, NF_ACCEPT, 0, NULL);
00073 }
00074 
00075 int main(int argc, char **argv)
00076 {
00077         struct nfq_handle *h;
00078         struct nfq_q_handle *qh;
00079         struct nfnl_handle *nh;
00080         int fd;
00081         int rv;
00082         char buf[4096] __attribute__ ((aligned));
00083           
00084         printf("opening library handle\n");
00085         h = nfq_open(); // 获取libnetfilter 队列句柄
00086         if (!h) {
00087                 fprintf(stderr, "error during nfq_open()\n");
00088                 exit(1);
00089         }
00090 
00091         printf("unbinding existing nf_queue handler for AF_INET (if any)\n");
00092         if (nfq_unbind_pf(h, AF_INET) &lt; 0) { // 先将队列连接句柄与AF_INET地址域解绑
00093                 fprintf(stderr, "error during nfq_unbind_pf()\n");
00094                 exit(1);
00095         }
00096 
00097         printf("binding nfnetlink_queue as nf_queue handler for AF_INET\n");
00098         if (nfq_bind_pf(h, AF_INET) &lt; 0) { // 将队列连接句柄与AF_INET地址绑定
00099                 fprintf(stderr, "error during nfq_bind_pf()\n");
00100                 exit(1);
00101         }
00102 
00103         printf("binding this socket to queue '0'\n");
00104         qh = nfq_create_queue(h,  0, &amp;cb, NULL); // 创建队列句柄用来处理0队列报文
00105         if (!qh) {
00106                 fprintf(stderr, "error during nfq_create_queue()\n");
00107                 exit(1);
00108         }
00109 
00110         printf("setting copy_packet mode\n");
00111         if (nfq_set_mode(qh, NFQNL_COPY_PACKET, 0xffff) &lt; 0) { // 设置队列工作模式
00112                 fprintf(stderr, "can't set packet_copy mode\n");
00113                 exit(1);
00114         }
00115 
00116         fd = nfq_fd(h); // 获取队列连接描述符
00117 
00118         while ((rv = recv(fd, buf, sizeof(buf), 0)) &amp;&amp; rv &gt;= 0) {
00119                 printf("pkt received\n");
00120                 nfq_handle_packet(h, buf, rv); // 处理收到的每个报文
00121         }
00122 
00123         printf("unbinding from queue 0\n");
00124         nfq_destroy_queue(qh); // 从队列0解绑
00125 
00126 #ifdef INSANE
00127         /* normally, applications SHOULD NOT issue this command, since
00128          * it detaches other programs/sockets from AF_INET, too ! */
00129         printf("unbinding from AF_INET\n");
00130         nfq_unbind_pf(h, AF_INET);
00131 #endif
00132 
00133         printf("closing library handle\n");
00134         nfq_close(h); // 关闭库句柄
00135 
00136         exit(0);
00137 }
</code></pre>

<p>编译程序：</p>

<pre><code>gcc nfqnl_test.c -lnetfilter_queue -o nfqnl_test
</code></pre>

<p>配置iptables：
使用iptables命令修改防火墙规则，将发送到112.80.248.74的报文放置到队列0中：</p>

<pre><code>#iptables -t filter -A OUTPUT -d 112.80.248.74 -j NFQUEUE --queue-num 0
#iptables -t filter -L
Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
NFQUEUE    all  --  anywhere             112.80.248.74  NFQUEUE num 0
</code></pre>

<p>启动ping程序：</p>

<pre><code># ping 112.80.248.74
PING 112.80.248.74 (112.80.248.74) 56(84) bytes of data.
</code></pre>

<p>当nfqnl_test程序未启动时，ping程序不能正确发送出icmp报文，也就不能收到icmp回复。</p>

<p>启动nfqnl_test程序：</p>

<pre><code># ./nfqnl_test
opening library handle
unbinding existing nf_queue handler for AF_INET (if any)
binding nfnetlink_queue as nf_queue handler for AF_INET
binding this socket to queue '0'
setting copy_packet mode
pkt received
hw_protocol=0x0000 hook=3 id=1 outdev=2 payload_len=84
entering callback
pkt received
hw_protocol=0x0000 hook=3 id=2 outdev=2 payload_len=84
</code></pre>

<p>nfqnl_test程序从nfqueue_num 0中读取报文，打印相关信息后，将报文送回协议栈，完成了发送流程，从目标收到了icmp报文回复</p>

<pre><code>64 bytes from 112.80.248.74: icmp_req=612 ttl=58 time=1.84 ms
64 bytes from 112.80.248.74: icmp_req=613 ttl=58 time=1.83 ms
64 bytes from 112.80.248.74: icmp_req=614 ttl=58 time=1.76 ms
64 bytes from 112.80.248.74: icmp_req=615 ttl=58 time=1.83 ms
64 bytes from 112.80.248.74: icmp_req=616 ttl=58 time=1.97 ms
64 bytes from 112.80.248.74: icmp_req=617 ttl=58 time=1.92 ms
64 bytes from 112.80.248.74: icmp_req=618 ttl=58 time=2.07 ms   
</code></pre>

<h1>参考</h1>

<p>netfilter<a href="http://www.netfilter.org/">官网</a><br/>
<a href="http://bbs.chinaunix.net/forum.php?mod=viewthread&amp;tid=1196223">用户态修改网络数据包例子</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用FIFO命名管道进行进程间通讯]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/06/14/shi-yong-fifoming-ming-guan-dao-jin-xing-jin-cheng-jian-tong-xun/"/>
    <updated>2015-06-14T15:56:00+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/06/14/shi-yong-fifoming-ming-guan-dao-jin-xing-jin-cheng-jian-tong-xun</id>
    <content type="html"><![CDATA[<p>管道是进程间通讯的一种方式。使用<code>pipe</code>，<code>popen</code>，<code>pclose</code>，等接口我们可以使用管道来进行进程间通讯。但是这一种管道只能由相关进程使用，这些相关进程的共同祖先进程创建了管道。通过FIFO，也称为命名管道，不相关的进程也可以进行通讯。</p>

<h1>创建命名管道</h1>

<p>调用mkfifo接口创建命名管道：</p>

<pre><code>#include &lt;sys/types.h&gt;
#include &lt;sys/stat.h&gt;
int mkfifo(const char *path, mode_t mode);
</code></pre>

<p>创建FIFO类似于创建文件。FIFO的路径名存在于文件系统中。FIFO是一种文件类型。stat结构成员st_mode的编码指明文件是否是FIFO类型。可以用S_ISFIFO宏对此进行测试。 mkfifo函数创建一个路径名为path的fifo。mode和umask掩码规定了命名管道的访问权限。<br/>
参数：<br/>
path是管道在文件系统中的存在路径。<br/>
mode于open函数中定义的mode一样。</p>

<p>返回值：<br/>
成功返回0。失败返回-1，同时设置errno错误码。</p>

<p>错误原因：</p>

<ul>
<li>ENOTSUP       系统内核不支持fifo</li>
<li>ENOTDIR       path前缀不是合法目录</li>
<li>ENAMETOOLONG  path路径太长</li>
<li>EACCESS       用户对于path中的目录没有权限访问</li>
<li>EROFS         path指定的目录在只读文件系统</li>
<li><p>EEXIST        path指定文件已经存在</p>

<p>  <!-- more --></p></li>
</ul>


<h1>注意事项</h1>

<p>我们可以像访问普通文件一样访问命名管道文件。一般的文件I/O函数都可以用于FIFO。<br/>
当打开一个FIFO，非阻塞标志（O_NONBLOCK）产生下列影响：</p>

<ul>
<li>在一般情况下（没有指定O_NOBLOCK），只读open要阻塞到某个其他进程为写而打开此FIFO。类似地，只写open要阻塞到某个进程为读而打开此FIFO。</li>
<li>如果指定了O_NONBLOCK，则只读open立即返回。但是，如果没有进程已经为读而打开一个FIFO，那么只写open将出错返回-1，其errno是ENXIO。</li>
</ul>


<p>当多个写进程同时向同一FIFO进行写操作时，如果保证来自不同程序的数据块不相互交错，每个写操作必须原子话，FIFO的长度是需要考虑的一个很重要因素。系统对任一时刻在一个FIFO中可以存在的数据长度是有限制的。它由#define PIPE_BUF定义，在头文件limits.h中。在Linux和许多其他类UNIX系统中，它的值通常是4096字节，Red Hat Fedora9下是4096，但在某些系统中它可能会小到512字节。</p>

<ul>
<li>当要写入的数据量不大于PIPE_BUF时，Linux将保证写入的原子性。如果此时管道空闲缓冲区不足以容纳要写入的字节数，则进入睡眠，直到当缓冲区中能够容纳要写入的字节数时，才开始进行一次性写操作。即写入的数据长度小于等于PIPE_BUF时，那么或者写入全部字节，或者一个字节都不写入，它属于一个一次性行为，具体要看FIFO中是否有足够的缓冲区。</li>
<li>当要写入的数据量大于PIPE_BUF时，Linux将不再保证写入的原子性。FIFO缓冲区一有空闲区域，写进程就会试图向管道写入数据，写操作在写完所有请求写的数据后返回。</li>
</ul>


<h1>FIFO示例</h1>

<p>创建FIFO</p>

<pre><code>ret = mkfifo(FIFO_NAME,0777);
if ((-1 == ret) &amp;&amp; (errno != EEXIST)) {
    perror("create fifo fail.\n");
    exit(1);
}
</code></pre>

<p>读FIFO进程代码</p>

<pre><code>// create fifo
int ret = mkfifo(FIFO_NAME,0777);
if ((-1 == ret) &amp;&amp; (errno != EEXIST)) {
    perror("create fifo fail.\n");
    exit(1);
}

int fd = open(FIFO_NAME, O_RDONLY);
// int fd = open(FIFO_NAME, O_RDWR);
if (-1 == fd) {
    printf("open fifo %s fail\n", FIFO_NAME);
    exit(1);
}
printf("open fifo %s for read suc\n", FIFO_NAME);

char buf[1024];
while (1 ) {
    ssize_t size = read(fd, buf, sizeof(buf));
    if (size &gt; 0) {
        buf[size] = '\0';
        printf("read from fifo: %s\n", buf);
    } else if(size == 0) {
        printf("write end of fifo exit\n");
        break;
    } else {
        perror("read fail from fifo:");
        break;
    }
}
close(fd);
return 0;
</code></pre>

<p>写FIFO进程代码</p>

<pre><code>// create fifo
int ret = mkfifo(FIFO_NAME,0777);
if ((-1 == ret) &amp;&amp; (errno != EEXIST)) {
    perror("create fifo fail.\n");
    exit(1);
}

int fd = open(FIFO_NAME, O_WRONLY);
if (-1 == fd) {
    printf("open fifo %s fail\n", FIFO_NAME);
    exit(1);
}
printf("open fifo %s for write suc", FIFO_NAME);

while (1) {
    char buf[1024] = {0};
    if (gets(buf) == NULL) {
        break;
    }
    int len = strlen(buf);
    if (0 == len)
      break;
    printf("%d\n", len);
    ssize_t size = write(fd, buf, len);
    if (size &gt;= 0) {
        printf("write to fifo: %s, msg: %s, size:%ld \n", FIFO_NAME, buf, size);
    } else {
        perror("write fail\n");
        break;
    }
}
close(fd);
return 0;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux/Unix设置SUID]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/06/02/linux-slash-unixshe-zhi-suid/"/>
    <updated>2015-06-02T13:56:27+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/06/02/linux-slash-unixshe-zhi-suid</id>
    <content type="html"><![CDATA[<h1>非root用户运行tcpdump</h1>

<p>有些时候，我们希望以非root用户运行一些程序，比如以普通用户运行tcpdump命令进行抓包时，系统报如下异常信息：</p>

<p>Mac OS 系统：</p>

<pre><code>MacBook-Pro:plugins jintao$ tcpdump
tcpdump: ioctl(SIOCIFCREATE): Operation not permitted
MacBook-Pro:plugins jintao$
</code></pre>

<p>Ubuntu系统：</p>

<pre><code>[app@mp5 ~]$ tcpdump
tcpdump: no suitable device found
[app@mp5 ~]$
</code></pre>

<p>为什么会出现上述异常信息呢？是否是因为普通用户没有执行权限？下面是系统中tcpdump命令的权限信息<br/>
Mac OS 系统：</p>

<pre><code>MacBook-Pro:plugins jintao$ which tcpdump
/usr/sbin/tcpdump
MacBook-Pro:plugins jintao$ ls -l /usr/sbin/tcpdump
-rwxr-xr-x 1 root wheel 749040  9 10  2014 /usr/sbin/tcpdump*
MacBook-Pro:plugins jintao$
</code></pre>

<p>Ubuntu系统：</p>

<pre><code>[app@mp5 ~]$ which tcpdump
/usr/sbin/tcpdump
[app@mp5 ~]$ ls -l /usr/sbin/tcpdump
-rwxr-xr-x. 1 root root 742080 3月  26 2012 /usr/sbin/ tcpdump
[app@mp5 ~]$
</code></pre>

<p>根据tcpdump的权限位-rwxr-xr-x我们发现对于普通用户jintao、app是拥有可读和可执行权限的。以普通用户执行tcpdump时，tcpdump进程的实际运行用户和有效用户都是普通用户，tcpdump运行过程中需要获取系统网卡资源信息，而获取这些信息需要root权限，这样的话系统就禁止了tcpdump程序的运行。<br/>
解决这样的问题，我们可以尝试以下三种方法：</p>

<p>  <!-- more --></p>

<ul>
<li>su切换到root用户，然后再执行tcpdump，这一解决方案与我们以非root用户运行不符</li>
<li>以root用户编辑/etc/sudoers文件，赋予普通用户执行tcpdump命令的权限</li>
<li>设置tcpdump程序的用户ID权限位SUID</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MacBook-Pro:C++ jintao$ sudo chmod u+s /usr/sbin/tcpdump
</span><span class='line'>Password:
</span><span class='line'>MacBook-Pro:C++ jintao$ ls -l /usr/sbin/tcpdump
</span><span class='line'>-rwsr-xr-x 1 root wheel 749040  9 10  2014 /usr/sbin/tcpdump*
</span><span class='line'>MacBook-Pro:C++ jintao$ tcpdump
</span><span class='line'>tcpdump: data link type PKTAP
</span><span class='line'>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span></code></pre></td></tr></table></div></figure>


<p>下面着重介绍第三种方法：</p>

<h1>什么是SUID</h1>

<p>SUID(Set owner User ID)是赋予文件的一种特殊权限位。在UNIX系统中，特权（例如能改变当前日期的表示法以及访问控制（例如，能否读、写一特定文件））是基于用户和组ID的。用户运行某程序时，程序访问资源的权限基于运行此程序的用户来决定。SUID被用来赋予程序访问资源的权限与程序的拥有者相同，而不是实际执行者。一言以蔽之，运行设置SUID权限位的程序时，普通用户将会获取文件拥有者的用户ID(UID)和组ID(GID)。</p>

<h2>Example1:passwd command</h2>

<p>我们运行passwd来修改我们的登陆密码，passwd命令拥有者是root用户。passwd命令会尝试修改系统配置文件，比如/etc/passwd, /etc/shadow等。其中的一些文件，只有root权限才能访问，非root用户无法打开。如果去掉SUID权限位，只是设置passwd command文件的所有权限位，那这个命令无法访问/etc/shadow等文件，程序会返回权限禁止错误或者其他措施。所以passwd被设置SUID权限位来赋予非root用户更新/etc/shadow等文件的权限。</p>

<h2>Example2: ping command</h2>

<p>当我们运行ping命令时，ping命令会打开socket文件和端口用来发送和接收IP数据包。非root用户无法获取权限打开socket和端口。所以对ping命令文件设置SUID权限位，任何执行ping命令的用户都可以获取ping命令文件拥有者（root用户）的权限。当执行ping命令时就拥有root权限来打开socket和端口port</p>

<h1>如何设置文件SUID权限位</h1>

<p>与设置文件其他的读、写、可执行权限位类似，可以用以下方法设置</p>

<pre><code>* 字符命令方式（s代表Set）
* 八进制数字（4）
</code></pre>

<p>对file1.sh设置SUID</p>

<p>字符模式：</p>

<pre><code>chmod u+s file1.sh
</code></pre>

<p>设置owner可执行权限位为SUID位</p>

<p>数字模式：</p>

<pre><code>chmod 4750 file1.sh
</code></pre>

<p>4750，4代表设置SUID权限位，7代表owner可读、可写、可执行权限位，5代表组拥有可读、可执行权限位，0代表其他不会不具有任何权限。</p>

<p>对于file1.sh文件，设置SUID前权限位：</p>

<pre><code>MacBook-Pro:C++ jintao$ ls -l file1.sh
-rwxr--r-- 1 jintao staff 0  6  2 15:57 file1.sh*
MacBook-Pro:C++ jintao$
</code></pre>

<p>设置SUID权限位后：</p>

<pre><code>MacBook-Pro:C++ jintao$ ls -l file1.sh
-rwsr--r-- 1 jintao staff 0  6  2 15:57 file1.sh*
MacBook-Pro:C++ jintao$
</code></pre>

<h1>何时使用SUID</h1>

<p>1）当需要root用户登录来执行某些命令/程序/脚本<br/>
2）不想赋予某些特殊用户信任，但是想以owner用户运行某些命令时<br/>
3）不想使用SUDO命令而执行某些文件、脚本时</p>

<h1>参考</h1>

<p><a href="http://www.linuxnix.com/2011/12/suid-set-suid-linuxunix.html">http://www.linuxnix.com/2011/12/suid-set-suid-linuxunix.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python解析json]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/05/28/pythonjie-xi-json/"/>
    <updated>2015-05-28T15:21:55+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/05/28/pythonjie-xi-json</id>
    <content type="html"><![CDATA[<h1>JSON简介</h1>

<p>JSON(JavaScript Object Notation)是一个轻量级的数据交换格式。方便人类读写。方便机器解析和产生。它基于<a href="http://javascript.crockford.com/">JavaScript Programming Language</a>的子集，<a href="http://www.ecma-international.org/publications/files/ECMA-ST/Ecma-262.pdf">Standard ECMA-262 3rd Edition - December 1999.</a>。JSON使用完全独立于各种语言的文本格式，但是也使用了类似C语言家族的习惯，包括C,C++,C#,Java,JavaScript,Perl,Python以及其他语言。这些特性使得JSON成为理想的数据交换语言。</p>

<p>JSON基于两种结构：</p>

<ul>
<li>一个name/value对集合。在各种语言中，这种集合被认为是一个对象，记录，结构体，字典，哈希表，有键列表，或者关联数组</li>
<li>一个有序列表。在大多数语言中，这种列表被认为是一个数组，向量，列表，或者序列。</li>
</ul>


<p>这些都是常见的数据结构。事实上大部分现代计算机语言都以某种形式支持它们。这使得一种数据格式在同样基于这些结构的编程语言之间交换成为可能。
关于JSON格式中各个基本类型和数据结构的详细描述，可以参考<a href="http://www.json.org/">json</a></p>

<p>  <!-- more --></p>

<h1>Python JSON模块</h1>

<h2>类</h2>

<p>类JSONDecoder</p>

<pre><code>class JSONDecoder(__builtin__.object)   
</code></pre>

<p>将JSON格式解码为Python对应类型，下面是对应关系：</p>

<pre><code>    | JSON          | Python            |
    +===============+===================+
    | object        | dict              |
    +---------------+-------------------+
    | array         | list              |
    +---------------+-------------------+
    | string        | unicode           |
    +---------------+-------------------+
    | number (int)  | int, long         |
    +---------------+-------------------+
    | number (real) | float             |
    +---------------+-------------------+
    | true          | True              |
    +---------------+-------------------+
    | false         | False             |
    +---------------+-------------------+
    | null          | None              |
    +---------------+-------------------+
</code></pre>

<p>类JSONEncoder</p>

<pre><code>class JSONEncoder(__builtin__.object)
</code></pre>

<p>将Python中的类型转换为JSON格式，下面是对应关系：</p>

<pre><code>    | Python            | JSON          |
    +===================+===============+
    | dict              | object        |
    +-------------------+---------------+
    | list, tuple       | array         |
    +-------------------+---------------+
    | str, unicode      | string        |
    +-------------------+---------------+
    | int, long, float  | number        |
    +-------------------+---------------+
    | True              | true          |
    +-------------------+---------------+
    | False             | false         |
    +-------------------+---------------+
    | None              | null          |
    +-------------------+---------------+
</code></pre>

<h2>函数</h2>

<p>json模块对外提供了4个函数来进行json格式的编码、解码工作：<br/>
1、dump函数</p>

<pre><code>dump(obj, fp, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding='utf-8', default=None, sort_keys=False, **kw)
</code></pre>

<p>序列化<code>obj</code>为json格式流保存到fp中（fp是一个支持.write()函数的类文件对象）</p>

<ul>
<li><p>skipkeys<br/>
如果<code>skipkeys</code>为true，字典（<code>dict</code>）中键不为基本类型（<code>str</code>,<code>unicode</code>,<code>int</code>,<code>long</code>,<code>float</code>,<code>bool</code>,<code>None</code>）时，键值对将会被过滤掉，否则产生<code>TypeError</code>异常</p></li>
<li><p>ensure_ascii  <br/>
如果<code>ensure_ascii</code>为true(默认为true)，输出中的所有非ASCII字符都转义为<code>\uXXXX</code>序列，并且返回值序列只包含ASCII序列。</p></li>
<li><p>check_circular<br/>
如果check_circular为false，将会忽略对容器类型的循环引用检测，进而导致<code>OverflowError</code></p></li>
<li><p>allow_nan<br/>
如果<code>allow_nan</code>为false，序列化float类型无限值（<code>nan</code>,<code>inf</code>,<code>-inf</code>）时，将会导致<code>ValueError</code>错误</p></li>
<li><p>indent<br/>
如果indent指定为非负数值，JSON数组和对象成员将会以indent缩进整齐打印。</p></li>
<li><p>separators<br/>
如果separators是一个<code>(item_separator, dict_separator)</code>元组，它就会用来替代缺省的<code>(', ', ': ')</code>分隔符。<code>(',', ':')</code>是最长用的压缩分隔符</p></li>
<li>encoding
json文本字符编码，缺省为UTF-8</li>
<li>default(obj)<br/>
default(obj)是一个函数返回obj的序列化版本或者产生TypeError。</li>
<li>sort_keys<br/>
如果为True(sort_keys默认为False)，字典将会按照key排序输出。</li>
</ul>


<p>2、dumps函数</p>

<pre><code>dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding='utf-8', default=None, sort_keys=False, **kw)
</code></pre>

<p>序列化<code>obj</code>对象为JSON格式的字符串。
各个参数的意思于上面dump函数相同</p>

<p>3、load函数</p>

<pre><code>load(fp, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)
</code></pre>

<p>load函数从fp引用的对象中读取JSON格式字符串，反序列化为Python对象。</p>

<ul>
<li>encoding<br/>
如果fp的内容不是基于ASCII字符集，那么需要指定encoding为相应编码集。</li>
<li>object_hook<br/>
object_hook可选参数被用来代替Python中的<code>dict</code>类型解析json序列串中的对象。这一特性被用来定制解码器。</li>
<li>object_pairs_hook<br/>
object_pairs_hook作为可选函数，被用来解析有序对，如果同时设置了object_pairs_hook和object_hook参数，优先使用object_pairs_hook函数。</li>
</ul>


<p>4、loads</p>

<pre><code>loads(s, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)
</code></pre>

<p>loads函数将s字符串反序列化为Python对象。</p>

<ul>
<li><p>parse_float<br/>
如果指定parse_float参数，它被用来反序列化float字符串，缺省为float(num_str)。</p></li>
<li><p>parse_int<br/>
如果指定parse_int参数，它被用来反序列化int字符串，缺省为int(num_str)</p></li>
<li><p>parse_constant<br/>
如果指定parse_constant参数，它将被用来返序列化-Infinity, Infinity, NaN, null, true, false.</p></li>
</ul>


<h2>示例</h2>

<p>1、编码Python基本类型</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])
'["foo", {"bar": ["baz", null, 1.0, 2]}]'
&gt;&gt;&gt; print json.dumps("\"foo\bar")
"\"foo\bar"
&gt;&gt;&gt; print json.dumps(u'\u1234')
"\u1234"
&gt;&gt;&gt; print json.dumps('\\')
"\\"
&gt;&gt;&gt; print json.dumps({"c": 0, "b": 0, "a": 0}, sort_keys=True)
{"a": 0, "b": 0, "c": 0}
&gt;&gt;&gt; from StringIO import StringIO
&gt;&gt;&gt; io = StringIO()
&gt;&gt;&gt; json.dump(['streaming API'], io)
&gt;&gt;&gt; io.getvalue()
'["streaming API"]'   
</code></pre>

<p>2、压缩编码</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; json.dumps([1,2,3,{'4': 5, '6': 7}], sort_keys=True, separators=(',',':'))
'[1,2,3,{"4":5,"6":7}]'
</code></pre>

<p>3、优雅打印</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; print json.dumps({'4': 5, '6': 7}, sort_keys=True,
...                  indent=4, separators=(',', ': '))
{
    "4": 5,
    "6": 7
}
</code></pre>

<p>4、反序列化JSON</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; obj = [u'foo', {u'bar': [u'baz', None, 1.0, 2]}]
&gt;&gt;&gt; json.loads('["foo", {"bar":["baz", null, 1.0, 2]}]') == obj
True
&gt;&gt;&gt; json.loads('"\\"foo\\bar"') == u'"foo\x08ar'
True
&gt;&gt;&gt; from StringIO import StringIO
&gt;&gt;&gt; io = StringIO('["streaming API"]')
&gt;&gt;&gt; json.load(io)[0] == 'streaming API'
True
</code></pre>

<p>5、定制JSON对象反序列化</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; def as_complex(dct):
...     if '__complex__' in dct:
...         return complex(dct['real'], dct['imag'])
...     return dct
...
&gt;&gt;&gt; json.loads('{"__complex__": true, "real": 1, "imag": 2}',
...     object_hook=as_complex)
(1+2j)
&gt;&gt;&gt; from decimal import Decimal
&gt;&gt;&gt; json.loads('1.1', parse_float=Decimal) == Decimal('1.1')
True
</code></pre>

<p>6、定制JSON对象序列化</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; def encode_complex(obj):
...     if isinstance(obj, complex):
...         return [obj.real, obj.imag]
...     raise TypeError(repr(o) + " is not JSON serializable")
...
&gt;&gt;&gt; json.dumps(2 + 1j, default=encode_complex)
'[2.0, 1.0]'
&gt;&gt;&gt; json.JSONEncoder(default=encode_complex).encode(2 + 1j)
'[2.0, 1.0]'
&gt;&gt;&gt; ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))
'[2.0, 1.0]'
</code></pre>

<p>7、使用json.tool校验和打印json</p>

<pre><code>$ echo '{"json":"obj"}' | python -m json.tool
{
    "json": "obj"
}
$ echo '{ 1.2:3.4}' | python -m json.tool
Expecting property name enclosed in double quotes: line 1 column 3 (char 2)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tcp Server使用kevent进行io复用]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/05/01/tcp-servershi-yong-keventjin-xing-iofu-yong/"/>
    <updated>2015-05-01T08:40:25+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/05/01/tcp-servershi-yong-keventjin-xing-iofu-yong</id>
    <content type="html"><![CDATA[<h1>概述</h1>

<p>kqueue是FreeBSD系统中引入的可扩展事件通知接口，NetBSD，OpenBSD，DragonflyBSD和OS X这些系统也支持此接口。传统的io复用接口如select和poll存在以下两个缺点：</p>

<ul>
<li>支持的文件描述符数量有限，select接口支持的文件描述个数与进程能够打开的最大文件个数有关</li>
<li>当大量描述符需要复用时，select和poll的效率会降低，内核是采用轮询方式判断描述符是否可用</li>
</ul>


<p>kqueue是针对传统传统的select/poll处理大量的文件描述符性能较低效而开发出来的。注册一批描述符到kqueue以后，当其中的描述符状态发生变化时，kqueue将一次性通知应用程序哪些描述符可读、可写或者发生错误。</p>

<p>kqueue支持多种类型的文件描述符，包括socket、信号、定时器、AIO、VNODE、PIPE。</p>

<h1>接口</h1>

<h2>kqueue</h2>

<pre><code>int kqueue(void);
</code></pre>

<p>kqueue系统调用创建一个新的内核事件队列并返回该队列描述符。调用fork时，子进程不继承该描述符。<br/>
失败时，系统调用返回-1,同时设置errno</p>

<h2>kevent</h2>

<pre><code>int kevent(int kq, const struct kevent *changelist, int nchanges, struct kevent *eventlist, int nevents, const struct timespec *timeout);
</code></pre>

<p>使用kevent系统调用向队列注册事件和返回已经触发的事件。</p>

<ul>
<li>kq<br/>
kq为kqueue系统调用返回的队列描述符</li>
<li>changelist<br/>
changelist指向一个kevnet结构体数组，kevent定义在&lt;sys/event.h>头文件中，这个数组描述了需要对kq队列中的事件进行修改，包括添加、删除、修改等操作</li>
<li>nchanges<br/>
nchanges是changelist参数指向数组的大小</li>
<li>evnetlist<br/>
指向一个kevnet结构体数组，用于返回已经触发的事件</li>
<li>nevents<br/>
定义eventlist数组大小</li>
<li><p>timeout
timeout是非NULL指针时，定义系统调用超时间隔。timeout为NULL时，kevent系统调用无限阻塞等待事件发生。timeout非NULL，但是值为0时，kevent立即返回</p>

<p><!-- more --></p></li>
</ul>


<h2>EV_SET</h2>

<pre><code>EV_SET(&amp;kev, ident, filter, flags, fflags, data, udata);
struct kevent {
         uintptr_t       ident;          /* identifier for this event */
         int16_t         filter;         /* filter for event */
         uint16_t        flags;          /* general flags */
         uint32_t        fflags;         /* filter-specific flags */
         intptr_t        data;           /* filter-specific data */
         void            *udata;         /* opaque user data identifier */
 };
</code></pre>

<p>EV_SET宏用来初始化一个kevent结构体。下面详细介绍结构体各个字段</p>

<ul>
<li>ident
ident用来标识一个事件，ident值的准确含义由filter字段进行解释，ident值通常代表一个文件描述符</li>
<li><p>filter
内核filter定义的过滤器处理发生在ident上的事件。预定义的系统过滤器如下，通过kevent结构体中的flags和data字段传递参数</p>

<p>EVFILT_READ <br/>
文件描述符作为标识符，当描述符可读时返回。根据文件描述符类型不同，触发该过滤器的情况不同：</p>

<ul>
<li>sockets:<br/>
处于监听状态的socket套接字，当存在待处理的建立连接请求（已经完成三次握手）时，该套接字可读，kevent结构体的data字段包含监听队列中待处理的请求个数。<br/>
非监听状态的套接字缓冲区中有可读数据时，触发该过滤器，每个套接字对应的缓冲区可读低水位可以通过传递fflags和data参数进行设置。</li>
<li>Vnodes<br/>
当文件指针没有达到文件末尾时，触发该过滤器。</li>
<li>Fifos, Pipes<br/>
当管道可读时，触发该过滤器。data字段返回可读字节数。</li>
</ul>


<p>EVFILT_WRITE  <br/>
文件描述符作为标识符。当文件描述符可写时，触发该过滤器。对于sockets、pipes和fifos，data字段返回缓冲区中可写字节数。  <br/>
EVFILT_AIO<br/>
尚不支持<br/>
EVFILT_VNODE  <br/>
文件描述符作为标识符，fflags字段定义需要监测的事件类型：</p>

<ul>
<li>NOTE_DELETE  <br/>
unlink系统调用操作文件描述符指向的文件时，事件发生。</li>
<li>NOTE_WRITE  <br/>
对文件描述指向的文件进行写操作</li>
<li>NOTE_EXTEND<br/>
对文件描述符指向的文件进行extened</li>
<li>NOTE_ATTRIB<br/>
文件描述符指向的文件属性发生了变化</li>
<li>NOTE_LINK<br/>
文件描述指向的文件链接数发生了变化</li>
<li>NOTE_RENAME<br/>
文件描述符指向的文件发生了重命名</li>
<li>NOTE_REVOKE</li>
</ul>


<p>kevent系统调用返回时，fflags包含触发过滤器的事件</p>

<p>EVFILT_PROC
进程id作为标识符。监测的事件定义在fflags字段中：</p>

<ul>
<li>NOTE_EXIT  <br/>
进程退出</li>
<li>NOTE_EXITSTATUS<br/>
进程已经退出，退出状态</li>
<li>NOTE_FORK<br/>
进程调用fork或者其他类似接口创建子进程</li>
<li>NOTE_EXEC<br/>
进程调用execve或者其他类似接口执行一个新进程</li>
<li>NOTE_SIGNAL<br/>
进程被发送一个信号。<br/>
kevent系统调用返回时，fflags包含触发过滤器的事件。</li>
</ul>


<p>EVFILT_SIGNAL<br/>
将信号值作为标识符，当该信号发送到进程时，触发过滤器。</p>

<p>EVFILT_TIMER
设置一个ident标识的定时器。当添加一个定时器时，data字段指定定时器超时事件，fflags字段可以为以下设置：</p>

<ul>
<li>NOTE_SECONDS <br/>
data字段值单位为秒</li>
<li>NOTE_USECONDS<br/>
data字段值单位为毫米</li>
<li>NOTE_NSECONDS<br/>
data字段值单位为纳秒</li>
<li>NOTE_ABSOLUTE
data字段值为绝对时间</li>
</ul>
</li>
<li><p>flags<br/>
flags表示对该事件做的操作。</p>

<ul>
<li>EV_ADD<br/>
添加该事件到kqueue队列</li>
<li>EV_ENABLE
如果该事件触发，kevent返回该事件</li>
<li>EV_DISABLE
如果该事件触发，kevent不返回该事件</li>
<li>EV_DELETE
从kevent队列中删除该事件</li>
<li>EV_RECEIPT
对kqueue进行批量修改，而不返回任何待处理事件。</li>
<li>EV_ONESHOT
过滤器第一次触发后，返回该事件，然后将该事件从kqueue队列中删除。</li>
<li>EV_CLEAR
用户获取事件后，重置事件状态。</li>
<li>EV_ERROR
系统处理事件出错时，返回该事件event，将flags设置为EV_ERROR</li>
</ul>
</li>
<li><p>fflags<br/>
过滤器相关的标志</p></li>
<li>data<br/>
过滤器相关的数值</li>
<li>udata
用户定义的值，当事件返回时，内核将该值带给用户</li>
</ul>


<p>将<a href="http://jintao-zero.github.io/blog/2015/04/12/tcp-servershi-yong-selectjin-xing-i-slash-ofu-yong/">tcp server 使用select进行并发</a>示例改为使用kevent进行i/o多路复用，主要涉及以下方面的修改：</p>

<p>1、套接字注册</p>

<pre><code>int Register(int kq, int fd)
{
    struct kevent ke;
    EV_SET(&amp;ke, fd, EVFILT_READ, EV_ADD, 0, 0, NULL);
    return kevent(kq, &amp;ke, 1, NULL, 0, NULL);
}
</code></pre>

<p> 目前只是对监听套接字和客户端连接套接字注册可读过滤器</p>

<p>2、循环调用kevent处理套接字事件</p>

<pre><code>struct kevent events[MAX_EVENT_COUNT];
for ( ; ; ) {
    int nevent = kevent(kq, NULL, 0, events, MAX_EVENT_COUNT, NULL);
}

void HandleEvent(int kq, struct kevent * events, int nevents) 
{
    for (int i = 0; i &lt; nevents; i++) {
        int sock = events[i].ident;
        int data = events[i].data;
        if (sock == serv_sock) {
            Accept(kq, data);
        } else {
            Receive(sock, data);
        }
    }
}

void Accept(int kq, int conn_size)
{
    for (int i = 0; i &lt; conn_size; i++) {
      int client = accept(serv_sock, NULL, NULL);
      Register(kq, client);
    }
}

void Receive(int sock, int buf_size)
{
    if (0 == buf_size)
        close(sock); // close a file descriptor removing any            kevents that reference the descriptor

    char *buf = malloc(buf_size);
    if (NULL == buf)
        return;

    recv(sock, buf, buf_size, 0);
    for (int i = 0; i &lt; buf_size; i++)
        buf[i] = toupper(buf[i]);
    send(sock, buf, buf_size, 0);
    free(buf);
}    
</code></pre>

<h1>结束语</h1>

<p>这篇文章只是简单介绍了kevent I/O多路复用模型的简单用法，上述例子中涉及的一些细节，如错误处理等都尚须完善<br/>
参考<a href="http://www.ibm.com/developerworks/cn/aix/library/1105_huangrg_kqueue/index.html#resources">使用 kqueue 在 FreeBSD 上开发高性能应用服务器</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tcp server使用select进行I/O复用]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/04/12/tcp-servershi-yong-selectjin-xing-i-slash-ofu-yong/"/>
    <updated>2015-04-12T15:30:03+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/04/12/tcp-servershi-yong-selectjin-xing-i-slash-ofu-yong</id>
    <content type="html"><![CDATA[<p>在<a href="http://jintao-zero.github.io/blog/2015/02/13/tcp-fu-wu-duan-li-zi/">tcp服务端示例</a>中，接受一个客户端连接，调用accept函数返回后就对本客户端连接进行业务处理，如果业务逻辑比较复杂，那么服务端有可能就阻塞在某个客户端上，而不能处理其他客户端连接，解决此问题有多种模型可以采用：<br/>
1）多进程，为每个客户端连接创建一个子进程进行处理<br/>
2）多线程，多个线程并行处理客户端连接<br/>
3）I/O多路复用，服务器采用单线程模型，使用I/O多路复用模型，并行处理多个客户端文件描述符<br/>
在上一篇示例<a href="http://jintao-zero.github.io/blog/2015/04/06/tcp-client-shi-yong-selectjin-xing-i-slash-ofu-yong/">tcp client 使用select进行I/O复用</a>中介绍的select函数同样适用与对tcp server端的I/O多路复用改造，改造主要设计几下几个方面：</p>

<!-- more -->


<p>1）将server监听套接字添加到readfds套接字集合中，监听套接字可读时，调用accept接受一个新的客户端连接，并将添加到readfds套接字集合中</p>

<pre><code>if (FD_ISSET(sock_server, &amp;rfds)) {
    struct sockaddr_in clientaddr;
    socklen_t clientaddr_len = sizeof(clientaddr);
    int clientsock = accept(sock_server, (struct sockaddr *)&amp;clientaddr, &amp;clientaddr_len);
    if (clientsock &lt; 0) {
        printf("accept fail. reason:%s\n", strerror(errno));
        continue;
    } else {
        printf("new client connected, %s:%d \n", inet_ntoa(clientaddr.sin_addr), clientaddr.sin_port);
        int i;
        for (i = 0; i &lt; FD_SETSIZE; i++) {
            if (clientfds[i] == -1) {
                clientfds[i] = clientsock;
                break;
            }
        }
        if (i == FD_SETSIZE) {
            printf("too many clients, ignore this one\n");
            continue;
        }
        FD_SET(clientfds[i], &amp;allfds);
        if (clientfds[i] &gt; maxfd)
            maxfd = clientfds[i];
    }
}  
</code></pre>

<p>2）当每个客户端套接字可读时，对套接字调用read操作后，继续执行select判断是否有套接字可读，而不是处理一个客户端连接直到完成。</p>

<pre><code>for (int i = 0; i &lt; FD_SETSIZE; i++) {
    if (readyfds == 0)
        break;
    if (clientfds[i] &lt; 0)
        continue;
    if (FD_ISSET(clientfds[i], &amp;rfds)) {
        readyfds--;
        char buf[LINE_MAX];
        ssize_t rcv_len;
        rcv_len = recv(clientfds[i], buf, sizeof(buf), 0);
        if (rcv_len &gt; 0) {
            buf[rcv_len] = '\0';
            printf("recv from client(%d), msg: %s\n", clientfds[i], buf);
            for (int i = 0; i &lt; rcv_len; i++)
                buf[i] = toupper(buf[i]);
                send(clientfds[i], buf, rcv_len, 0);
                printf("send to client:%s", buf);
            } else if (rcv_len == 0) {
                printf("recv_len == 0 from client:%d\n", clientfds[i]);
                FD_CLR(clientfds[i], &amp;allfds);
                close(clientfds[i]);
                clientfds[i] = -1;
            } else {
                printf("recv from clientfd(%d) fail. reason:%s\n", clientfds[i], strerror(errno));
                continue;
            }
        }
    }
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tcp Client 使用select进行I/O复用]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/04/06/tcp-client-shi-yong-selectjin-xing-i-slash-ofu-yong/"/>
    <updated>2015-04-06T11:49:13+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/04/06/tcp-client-shi-yong-selectjin-xing-i-slash-ofu-yong</id>
    <content type="html"><![CDATA[<p>在<a href="http://jintao-zero.github.io/blog/2015/02/10/tcp-ke-hu-duan-shi-li/">tcp客户端示例</a>中，存在以下两种情况时，示例代码不能更好的处理：</p>

<ul>
<li><p>目前客户端输入一条数据并发送，等待服务端返回后，才能继续输入数据
 这样的设计不利于客户端批量处理数据</p></li>
<li><p>当服务端出现异常（如服务进程退出或者服务端主机崩溃等异常情况），客户端也许正在等待输入，不能够及时感知到服务端的异常，只有从send返回错误时，才能感知到服务端故障</p></li>
</ul>


<h1>select 函数介绍</h1>

<p>上面实现的客户端示例中，客户端只能处理一个描述符，我们需要修改客户端使其可以同时处理标准输入和套接字描述符，达到I/O复用：</p>

<pre><code>#include &lt;sys/select.h&gt;
#include &lt;sys/time.h&gt;
int select(int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds,
     struct timeval *restrict timeout);
</code></pre>

<ul>
<li><p>timeout参数，它告知内核等待所有描述符中的一个就绪可花多长时间<br/>
  struct timeval {<br/>
      long tv_sec;  /* seconds*/<br/>
      long tv_usec; /* microseconds*/<br/>
  }   <br/>
  (1) 永远等待下去：仅在有一个描述符准备好时返回。为此，将timeout设置为   空指针<br/>
  (2) 等待一段固定时间：在有一个描述符准备好I/O时返回，但是不超过由该参数所指向的timeval结构中指定的秒数和微秒数<br/>
  (3) 根本不等待：检查描述符后立即返回，这称为轮询。为此，该参数必须指向一个timeval结构，而且其中的定时器值必须为0</p></li>
<li><p>readfds, writefds, errorfds参数，这三个参数指定了，需要内核测试读、写     和异常条件的描述符集合。
系统提供了以下宏来对描述符进行操作：<br/>
void FD_CLR(fd, fd_set <em>fdset)<br/>
void FD_COPY(fd_set </em>fdest_orig, fd_set <em>fdset_copy)<br/>
int FD_ISSET(fd, fd_set </em>fdset)<br/>
void FD_SET(fd, fd_set <em>fdset)<br/>
void FD_ZERO(fd_set </em>fdset)</p></li>
<li><p>nfds参数，指定待测试的描述符个数，它的值是待测试的最大描述符加1</p></li>
</ul>


<!-- more -->


<h1>描述符就绪条件</h1>

<ul>
<li><p>满足下列四个条件中的任何一个时，一个套接字准备好读<br/>
a) 该套接字接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的当前大小。对这样的套接字执行读操作不会阻塞并将返回一个大于0的值（也就是返回准备好读入的数据）。对于TCP和UDP套接字，其默认值为1。<br/>
b) 该连接的读半部关闭（也就是接收了FIN的TCP连接）。对这样的套接字的读操作将不阻塞并返回0（也就是返回EOF）<br/>
c) 该套接字是一个监听套接字且已完成的连接数大于0。对于这样的套接字调用accept通常不会阻塞。  <br/>
d) 其上有一个套接字错误待处理。对这样的套接字的读操作将不阻塞并返回－1（也就是返回一个错误），同时把errno设置成确切的错误条件。</p></li>
<li><p>下列四个条件中的任何一个满足时，一个套接字准备好写。<br/>
a) 该套接字发送缓冲区中的可用空间字节数大于等于套接字发送缓冲区低水位表姐的当前大小，并且或者该套接字已连接，或者该套接字不需要连接（如UDP套接字）。  <br/>
b) 该连接的写半部关闭。对这样的套接字的写操作将产生SIGPIPE信号。<br/>
c) 使用非阻塞式connect的套接字已建立连接，或者connect已经以失败告终。<br/>
d) 其上有一个套接字错误待处理。</p></li>
<li>如果一个套接字存在带外数据或者仍处于带外标记，那么它有异常条件待处理。</li>
</ul>


<h1>修改tcp客户端程序</h1>

<ul>
<li><p>批量输入<br/>
a) 用户输入数据，标准输入可读，read返回读入字节数，发送到服务器<br/>
b) 用户输入Ctrl-D时，标准输入可读，read返回字节数为0，此时关闭套接字写端</p></li>
<li><p>套接字增加处理情况：
a) 如果对端TCP发送数据，那么该套接字变为可读，并且read返回一个大于0的值（即读入数据的字节数）。<br/>
b) 如果对端TCP发送一个FIN（对端进程终止），那么该套接字变为可读，并且read返回0（EOF）。<br/>
c) 如果对端TCP发送一个RST（对端主机崩溃并重新启动），那么该套接字变为可读，并且read返回－1，而errno中含有确切的错误码。</p></li>
</ul>


<p>以下是相关修改：<br/>
1、将标准输入、套接字添加到客服描述符集合</p>

<pre><code>fd_set readfds;
FD_ZERO(&amp;readfds);
FD_SET(sock_client, &amp;readfds);
FD_SET(STDIN_FILENO, &amp;readfds);
int maxfd = (STDIN_FILENO &gt; sock_client ? STDIN_FILENO: sock_client) + 1;
select(maxfd, &amp;readfds, NULL, NULL, NULL)
</code></pre>

<p>2、标准输入可读</p>

<pre><code>if (FD_ISSET(STDIN_FILENO , &amp;readfds)) {
    ssize_t rd_size = read(STDIN_FILENO , buf, sizeof(buf));
    if (rd_size &gt; 0) {
        ssize_t sd_size = send(sock_client, buf, rd_size, 0);
        buf[rd_size] = '\0';
        printf("send msg(len:%ld):%s to server \n", sd_size, buf);
    } else if (rd_size == 0) {
    // client finish send msg to server, we close write part of the full-duplex connection
        shutdown(sock_client, SHUT_WR); // send FIN to server
        stdineof = 1;
        continue;
    } else {
    // client finish send msg to server, we close write part of the full-duplex connection
        printf("read fail from console, reason:%s \n", strerror(errno));
        break;
    }
}  
</code></pre>

<p>3、套接字可读</p>

<pre><code>if (FD_ISSET(sock_client, &amp;readfds)) {
    ssize_t rd_size = read(sock_client, buf, sizeof(buf));
    if (rd_size &gt; 0) {
        printf("receive from server:%s", buf);
    } else if (rd_size == 0) { // client receive FIN
            printf("receive 0 from server\n");
            if (stdineof == 1) {
                printf("normal finish\n");
            } else {// server crash and reset, client receive RST
                printf("server terminate prematurely\n");
            }
            break;
        } else {
            printf("read fail.reason: %s\n", strerror(errno));
            break;
        }
    }
}
</code></pre>

<p>下面是使用select进行I/O复用的tcp客户端代码：</p>

<pre><code>int main(int argc, char *argv[])
{
    // judge the legal arguments
    if (2 &gt; argc) {
        printf("please input a hostname \n");
        return -1;
    }

// create a socket
    int sock_client = socket(AF_INET, SOCK_STREAM, 0);
    if (0 &gt; sock_client) {
        perror("create socket error");
        return -1;
    }


    // construct server sockaddr
        struct hostent *p = gethostbyname(argv[1]);
        if (p == NULL) {
            printf("gethostbyname:%s fail.reason:%s \n", argv[1], strerror(errno));
            return -1;
        }
        struct sockaddr_in servaddr;
        bzero(&amp;servaddr, sizeof(servaddr));
        servaddr.sin_family = AF_INET;
        servaddr.sin_addr = *(struct in_addr *)p-&gt;h_addr;
        servaddr.sin_port = htons(SERVER_PORT);

        // connect to server
        if (connect(sock_client, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) == -1) {
            printf("connect to server:%s port:%d fail.reason:%s \n", inet_ntoa(servaddr.sin_addr), SERVER_PORT,
                strerror(errno));
            return -1;
        }
        printf("connect to server:%s port:%d success\n", inet_ntoa(servaddr.sin_addr), SERVER_PORT );


        int stdineof = 0;
        for (; ; ) {
            fd_set readfds;
            FD_ZERO(&amp;readfds);
            FD_SET(sock_client, &amp;readfds);
            if (stdineof == 0)
                FD_SET(STDIN_FILENO, &amp;readfds);
            int maxfd = (STDIN_FILENO &gt; sock_client ? STDIN_FILENO: sock_client) + 1;
            if (select(maxfd, &amp;readfds, NULL, NULL, NULL) &gt; 0) {
                char buf[LINE_MAX]={0};
                if (FD_ISSET(STDIN_FILENO , &amp;readfds)) {
                    ssize_t rd_size = read(STDIN_FILENO , buf, sizeof(buf));
                    if (rd_size &gt; 0) {
                        ssize_t sd_size = send(sock_client, buf, rd_size, 0);
                        buf[rd_size] = '\0';
                        printf("send msg(len:%ld):%s to server \n", sd_size, buf);
                    } else if (rd_size == 0) {
                        // client finish send msg to server, we close write part of the full-duplex connection
                        shutdown(sock_client, SHUT_WR); // send FIN to server
                        stdineof = 1;
                        continue;
                    } else {
                        // client finish send msg to server, we close write part of the full-duplex connection
                        printf("read fail from console, reason:%s \n", strerror(errno));
                        break;
                    }
                } else if (FD_ISSET(sock_client, &amp;readfds)) {
                    ssize_t rd_size = read(sock_client, buf, sizeof(buf));
                    if (rd_size &gt; 0) {
                        printf("receive from server:%s", buf);
                    } else if (rd_size == 0) { // client receive FIN
                        printf("receive 0 from server\n");
                        if (stdineof == 1) {
                            printf("normal finish\n");
                        } else {// server crash and reset, client receive RST
                            printf("server terminate prematurely\n");
                        }
                        break;
                    } else {
                        printf("read fail.reason: %s\n", strerror(errno));
                        break;
                    }
                }
            }
        }
        close(sock_client);
    }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python Property 属性用法]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/04/05/python-property-shu-xing-yong-fa/"/>
    <updated>2015-04-05T17:26:05+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/04/05/python-property-shu-xing-yong-fa</id>
    <content type="html"><![CDATA[<p>python提供了一个property类：</p>

<pre><code>class property([fget[, fset[, fdel[, doc]]]])
</code></pre>

<p>property类为新式类（继承object）返回property属性<br/>
fget函数用来获取属性值。fset设置属性值。fdel用来删除属性。doc为属性创建docstring。<br/>
property的典型应用是应用一个被管理的属性x：</p>

<pre><code>class C(object):
def __init__(self):
    self._x = None

def getx(self):
    return self._x

def setx(self, value):
    self._x = value

def delx(self):
    del self._x

x = property(getx, setx, delx, "I'm the 'x' property.")
</code></pre>

<p>如果c是类C的实例，c.x将会调用getx，c.x＝value将会调用setx，del c.x会调用用delx</p>

<p>将property 用作decorrator可以定义只读properties：</p>

<pre><code>class Parrot(object):
    def __init__(self):
        self._voltage = 100000

    @property
    def voltage(self):
        """Get the current voltage."""
        return self._voltage
</code></pre>

<p>@property修饰符将voltage函数变为voltage函数的同名属性的只读getter函数，同时这只这个属性的docstring与voltage函数相同</p>

<p>一个property对象具有getter，setter和deleter方法可以用当作修饰符将属性同名函数变为属性对应的访问函数，下面是例子：</p>

<pre><code>class C(object):
    def __init__(self):
        self._x = None

    @property
    def x(self):
        """I'm the 'x' property."""
        return self._x

    @x.setter
    def x(self, value):
        self._x = value

    @x.deleter
    def x(self):
        del self._x
</code></pre>

<p>上面的用法与第一个列子相同，需要注意的是几个函数的名字都相同</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tcp服务端并发之子进程]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/02/17/tcpfu-wu-duan-bing-fa-zhi-zi-jin-cheng/"/>
    <updated>2015-02-17T14:56:56+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/02/17/tcpfu-wu-duan-bing-fa-zhi-zi-jin-cheng</id>
    <content type="html"><![CDATA[<p>上一篇博客中实现的tcp服务端每次只能处理一个客户端连接，如果有多个客户端同时与服务端进行通讯的话，那只能进行等待上一个客户端通讯完成才可以，那么如何修改服务端为并发服务器程序呢？Unix中编写并发服务器程序最简单的方法就是fork一个子进程来服务每个客户。以下为一个典型的并发服务器的轮廓：</p>

<pre><code>pid_t pid;
int listenfd, connfd;
listenfd = Socket(...);
    /* fill in sockaddr_in{} with server's well-known port */
Bind*(listenfd, ...);
Listen(listenfd, LISTENQ);
for ( ; ; ) {
    connfd = Accept(listenfd, ...);  /* probably blocks */
    if ((pid = Fork()) == 0) {
        Close(listenfd);    /* child close listening socket */
        doit(connfd);       /* process the request */
        close(connfd);      /* child terminates */
        exit(0);            /* child terminate */
    }
    Close(connfd);          /* parent closes connected socket */
}
</code></pre>

<p>fork函数</p>

<pre><code>pid_t fork(void);
</code></pre>

<p>fork创建一个新进程。新进程是当前运行进程的一个拷贝。fork函数一次调用，两次返回。对于子进程返回值为0，对于父进程，返回值为子进程id。</p>

<p>以下为根据上面的并发服务器轮廓代码修改的tcp客户端代码：</p>

<!-- more -->


<pre><code>for (; ; ) {

    if ((connsock = accept(sock_server, (struct sockaddr *)&amp;clientaddr, &amp;clientaddr_len)) &lt; 0) {
        if (errno == EINTR) {
            continue;
        }
        else {
            printf("accept fail. reason:%s \n", strerror(errno));
            close(sock_server);
            exit(0);
        }
    }
    printf("new client connected, %s:%d \n", inet_ntoa(clientaddr.sin_addr), clientaddr.sin_port);

    int child = fork();
    if (child == 0) { // child process

        close(sock_server);
        printf("child process:%d \n", getpid());
        // recv data from client
        char buf[1024];
        ssize_t rcv_len;
        while ((rcv_len = recv(connsock, buf, sizeof(buf), 0)) &gt; 0) {
            printf("recv from client:%s\n", buf);
            for (int i = 0; i &lt; rcv_len; i++)
                buf[i] = toupper(buf[i]);
            send(connsock, buf, rcv_len, 0);
            printf("send to  client:%s\n", buf);
        }
        printf("len:%ld \n", rcv_len);
        close(connsock);
        exit(0);
    }

    // parent process
    close(connsock);
}
</code></pre>

<p>以上tcp服务端程序可以并发处理多个客户端请求，但是在通讯结束，子进程调用exit函数退出后，会产生僵死进程, 使用ps命令可以看到多个server进程状态为Z+：<br/>
<img src="http://jintao-zero.github.io/images/zombie.png">
设置僵死状态的目的是维护子进程的信息，以便父进程在以后某个时候获取。这些信息包括子进程的进程ID、终止状态以及资源利用信息（CPU时间、内存使用量等等）。如果一个进程终止，而该进程有子进程处于僵死状态，那么它的所有僵死子进程的富进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们。<br/>
僵死进程占用内核中的空间，最终可能导致我们耗尽进程资源，因此我们需要及时的清理僵死子进程，无论何时我们fork子进程都得wait它们，以防它们变成僵死进程。每个子进程在退出时，内核都会向父进程发送SIGCHLD信号，因此父进程需要建立一个俘获SIGCHLD信号的信号处理函数，在函数体中调用wait。</p>

<p>wait函数</p>

<pre><code>pid_t wait(int *stat_loc);
</code></pre>

<p>wait函数阻塞调用进程直到获取到一个退出子进程的信息，成功返回后，stat_loc返回退出子进程的退出信息。SIGCHILD信号处理函数为：</p>

<pre><code>void chld_sig_handler(int signo)
{
    int stat_loc;
    wait(&amp;stat_loc);
    return ;
}
</code></pre>

<p>sigaction函数</p>

<pre><code>struct  sigaction {
         union __sigaction_u __sigaction_u;  /* signal handler */
         sigset_t sa_mask;               /* signal mask to apply */
         int     sa_flags;               /* see signal options below */
 };

 union __sigaction_u {
         void    (*__sa_handler)(int);
         void    (*__sa_sigaction)(int, struct __siginfo *,
                        void *);
 };

#define sa_handler      __sigaction_u.__sa_handler
#define sa_sigaction    __sigaction_u.__sa_sigaction

int sigaction(int sig, const struct sigaction *restrict act, struct sigaction *restrict oact);
</code></pre>

<p>sigaction函数用来修改进程对于某个信号的处理函数
参数sig为需要修改处理函数的信号id
参数act说明了该信号处理函数，以及进入处理函数时的信号掩码</p>

<pre><code>// register SIGCHLD process handler
struct sigaction act;
struct sigaction oact;
act.sa_handler = chld_sig_handler;
sigemptyset(&amp;act.sa_mask);
act.sa_flags = 0;
if (sigaction(SIGCHLD, &amp;act, &amp;oact) &lt; 0) {
    printf("set SIGCHLD handler fail. reason:%s \n", strerror(errno));
    close(sock_server);
    return -1;
}
</code></pre>

<p>在tcp服务代码中添加了SIGCHLD信号处理函数后，重新测试，但是发现仍然会出现僵死子进程：<br/>
<img src="http://jintao-zero.github.io/images/zombie_wait.png"><br/>
Unix信号处理机制中，<br/>
1、当一个信号达到后，进入该信号的处理函数后，进程将屏蔽该信号 <br/>
2、多个同样类型信号同时到达时，信号处理函数只执行一次，其他的信号不进行排队</p>

<p>这样当多个客户端连接同时结束时，会导致服务端子进程同时退出，多个SIGCHLD信号同时产生递送到服务端父进程，那么一种可能的情况是，在信号处理函数被调用之前，信号都到达，那么只有一个信号被处理，其他信号不会排队，将会被丢弃，这样仍然产生僵死子进程。<br/>
为了解决这样问题，可以在信号处理函数中多次执行wait操作，获取已经结束子进程的退出信息。但是上面的wait接口是阻塞等待、直到有新退出进程，这样的话就会影响进程的正常执行，下面介绍另外一个</p>

<pre><code>pid_t waitpid(pid_t pid, int *stat_loc, int options);
</code></pre>

<p>参数pid指定需要等待的进程集。pid为-1时，等待任何子进程。pid为0时，等待调用者进程组里面的任何子进程。pid大于0时，等待进程号为pid的子进程。
参数stat_loc用来保存进程退出状态。
参数options,为WNOHANG、WUNTRACED选项的或。指定WNOHANG操作时，如果尚没有退出的子进程，你们waitp函数不阻塞等待，会返回0。指定WUNTRACED选项时，如果子进程是由于SIGTTIN,SIGTTOU,SIGTSTP,SIGSTOP信号而处于stopped状态，那么wait操作也会获取到这些进程的状态信息。<br/>
需要修改SIGCHLD信号处理函数，使用waitp函数，设置options位WNOHANG来读取所有已经退出子进程的进程状态，防止变为僵尸进程。</p>

<pre><code>void chld_sig_handler(int signo)
{
    int stat_loc;
    int options = WNOHANG;
    int pid;
    while ((pid = waitpid(-1, &amp;stat_loc, options)) &gt; 0) {
        printf("wait pid:%d suc\n", pid);   // normally we should call i/o func in signal handler
    }
return ;
}
</code></pre>

<p>对于服务器主进程而言，大部分的时间都是阻塞在accept系统调用上，这一类的系统调用也称为慢系统调用（slow system call），适用与慢系统调用的一个规则是：当阻塞与某个慢系统调用的一个进程捕获某个信号且相应信号处理函数返回时，该系统调用可能返回一个EINTR错误。有些内核自动重启某些被中断的系统调用。为了便于移植，当我们编写捕获信号的程序时（多数并发服务器捕获SIGCHLD），我们必须对慢系统调用返回EINTR有所准备。修改服务器代码为：</p>

<pre><code>if ((connsock = accept(sock_server, (struct sockaddr *)&amp;clientaddr, &amp;clientaddr_len)) &lt; 0) {
    if (errno == EINTR) {
        continue;
    } else {
        printf("accept fail. reason:%s \n", strerror(errno));
        close(sock_server);
        exit(0);
    }
}
</code></pre>

<p>本片文章的目的时总结我们在网络编程时可能会遇到的三种情况：
(1) 当fork子进程时，必须捕获SIGCHLD信号
(2) 当捕获信号时，必须处理被中断的系统调用
(3) SIGCHLD的信号处理函数必须正确编写，应适用waitpid函数以免留下僵尸进程</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tcp 服务端例子]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/02/13/tcp-fu-wu-duan-li-zi/"/>
    <updated>2015-02-13T11:04:43+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/02/13/tcp-fu-wu-duan-li-zi</id>
    <content type="html"><![CDATA[<p>实现了一个简单服务端，使用tcp与客户端进行通讯。本片文章主要介绍在tcp服务端网络编程中用到的几个基本函数：<br/>
1、创建套接字socket函数</p>

<pre><code>int socket(int domain, int type, int protocol)
</code></pre>

<p>socket函数创建一个通讯端并返回这个终端的文件描述符。</p>

<p>参数domain指定发生整个通讯过程所在的协议域。协议域定义在&lt;sys/socket.h>头文件中，常用协议域名为：</p>

<pre><code>PF_LOCAL 主机内部通讯协议，之前名为PF_UNIX
PF_UNIX  主机内部通讯协议，废弃，使用PF_LOCAL
PF_INET  IPV4通讯协议
PF_INET6 IPV6通讯协议
。。。
</code></pre>

<p>本例子中使用PF_INET ipv4通讯协议域</p>

<p>参数type指定socket类型，目前定义类型为：</p>

<pre><code>SOCK_STREAM                                      
SOCK_DGRAM
SOCK_RAW
SOCK_SEQPACKET
SOCK_RDM
</code></pre>

<p>SOCK_STREAM 类型提供序列化、可靠的、全双工字节流套接字
SOCK_DGRAM 类型提供无连接的、不可靠的，有报文最大限制的数据报通讯套接字
SOCK_RAW 类型提供读取内部网络协议和网卡接口的原始套接字，需要有超级用户权限<br/>
本例子中使用SOCK_STREAM流套接字类型</p>

<p>失败时，函数返回-1，成功时，返回套接字文件描述符</p>

<p>2、bind函数</p>

<pre><code>int bind(int socket, const struct sockaddr *address, socklen_t address_len);
</code></pre>

<p>bind函数把一个本地协议地址赋予一个套接字。
参数socket，为需要赋予地址的套接字。
参数address，为赋予到套接字的地址结构，有ip和端口号标识。
参数address_len, 为该地址结构大小</p>

<p>对于服务端来讲，在调用监听函数之前，都需要bind到特定地址和端口</p>

<!-- more -->


<p>3、listen函数</p>

<pre><code>int listen(int socket, int backlog);
</code></pre>

<p>listen函数仅由TCP服务器调用，它做两件事情：<br/>
(1) 当socket函数创建一个套接字时，它被假设为一个主动套接字，也就是说，它是一个将调用connect发起连接的客户套接字。   listen函数把一个未连接的套接字转换成一个被动套接字，指示内核应接受指向该套接字的连接请求。根据tcp状态转换图，调用listen导致套接字从CLOSED状态转换到LISTEN状态。<br/>
(2) 本函数的第二个参数规定了内核应该为相应套接字排队的最大连接个数。
本函数通常应该在调用socket和bind这两个函数之后，并在调用accept函数之前调用。
内核为任何一个给定的监听套接字维护两个队列：<br/>
(1)未完成连接队列，每个这样的SYN分节对应其中一项：已由某个客户发出并到达服务器，而服务器正在等待完成相应的TCP三路握手过程。这些套接字处于SYN_RCVD状态<br/>
(2)已完成连接队列，每个已完成TCP三路握手的客户对应其中一项。这些套接字处于ESTABLISHED状态。
参数backlog规定了以上两个队列的总和大小</p>

<p>4、accept函数</p>

<pre><code>int accept(int socket, struct sockaddr *restrict address, socklen_t *restrict address_len);
</code></pre>

<p>accept函数由TCP服务器调用，用于从已完成连接队列对头返回下一个已完成连接。如果已完成连接队列未空，那么进程被投入睡眠（假定套接字为默认的阻塞方式）。
参数address和address_len返回已连接的对端进程的协议地址。
如果accept成功，那么其返回值是由内核自动生产的一个全新描述符，代表与所返回客户的TCP连接。</p>

<p>5、下面是服务端源代码
此服务端小程序主要完成功能：1、监听服务端口，接收连接 2、接收客户端数据并处理后发回服务端</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;sys/socket.h&gt;
#include &lt;sys/errno.h&gt;
#include &lt;string.h&gt;
#include &lt;netinet/in.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;ctype.h&gt;

#define SERVER_PORT 8000

int main()
{
    // create socket
    int sock_server = socket(AF_INET, SOCK_STREAM, 0);
    if (-1 == sock_server) {
        printf("create socket fail.reason:%s\n",                strerror(errno));
        return -1;
    }

    // bind socket to local addr and port
    struct sockaddr_in servaddr;
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr  = INADDR_ANY;
    servaddr.sin_port = htons(SERVER_PORT);
    if (-1 == bind(sock_server, (struct sockaddr *)&amp;servaddr, (socklen_t)sizeof(servaddr))) {
        printf("bind to local addr fail.%s \n", strerror(errno));
        return -1;
    }
    printf("bind to local addr success\n");

    // make socket to listen
    if (-1 == listen(sock_server, 128)) {
        printf("listen fail.%s\n", strerror(errno));
        return -1;
    }

    struct sockaddr_in clientaddr;
    socklen_t clientaddr_len = sizeof(clientaddr);
    int connsock;

    // accept a new client connection
    while ((connsock = accept(sock_server, (struct sockaddr *)&amp;clientaddr, &amp;clientaddr_len)) != -1) {

        printf("new client connected, %s:%d \n", inet_ntoa(clientaddr.sin_addr),            clientaddr.sin_port);

        // recv data from client
        char buf[1024];
        ssize_t rcv_len;
        while ((rcv_len = recv(connsock, buf, sizeof(buf), 0)) &gt; 0) {
            printf("recv from client:%s\n", buf);
            for (int i = 0; i &lt; rcv_len; i++)
                buf[i] = toupper(buf[i]);
            send(connsock, buf, rcv_len, 0);
            printf("send to  client:%s\n", buf);
        }
        printf("len:%ld \n", rcv_len);
        close(connsock);
    }
    close(sock_server);
}   
</code></pre>

<p>运行效果：
<img src="http://jintao-zero.github.io/images/server.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tcp 客户端示例]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/02/10/tcp-ke-hu-duan-shi-li/"/>
    <updated>2015-02-10T19:07:27+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/02/10/tcp-ke-hu-duan-shi-li</id>
    <content type="html"><![CDATA[<p>实现了一个简单客户端，使用tcp与服务端进行通讯。本片文章主要介绍在tcp客户端网络编程中用到的几个基本函数：<br/>
1、创建socket</p>

<pre><code>int socket(int domain, int type, int protocol)
</code></pre>

<p>socket函数创建一个通讯端并返回这个终端的文件描述符。</p>

<p>参数domain指定发生整个通讯过程所在的协议域。协议域定义在&lt;sys/socket.h>头文件中，常用协议域名为：</p>

<pre><code>PF_LOCAL 主机内部通讯协议，之前名为PF_UNIX
PF_UNIX  主机内部通讯协议，废弃，使用PF_LOCAL
PF_INET  IPV4通讯协议
PF_INET6 IPV6通讯协议
。。。
</code></pre>

<p>本例子中使用PF_INET ipv4通讯协议域</p>

<p>参数type指定socket类型，目前定义类型为：</p>

<pre><code>SOCK_STREAM                                      
SOCK_DGRAM
SOCK_RAW
SOCK_SEQPACKET
SOCK_RDM
</code></pre>

<p>SOCK_STREAM 类型提供序列化、可靠的、全双工字节流套接字
SOCK_DGRAM 类型提供无连接的、不可靠的，有报文最大限制的数据报通讯套接字
SOCK_RAW 类型提供读取内部网络协议和网卡接口的原始套接字，需要有超级用户权限<br/>
本例子中使用SOCK_STREAM流套接字类型</p>

<p>失败时，函数返回－1，成功时，返回套接字文件描述符</p>

<p>2、connect连接服务端</p>

<pre><code>int connect(int socket, const struct sockaddr *address, socklen_t address_len);
</code></pre>

<p>connect函数在一个socket上面初始化一个连接</p>

<p>参数socket为要建立连接的套接字<br/>
参数address为要对端连接的地址，不同协议域会有不同的方式解析这个参数内容
参数address_len为传入的address地址所对应地址结构体占据的内存大小</p>

<p>连接成功，函数返回0，失败，则返回－1，同时置错误码errno</p>

<!-- more -->


<p></p>

<p>3、send发送内容</p>

<pre><code>ssize_t send(int socket, const void *buffer, size_t length, int flags);
</code></pre>

<p>send函数发送数据到对端套接字。使用send函数时需要socket处于连接状态。</p>

<p>参数buffer为需要发送内容首地址<br/>
参数length为需要发送的报文内容长度<br/>
参数flags可能包含以下两种：</p>

<pre><code>    #define MSG_OOB        0x1  /* process out-of-band data */
    #define MSG_DONTROUTE  0x4  /* bypass routing, use direct interface */
</code></pre>

<p>本例中，不需要以上两种标志，设置为0即可</p>

<p>发送成功，函数返回发送的字节数，发送失败，返回－1，设置errno错误码</p>

<p>4、recv接受内容</p>

<pre><code>ssize_t recv(int socket, void *buffer, size_t length, int flags);
</code></pre>

<p>recv函数只可以在处于连接状态套接字使用。
默认情况下，如果没有数据可读，recv调用将会一直阻塞等待数据到达，除非socket被设置为非阻塞状态。通常情况下，recv会返回任何可读数据，最大达到请求的length数量，而不是一直等待接收到length数量才返回，可以通过设置套接字属性SO_RCVLOWAT和SO_RCVTIMEO来进行修改。
如果没有可接收数据并且对端已经执行关闭操作，那么recv返回0</p>

<p>参数flags，有以下几种类型：</p>

<pre><code>MSG_OOB        process out-of-band data
MSG_PEEK       peek at incoming message
MSG_WAITALL    wait for full request or error
</code></pre>

<p>MSG_OOB标志请求接收带外数据。<br/>
MSG_PEEK标志使recv只从头读取队列中的数据而不从队列中删除这些数据，这样接下来的读操作会读取相同内容。
MSG_WAITALL标志使recv操作阻塞直到读取的报文达到请求字节数。</p>

<p>recv函数返回接收到的字节数，返回－1表示发生错误，返回0表示对端已经关闭连接。</p>

<p>5、示例代码
示例完成功能：1、与服务端建立tcp连接 2、从控制台读取输入，发送到服务端 3、读取服务端返回数据 4、关闭tcp连接</p>

<pre><code>#include &lt;sys/socket.h&gt;
#include &lt;netdb.h&gt;
#include &lt;arpa/inet.h&gt;
#include &lt;sys/errno.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;

#define SERVER_PORT 8000

int main(int argc, char *argv[])
{
    // judge the legal arguments
    if (2 &gt; argc) {
        printf("please input a hostname \n");
        return -1;
    }

    // create a SOC_STREAM socket
    int sock_client = socket(AF_INET, SOCK_STREAM, 0);
    if (0 &gt; sock_client) {
        perror("create socket error");
        return -1;
    }


    // construct server sockaddr
    struct hostent *p = gethostbyname(argv[1]);
    if (p == NULL) {
        printf("gethostbyname:%s fail.reason:%s \n", argv[1], strerror(errno));
        return -1;
    }
    struct sockaddr_in servaddr;
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr = *(struct in_addr *)p-&gt;h_addr;
    servaddr.sin_port = htons(SERVER_PORT);

    // connect to server
    if (connect(sock_client, (struct sockaddr *)&amp;servaddr, sizeof(servaddr)) == -1) {
        printf("connect to server:%s port:%d fail.reason:%s \n", inet_ntoa(servaddr.sin_addr), SERVER_PORT,
        strerror(errno));
        return -1;
    }
    printf("connect to server:%s port:%d success\n", inet_ntoa(servaddr.sin_addr), SERVER_PORT );

    // send and rev data with server
    char buf[1024];
    while(fgets(buf, sizeof(buf)-1, stdin))
    {
        int len = strlen(buf);
        if (len == 1)
            break;
        buf[len-1] = '\0';
        printf("%d\n", len-1);
        ssize_t send_size = send(sock_client, buf, len, 0);
        if (send_size != len) {
            printf("send fail \n");
            break;
        }
        ssize_t rcv_size = recv(sock_client, buf, sizeof(buf), 0);
        if (rcv_size == -1) {
            printf("rcv fail\n");
            break;
        }
        printf("recv from server:%s \n", buf);
    }
    close(sock_client);
}   
</code></pre>
]]></content>
  </entry>
  
</feed>

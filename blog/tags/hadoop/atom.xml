<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: Hadoop | jintao's blog]]></title>
  <link href="http://jintao-zero.github.io/blog/tags/hadoop/atom.xml" rel="self"/>
  <link href="http://jintao-zero.github.io/"/>
  <updated>2017-09-04T20:23:38+08:00</updated>
  <id>http://jintao-zero.github.io/</id>
  <author>
    <name><![CDATA[jintao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[hdfs文件系统java api介绍]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao/"/>
    <updated>2015-12-21T17:29:19+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/12/21/hdfswen-jian-xi-tong-java-apijie-shao</id>
    <content type="html"><![CDATA[<h1>Hadoop Filesystems</h1>

<p>Hadoop对于文件系统有一个抽象设计，HDFS只是一个实现。客户端使用Java 抽象类org.apache.hadoop.fs.FileSystem来访问Hadoop中的文件系统，有多个具体实现类:</p>

<pre><code>FileSystem      URI scheme      Java implementaion  
Local           file            fs.LocalFileSystem  

HDFS            hdfs            hdfs.DistributedFileSystem

WebHDFS         webhdfs         hdfs.web.WebHdfsFileSystem

Secure
WebHDFs         swebhdfs        hdfs.web.SWebHdfsFileSystem

HAR             har             fs.HarFileSystem

View            viewfs          viewfs.ViewFileSystem

FTP             ftp             fs.ftp.FTPFileSystem

S3              s3a             fs.s3a.S3AFileSystem

Azure           wasb            fs.azure.NativeAzureFileSystem

Swift           swift           fs.swift.snative.SwiftNative
</code></pre>

<p>Hadoop提供多个接口访问文件系统，接口利用URI的scheme来创建对应的实例与文件系统进行通讯。hdfs命令可以用来操作Hadoop各种文件系统，比如列出本地文件系统根目录内容：</p>

<pre><code>[root@yun1 ~]# hdfs dfs -ls file:///
Found 25 items
-rw-r--r--   1 root root          0 2015-10-19 11:06 file:///.autofsck
-rw-r--r--   1 root root          0 2014-07-04 14:16 file:///.autorelabel
dr-xr-xr-x   - root root       4096 2014-07-04 14:36 file:///bin
dr-xr-xr-x   - root root       1024 2014-09-17 15:54 file:///boot
drwxr-xr-x   - root root       4096 2014-07-04 09:17 file:///data
-rw-r--r--   1 root root       1001 2014-07-29 16:28 file:///dataplatform.log
drwxr-xr-x   - root root       3580 2015-10-19 11:08 file:///dev
</code></pre>

<h1>Java Interface</h1>

<!-- more -->


<p>访问HDFS文件系统需要先获取一个文件系统实例，FileSystem是一个文件系统统一访问接口。通过以下接口可以获取访问hdfs文件系统的实例：</p>

<pre><code>public static FileSystem get(Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf) throws IOException
public static FileSystem get(URI uri, Configuration conf, String user) throws IOException
</code></pre>

<p>Configuration对象封装客户端或者服务端的配置信息，这些信息由classpath目录下配置文件初始化，比如etc/hadoop/core-site.xml。第一个接口根据conf中的信息，返回文件系统。第二个接口使用URI的scheme和授权来觉得使用哪个文件系统，如果没有设置scheme，则使用conf中配置的文件系统。第三个接口是以user用户的身份获取文件系统。 使用FileSystem实例，调用open方法可以获取一个输入文件流：</p>

<pre><code>public FSDataInputStream open(Path f) throws IOException
public abstract FSDataInputStream open(Path f, int bufferSize) throws IOException 
</code></pre>

<p>下面的代码实例用于读取hdfs文件输出到标准输出：</p>

<pre><code>public class FileSystemCat {

    public static void main(String[] args) throws Exception {
        String uri = args[0];
        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(uri), conf);
        InputStream in = null;
        try {
            in = fs.open(new Path(uri));
            IOUtils.copyBytes(in, System.out, 4096, false);
        } finally {
            IOUtils.closeStream(in);
        }
    }
}
</code></pre>

<p>编译文件后，使用hadoop命令运行class文件：</p>

<pre><code># hadoop FileSystemCat hdfs://localhost/user/tom/quangle.txt
On the top of the Crumpetty Tree
The Quangle Wangle sat, 
But his face you could not see,
On account of his Beaver Hat.
</code></pre>

<h2>Writing Data</h2>

<p>FileSystem提供多个接口来创建文件，最简单的是输入一个路径作为参数，返回一个输出流：</p>

<pre><code>public FSDataOutputStream create(Path f) throws IOException 存在多个重载接口，允许指定是否重写已存在文件，文件的副本个数，写文件的缓冲区大小，文件的块大小和文件权限等等。存在append接口对已存在文件进行追加：
public FSDataOutputStream append(Path f) throws IOException
</code></pre>

<p>下面的代码实例是拷贝一个本地文件到Hadoop文件系统中：</p>

<pre><code>public class FileCopyWithProgress {
    public static void main(String []args) throws Exception {
        String localSrc = args[0];
        String dst = args[1];

        InputStream in = new BufferedInputStream(new FileInputStream(localSrc));

        Configuration conf = new Configuration();
        FileSystem fs = FileSystem.get(URI.create(dst), conf);
        OutputStream out = fs.create(new Path(dst), new Progressable() {
            public void progress() {
                System.out.print(".");
            }
        });

        IOUtils.copyBytes(in, out, 4096, true);
    }
}
</code></pre>

<p>运行程序结果如下：
    #hadoop FileCopyWithProgress input/docs/1400-8.txt hdfs://localhost/user/tom/1400-8.txt</p>

<p>创建目录使用下面的接口：</p>

<pre><code>public boolean mkdirs(Path f) throws IOException
</code></pre>

<h2>Quering the FileSystem</h2>

<p>FilsSystem提供了接口来获取文件或者文件夹信息，信息包括文件长度，块大小，复制，修改时间，所有权，访问权限属性。</p>

<pre><code>abstract FileStatus getFileStatus(Path f)
</code></pre>

<p>FileSystem提供了接口来列出一个目录中包含的内容：</p>

<pre><code>abstract FileStatus[]   listStatus(Path f)
FileStatus[]    listStatus(Path[] files)
FileStatus[]    listStatus(Path[] files, PathFilter filter)
FileStatus[]    listStatus(Path f, PathFilter filter)
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hadoop环境搭建]]></title>
    <link href="http://jintao-zero.github.io/blog/2015/09/19/hadoophuan-jing-da-jian/"/>
    <updated>2015-09-19T15:41:51+08:00</updated>
    <id>http://jintao-zero.github.io/blog/2015/09/19/hadoophuan-jing-da-jian</id>
    <content type="html"><![CDATA[<p>最近开始进行Hadoop分布式计算相关内容的学习，先从搭建开发环境开始。下面记录一下搭建Hadoop开发环境的过程，以及注意点。
本节介绍如何快速搭建和配置一个单节点Hadoop环境，便于使用Hadoop MapReduce和Hadoop Distributed File System(HDFS)。</p>

<h2>依赖条件</h2>

<p>支持的操作系统平台  <br/>
GNU/Linux支持作为Hadoop的开发和生产环境，Hadoop已经证明可以在GNU/Linux集群上运行2000节点。本文使用Ubuntu操作系统做为实验环境。</p>

<pre><code>Linux node8 3.16.0-30-generic #40~14.04.1-Ubuntu SMP Thu Jan 15 17:43:14 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
</code></pre>

<p>Windows系统也可以搭建Hadoop集群，本文暂时没有涉及，可以参考<a href="http://wiki.apache.org/hadoop/Hadoop2OnWindows">wiki page</a></p>

<p>依赖的软件</p>

<ul>
<li><p>Java环境<br/>
  安装方法：</p>

<p>  1、到oracle官网下载<a href="http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.tar.gz">JDK二进制压缩包</a><br/>
  2、将压缩包解压到/usr/local/lib/目录下，安装目录也可以换到其他路径  <br/>
      sudo tar xzvf jdk-8u45-linux-x64.tar.gz -C /usr/local/lib/<br/>
  3、修改/etc/profile文件配置JAVA_HOME、PATH、CLASSPATH环境变量<br/>
      JAVA_HOME=/usr/local/lib/jdk1.8.0_45<br/>
      PATH=$JAVA_HOME/bin:$PATH<br/>
      CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar <br/>
  4、运行java -version查看是否显示java版本信息</p></li>
<li><p>ssh远程控制软件<br/>
  如果系统没有运行sshd服务，则Ubuntu下运行apt-get命令安装ssh服务端
  sudo apt-get install openssh-server</p></li>
</ul>


<h2>下载Hadoop软件</h2>

<p>本文采用的是Hadoop最新的稳定版本<a href="http://apache.fayea.com/hadoop/common/current/hadoop-2.7.1.tar.gz">2.7.1</a></p>

<!-- more -->


<p></p>

<h2>准备运行集群</h2>

<p>1、将压缩包解压到一个安装目录下</p>

<pre><code>sudo tar xzvf hadoop-2.7.1.tar.gz -C /home/jintao/toolkit/
</code></pre>

<p>2、打开安装目录下etc/hadoop/hadoop-env.sh</p>

<pre><code>添加一句 export JAVA_HOME=/usr/local/lib/jdk1.8.0_45
</code></pre>

<p>3、运行bin/hadoop命令，查看hadoop命令使用帮助</p>

<h2>单机模式</h2>

<p>默认情况，Hadoop运行在非分布式模式，一个单独Java进程。这种模式调试时很有用。下面的例子，拷贝hadoop目录下面的etc/hadoop/*.xml作为输入，运行hadoop打印文件中匹配正则表达式的内容，输出到指定的output目录。</p>

<pre><code>$ mkdir input  
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
$ cat output/*
</code></pre>

<h2>伪分布式</h2>

<p>Hadoop可以在单个节点运行在伪分布式模式，每个Hadoop守护进程运行在不同的Java进程。</p>

<h3>配置</h3>

<p>编辑以下文件：
etc/hadoop/core-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>etc/hadoop/hdfs-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3>设置ssh无密码登录</h3>

<p>查看当前是否可以无密码登录：</p>

<pre><code>$ ssh localhost
</code></pre>

<p>如果不可以无密码登录，则执行一下命令：</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<h3>执行</h3>

<p>以下指令在本地运行一个MapReduce任务。<br/>
1、格式化hdfs文件系统</p>

<pre><code>$ bin/hdfs namenode -format
</code></pre>

<p>默认namenode存储路径：/tmp/hadoop-jintao/dfs/name</p>

<p>2、运行NameNode和DataNode守护进程：</p>

<pre><code>$ sbin/start-dfs.sh
</code></pre>

<p>hadoop守护进程日志输出到$HADOOP_LOG_DIR目录（默认在$HADOOP_HOME/logs安装目录的logs目录下）。使用jps查看java进行：</p>

<pre><code>jintao@node8:~/toolkit/hadoop-2.7.1$ jps
5248 DataNode
5473 SecondaryNameNode
5105 NameNode
13380 Jps
</code></pre>

<p>3、通过web接口查看NameNode信息；默认路径：</p>

<pre><code>http://localhost:50070/
</code></pre>

<p>4、创建执行MapReduce任务需要的HDFS路径：/user/&lt;username></p>

<pre><code>$ bin/hdfs dfs -mkdir /user 
$ bin/hdfs dfs -mkdir /user/jintao
</code></pre>

<p>5、将试验用的数据放到hdfs上input目录下：</p>

<pre><code>$ bin/hdfs dfs -put etc/hadoop input
</code></pre>

<p>6、运行hadoop自带的grep任务：</p>

<pre><code>$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>7、将结果文件从hdfs上获取到本地目录outpu中，并查看结果：</p>

<pre><code>$ bin/hdfs -get output output
$ cat output/*
</code></pre>

<p>或者直接查看hdfs上面的结果文件：</p>

<pre><code>$ bin/hdfs -cat output/*
</code></pre>

<p>8、关闭hadoop后台进程</p>

<pre><code>$ sbin/stop-dfs.sh
</code></pre>

<h3>伪分布式运行YARN</h3>

<p>设置一些参数，可以在伪分布式环境下运行YARN框架管理MapReduce任务，YARN框架会启动ResourceManager和NodeManager守护进程。<br/>
在上面1到4步完成的基础上，进行如下设置：<br/>
1、配置etc/hadoop/mapred-site.xml，如果不存在mapred-site.xml，则拷贝一份mapred-site.xml.template命名为mapred-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>配置etc/hadoop/yarn-site.xml：</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>2、启动ResourceManager和NodeManager后台进程：</p>

<pre><code>$ sbin/start-yarn.sh
$ jps
15858 NodeManager
15301 DataNode
15542 SecondaryNameNode
16119 Jps
15160 NameNode
15723 ResourceManager
</code></pre>

<p>3、浏览ResourceMnaager信息：</p>

<pre><code>http://localhost:8088/
</code></pre>

<p>4、运行一个MapReduce任务：</p>

<pre><code>$ bin/hdfs dfs -rm -r -f output
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>5、关闭yarn框架进程</p>

<pre><code>$ sbin/stop-yarn.sh
</code></pre>

<h2>集群环境</h2>

<p>搭建四台机器（node1、node2、node3、node4）的Hadoop集群环境：<br/>
1、node1部署NameNode和ResourceManager<br/>
2、node2、node3、node4作为slave节点部署DataNode和NodeManager</p>

<p>典型集群环境下，应该将单独一台机器运行NameNode，另外一台机器运行ResourceManager，这些是主控节点。其他服务（比如Web App Proxy Server和MapReduce Job History server）通常运行在一台指定机器或者共享设备上，依赖于系统负载。集群中其他机器都同时部署DataNode和NodeManager，这些都是slaves节点。</p>

<h3>准备工作</h3>

<p>1、每台机器都安装JAVA环境<br/>
   参考上面单机环境搭建，进行安装、配置环境变量</p>

<p>2、编辑hosts文件
    编辑每台机器的hosts文件，将hostname和ip的对应关系添加到/etc/hosts中</p>

<pre><code>192.168.88.120 node0
192.168.88.121 node1
192.168.88.122 node2
192.168.88.123 node3
</code></pre>

<p>在各台机器上通过主机名ping各台机器，查看是否能够ping通</p>

<p>3、配置ssh无密码登录
每台机上运行，生存密钥</p>

<pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<p>ssh集群启动时，主控节点会通过ssh远程登录到slaves节点执行脚本启动slaves节点，因此我们需要配置主控节点到slaves节点的无密码登录：<br/>
将主控节点的pub密钥拷贝到各个slaves节点~/.ssh/目录下</p>

<pre><code>scp id_rsa.pub jintao@node1:~/.ssh/node0.pub
</code></pre>

<p>将node0.pub文件的内容追加到各个节点的authorized_keys文件中：</p>

<pre><code>cat node0.pub &gt;&gt; authorized_keys
</code></pre>

<p>从node0节点ssh到slaves节点上，查看是否不需要密码</p>

<p>4、创建hadoop工作目录</p>

<pre><code>mkdir /home/jintao/hadoop_dir
</code></pre>

<p>如果将hadoop工作目录配置在其他目录下，则需要使hadoop的运行账户对该目录具有读写权限</p>

<p>5、下载Hadoop安装程序<br/>
从官网下载安装程序，解压到~/toolkit/目录下，toolkit后面陆续会安装其他zookeeper、hbase等项目</p>

<h3>配置Hadoop</h3>

<p>管理员应该使用etc/haddop-env.sh和etc/hadoop/mapred-env.sh和etc/hadoop/yarn-env.sh三个相关脚本来配置Hadoop进程环境。</p>

<p>1、打开安装目录下etc/hadoop/hadoop-env.sh</p>

<pre><code>添加一句 export JAVA_HOME=/usr/local/lib/jdk1.8.0_45
</code></pre>

<p>2、vim core-site.xml</p>

<pre><code>&lt;configuration&gt;
    &lt;property&gt;
            &lt;name&gt;fs.defaultFS&lt;/name&gt;
            &lt;value&gt;hdfs://node0:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
            &lt;value&gt;/home/jintao/hadoop_dir&lt;/value&gt;
            &lt;description&gt;A base for other temporary directories.&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>设置fs.defaultFS和hadoop.tmp.dir属性</p>

<p>3、vim hdfs-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>4、vim mapred-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>5、vim yarn-site.xml</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;node0&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>6、vim slaves</p>

<pre><code>ode1
node2
node3
</code></pre>

<p>7、将配置好的hadoop程序同步到slaves节点上</p>

<pre><code>scp -r toolkit/ node1:~
scp -r toolkit/ node2:~
scp -r toolkit/ node3:~
</code></pre>

<p>8、启动namenode节点</p>

<pre><code>1、cd ~/toolkit/hadoop-2.7.1/
2、bin/hdfs namenode -format
3、sbin/start-all.sh
</code></pre>

<p>9、node0上查看jps</p>

<pre><code>9904 Jps
9426 SecondaryNameNode
9190 NameNode
9607 ResourceManager
</code></pre>

<p>10、node1、node2、node3上查看jps</p>

<pre><code>9507 Jps
9323 NodeManager
9213 DataNode
</code></pre>

<p>11、系统启动日志记录在hadoop-2.7.1/logs目录下</p>
]]></content>
  </entry>
  
</feed>
